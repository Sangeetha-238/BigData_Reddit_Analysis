<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.246">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Natural Language Processing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./eda.html">
 <span class="menu-text">EDA</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./nlp.html" aria-current="page">
 <span class="menu-text">NLP</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Natural Language Processing</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/nlp_hero.png" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>This page outlines a technical proposal designed to address specific business goals by applying NLP methodologies to analyze and understand the content of subreddits. The primary objectives include uncovering popular themes and gauging sentiment.The subreddit chosen for analysis in this part is r/anime, r/movies, r/Animesuggest, r/MovieSuggestions.</p>
<section id="technical-analysis-report" class="level3">
<h3 class="anchored" data-anchor-id="technical-analysis-report">Technical Analysis Report</h3>
<section id="comprehensive-analysis-report-on-reddit-discussions-unveiling-trends-in-movie-popularity" class="level4">
<h4 class="anchored" data-anchor-id="comprehensive-analysis-report-on-reddit-discussions-unveiling-trends-in-movie-popularity">Comprehensive Analysis Report on Reddit Discussions: Unveiling Trends in Movie Popularity</h4>
<p>This analysis aims to discern prevailing trends in Reddit discussions related to movies. The primary goal is to compile a dataset featuring the most talked-about movies on the platform. Subsequently, this dataset will be cross-referenced with our external review data, particularly from platforms like Rotten Tomatoes. The objective is to determine if movies generating the most buzz on Reddit also receive positive critical acclaim or exhibit differing evaluations.</p>
<p>Key Steps:</p>
<ul>
<li><p>Extracting movie names from the reddit comment Submission</p></li>
<li><p>To extract relevant information efficiently, we employed sophisticated text cleaning techniques. These included:</p></li>
<li><p><strong>Document Assembler:</strong> Aggregated and organized the raw text data from Reddit comments, preparing it for further processing.</p></li>
<li><p><strong>Sentence Detector:</strong> Segregated the text into distinct sentences, enhancing the granularity of our analysis.</p></li>
<li><p><strong>BERT Embeddings:</strong> Utilized advanced BERT (Bidirectional Encoder Representations from Transformers) embeddings to capture contextualized representations of words, improving the accuracy of subsequent analyses.</p></li>
<li><p><strong>Named Entity Recognition (NER):</strong> Applied NER techniques to identify entities within the text, specifically focusing on recognizing movie names mentioned in the comments. Using ORG and PERSON labels</p></li>
<li><p><strong>NER Converter:</strong> Transformed the identified named entities, such as movie names, into a structured format suitable for dataset construction.</p></li>
</ul>
<p>After extracting initial movie names, we employed targeted regex pattern matching to capture additional titles:</p>
<ul>
<li><strong>Camel Casing Words:</strong> Identified and extracted movie titles written in Camel Case format.</li>
<li><strong>Quoted Phrases:</strong> Recognized and extracted movie names enclosed within double quotes.</li>
<li><strong>Capitalized Word Pairs:</strong> Extracted words between two capital-letter-starting words, facilitating retrieval of stylistically formatted movie titles.</li>
<li><strong>Numeric Associations:</strong> Captured numeric values following movie mentions, linking numerical information like release years to specific titles.</li>
<li><strong>Year in Parentheses:</strong> Identified words before the year mentioned within parentheses, aiding in the extraction of titles near their release years.</li>
</ul>
<p>Following this extraction, we refined the dataset by removing stop words based on element length. This meticulous process enhanced the accuracy and relevance of our dataset, ensuring a nuanced and precise analysis of movie discussions on Reddit.</p>
<div class="cell" data-fig-width="11.5">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-1">flowchart LR
  A[Document Assembler] --&gt; B[Sentence Detector]
  B --&gt; C[Tokenizer]
  C --&gt; D[BERT Embeddings]
  D --&gt; E[Named Entity Recognition]
  E --&gt; F[NER Converter]
  
  style A fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style B fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style C fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style D fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style E fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style F fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
 
  
 %% Add figure caption
  style caption fill:#F2F6F7,stroke:#F2F6F7,color:#747a7f;
  caption[Figure-1: NLP Pipeline for Reddit Data]
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<p>In the subsequent phase, our focus shifted to conducting sentiment analysis on our external dataset, utilizing the Rotten Tomatoes movie review dataset. To ensure the data was well-prepared for sentiment analysis, we implemented a series of fundamental text cleaning processes. The key techniques applied included:</p>
<ul>
<li><strong>Document Assembler:</strong> Aggregated and organized the raw text data, preparing it for subsequent processing steps.</li>
<li><strong>Tokenizer:</strong> Employed tokenization to break down the text into individual units, enhancing the granularity of our analysis.</li>
<li><strong>Normalizer:</strong> Applied normalization techniques to standardize the text, ensuring consistent formatting and reducing variability.</li>
<li><strong>Lemmatizer:</strong> Utilized lemmatization to transform words to their base or root form, enhancing the accuracy of sentiment analysis by considering the underlying meaning of words.</li>
<li><strong>Stopwords Remover:</strong> Implemented a stopwords removal process to eliminate common words that do not contribute significantly to sentiment analysis, thereby focusing on more meaningful content.</li>
</ul>
<p>These text cleaning techniques collectively facilitated the creation of a refined and standardized dataset for sentiment analysis.</p>
<p>For sentiment analysis, we employed two distinct sentiment models:</p>
<ul>
<li><strong>SentimentDL_use_twitter:</strong> This model leverages advanced deep learning techniques to discern sentiment, particularly tailored for the nuances and expressions commonly found in Twitter-like text.</li>
<li><strong>ClassifierDL_use_emotion:</strong> Utilizing a classifier approach, this model gauges sentiment by understanding emotional nuances present in the text, providing a comprehensive analysis of sentiment with a focus on emotional context.</li>
</ul>
<p>By incorporating these advanced sentiment analysis models and employing meticulous text cleaning processes, we aimed to extract nuanced sentiment insights from the Rotten Tomatoes movie review dataset. This multi-faceted approach ensures a robust and comprehensive analysis of sentiment dynamics associated with the movies in our external dataset.</p>
<div class="cell" data-fig-width="11.5">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-2">flowchart LR
  A[Document Assembler] --&gt; B[Tokenizer]
  B --&gt; C[Normalizer]
  C --&gt; D[Lemmatizer]
  D --&gt; E[Stopwords Remover]
  
  style A fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style B fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style C fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style D fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  style E fill:#fac3b6,stroke:#FF4301,stroke-width:1px;
  
 %% Add figure caption
  style caption fill:#F2F6F7,stroke:#F2F6F7,color:#747a7f;
  caption[Figure-2: NLP Pipeline for Data Cleaning]
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
</section>
<section id="executive-summary" class="level3">
<h3 class="anchored" data-anchor-id="executive-summary">Executive summary</h3>
<p>1-2 paragraphs on your NLP accomplishments - can include up to 2 images or tables, describe the high-level results, must be&nbsp;NON-TECHNICAL</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Content 2023 by [Project Team 34] <br> All content licensed under a <a href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International license (CC BY-NC 4.0)</a></div>   
    <div class="nav-footer-right">Made with <a href="https://quarto.org/">Quarto</a><br> <a href="https://github.com/gu-dsan6000/fall-2023-reddit-project-team-34">View the source at GitHub</a></div>
  </div>
</footer>



</body></html>