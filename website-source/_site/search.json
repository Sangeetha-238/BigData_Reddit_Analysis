[
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Analysis Report\nIn this analysis, we utilized Submissions Reddit data stored in an Azure Machine Learning workspace blob store in parquet format, employing PySpark for distributed data processing and Pandas for local data manipulation and analysis.\nTo kick off our exploration of entertainment subreddits, we aimed for a broad understanding of how submissions are distributed across entertainment-related subreddits. To achieve this goal, we created a lollipop graph with post counts of subreddits on the x-axis and different entertainment subreddits on the y-axis.\n\n\n\nFigure-1: Count of each subreddit in the dataset from 2021-2023\n\n\nFrom Figure 1, it’s evident that the ‘anime’ subreddit is the most active with 404,298 posts, showcasing a very active community with a strong interest in anime-related content. Following closely is the ‘movies’ subreddit, also bustling with activity at 382,085 posts. Both ‘anime’ and ‘movie’ subreddits outshine the ‘television’ subreddit in post counts, revealing higher user engagement in these topics. A similar trend can be observed among the subreddits dedicated to suggestions with the ‘AnimeSuggestions’ subreddit having a higher post count followed by ‘MovieSuggestions’ and ‘televisionsuggestions’. This indicates that there is a substantial interest in community-driven recommendations for anime. The ‘MovieSuggestions’ subreddit has a moderate number of posts, while ‘televisionsuggestions’ has the least, reflecting lower user engagement for television recommendations on the Reddit platform.\nNext, we filtered the data to keep only the subset of columns relevant to our analysis. The selected columns include information about the submission, such as the subreddit, author, title, selftext, creation timestamp, number of comments, score, and various other attributes related to the submission’s characteristics. After selecting specific columns, we aimed to understand the dataset’s structure and quality. To achieve this, we obtained the count of missing values in each column of the dataset. Table 1 represents a summary of missing values in our dataset, where each row corresponds to a different feature, and the ‘Missing Values’ column quantifies the number of missing values for each feature.\n\n \n\n  \n  Table-1: Count of missing values of all the columns for submissions dataset\n\n\nTable-1 shows that columns such as ‘author’, ‘title’, ‘selftext’, ‘created_utc’, ‘num_comments’, ‘score’, ‘over_18’, ‘pinned’, and ‘locked’ show complete data with zero missing values, suggesting they are mandatory fields in the platform’s post submission process. While, a significant number of missing values are observed in the ‘disable_comments’, ‘distinguished’, and ‘media’ columns. This could indicate that these fields are optional or applicable only to certain posts. This makes sense for instance, ‘distinguished’ could denote a special status assigned to certain posts, which would naturally be less common. Since the columns with the missing values were not relevant to our business goals and also removing missing values from these columns could remove posts with optional features. So we decided to retain the rows with missing values and it would also preserve the completeness of the dataset.\nMoving further, three new columns were added to the data by transforming the original DataFrame:\n\nFirstly, we extracted various time-related features like ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’ from the ‘created_utc’ timestamp. These features can be useful for analyzing trends or patterns in the data based on temporal information.\nSecondly, we wanted to analyze the overall length of posts, so we added a new column ‘post_length’ to the data. The values in this column are calculated based on the sum of the lengths of the ‘title’ and ‘selftext’ columns for each row.\nThirdly, we created a new column called ‘has_media’ that is set to “True” if a post has media content (like images or videos) and “False” if it doesn’t. This makes it easier to identify which posts include some form of media and which do not.\n\nAfter these transformations were done, the columns like “media,” “created_utc,” “disable_comments,” and “distinguished,” which were no longer necessary for our analysis, were dropped.\nThe following table shows the final columns and their descriptions that were used for our analysis.\n=====add table========\nMoving forward, we performed data manipulation to generate structured datasets encompassing top comments for specific subreddits, author post counts, and time series analysis. These datasets will serve as a foundation for extracting insights into user engagement, content popularity, temporal evolution, and author contributions on the Reddit platform through the creation of meaningful visualizations.\nThe detailed process and code can be found here for data cleaning and here for data manipulation.\n\n\nUnderstanding trends in the engagement of posts from 2021-2023\nNext, we were curious to see how the general trend in the engagement across prominent subreddits —‘anime,’ ‘movies,’ and ‘television’ evolve over different periods of time. In order to achieve this we firstly decided to analyse how number of posts and the scores varied over the period of two years.\n \n\n  \n  Figure-2: This graph illustrates the normalized post count trends across three subreddits (anime, movies, and television) over a span of two years, from January 2021 to April 2023. The peaks and troughs indicate fluctuations in user engagement and post frequency within the Reddit community.\n\n\nFigure-2 attempts to capture the trend in the number of posts made across the three subreddits over the time period of 2021-2023. To facilitate a more accurate assessment of relative fluctuations in user engagement and post frequency, normalized post counts were used. Overall, the subreddits exhibit a more gradual decline, implying a slow yet consistent decrease in the number of posts and interactions. The overarching decline across all three subreddits raises questions about the factors influencing these changes.However, when comparing the three sections, we can observe that the movies and anime subreddits show a general decrease in the number of posts. On the other hand, the engagement, in terms of posts made, remains relatively constant for the television subreddit. The possibility of shifting platform dynamics, evolving content consumption patterns, or the rise of alternative entertainment forums could be contributing to this trend. It indicates a potential shift in the digital landscape where traditional subreddit forums may no longer command the same level of attention as before. Certain high peaks could possibly correlate to significant new releases in any of the three categories, resulting in increased engagement and discussions on the platform. For instance, we can see a peak starting from March 2021, which could equate to the release of Zack Snyder’s much-hyped movie, Justice League.”\n \n\n  \n  Figure-3: This graph illustrates the scores across three subreddits (anime, movies, and television) over a span of two years, from January 2021 to April 2023. The peaks and troughs indicate fluctuations in user engagement and scores within the Reddit community.\n\n\nFigure 3 shows the trends in changes in the average scores from 2021 to 2023. When comparing Figures 2 and 3, we observe that, in general, scores remain relatively constant for the anime section during this period, despite a considerable fluctuating decline in the number of posts. However, for movies and television, there is a general slight upward trend in scores, in contrast to the step downward trend in the number of posts. This suggests that, for these two categories, the number of posts made is slightly inversely proportional to the rating. This could be due to the availability of fewer posts to view, resulting in an increase in scores for those written during that period.\nNext, we wanted to see if there are any trends in the number of posts and average score depending on the time of the month. This was to figure out if there was a day of the month were the number of engagement on the platform were showing a particular trend either high or low.\n \n\n  \n  Figure-4: Number of posts submitted on different days of the month from 2021-2023\n\n\nFigure 4 compares the number of posts across the three subreddits by the day of the month. In this figure, it is challenging to pinpoint any specific day of the month where the number of posts is particularly high. The downward trend at the end of the month is attributed to the variation in the number of days each month, as not every month has 31 days.\n \n\n  \n  Figure-5: Average score of posts submitted on different days of the month from 2021-2023\n\n\nWhen examining Figure 5, which compares the average scores for each day of the month, it is apparent that the scores generally remain constant with occasional bumps in all three categories. However, television shows the highest ratings despite having the fewest number of posts. This observation seems to confirm an inverse relationship between the number of posts and the scores. Furthermore, we aimed to streamline our analysis to understand how trends in the number of posts and scores vary when comparing different days of the week and hours of the day.\n \n\n  \n  Figure-6: Number of posts during the week and time of the day for the subreddits\n\n\nFigure-6 presents the distribution of posts across days of the week and hours of the day for the subreddits ‘anime,’ ‘movies,’ and ‘television.’ This visualization suggests that the ‘television’ subreddit has its own unique pattern of user interaction, potentially reflecting the airing schedule of popular shows or weekly events that drive discussions, especially during the evening hours from 3 PM to 5 PM. Overall, all three subreddits show a more spread-out activity throughout the week, indicating a consistent level of engagement without significant peaks or troughs.\n \n\n  \n  Figure-7: Number of posts during the week and time of the day for the subreddits\n\n\nFigure-7 illustrates the distribution of average scores across days of the week and hours of the day for the subreddits ‘anime,’ ‘movies,’ and ‘television.’ The plot suggests that people are generally more active in reading and voting for posts each day of the week, particularly during the late afternoon hours of 2 PM to 4 PM. This trend is also directly proportional to the number of posts made during those hours.\nOverall, we can assert that interaction activities peak on these Reddit threads during the late afternoon hours. These insights underscore the importance of timing in Reddit community engagement. For marketers and content creators, aligning content releases with these observed peaks could enhance user engagement. For platform moderators, it could inform the scheduling of events or AMAs (Ask Me Anything sessions) to ensure higher participation rates. Additionally, this data could assist in the strategic placement of advertisements during specific hours of a particular day, ensuring they reach the most active audience segments.\n\n\nExploring how Reddit post engagement dynamics is influenced by subreddit characteristics.\n \n\n  \n  Figure-8: Correlation between post lengths and scores within anime, movies, and television subreddits on Reddit.\n\n\n\n\nUser Engagement Analysis\n\nComparative Analysis of Post Engagement by Length and Score in Entertainment-Related Subreddits\nThis scatter plot illustrates the engagement dynamics of Reddit posts, comparing post length to user engagement across subreddits dedicated to anime, movies, and television. Each dot represents an individual post, with its size corresponding to the score, which is a proxy for the post’s popularity or engagement level.\nA cursory analysis reveals a dense clustering of posts with scores under 10,000 across all subreddits, with post lengths predominantly falling below 2000 characters. This suggests that shorter posts are more common, regardless of the subreddit category. Interestingly, there is a visible trend where posts with higher scores tend to have shorter lengths, indicating that more concise posts may resonate better with the audience or are more likely to be engaged with.\nThe larger-sized dots, indicating posts with exceptionally high scores, are predominantly short and are scattered across all three subreddits. This may indicate that highly engaging posts, which are likely to go viral or hit the front page of Reddit, tend to be succinct.\nThis insight can inform content creators and marketers about optimal post lengths for audience engagement in different entertainment categories on Reddit.\n\n\nTop Reddit Authors by Comment Engagement in the subreddit Discussion\nThe table presents a ranking of authors by the comment volume on their posts in the movie, television and anime subreddits. High comment counts generally indicate that an author’s contributions are well-received, sparking active discussions among the subreddit’s users. This level of engagement typically reflects the community’s interest and the value they find in the content shared by the author.\nThe table not only identifies the most engaging authors in the subreddits but also underscores the importance of creating content that encourages community participation. The data provides valuable insights into user engagement and could be leveraged to understand better what types of posts cultivate active discussions in online communities.\n\n \n\n  \n  Table-2: Ranks of authors from a subreddit based on the number of comments their posts receive, highlighting the most engaging content creators\n\n\n\n\nLeading Content Creators based on top Comments\nThe bar chart presents the post counts attributed to the ten most active authors within the subreddits “movies, anime, and television”. These counts are a direct indicator of the quantity of content contributed by individual authors rather than the quality or engagement level of the posts.\nThe presence of active contributors can be vital for fostering community engagement and providing a steady stream of content for discussion. On the other hand, the steep drop in post counts after the third author indicates that there is less parity in content contribution among the top authors. The remaining seven authors in the list show a relatively lower level of activity, with post counts ranging from moderate to minimal. This disparity suggests that a small group of authors may dominate the conversation or content within this subreddit.\nThe movies subreddit appears to have a few highly active authors who contribute a significant portion of the content. This concentration of activity might influence the diversity of topics and perspectives presented within the community.\nIn the television subreddit, the distribution of post counts among the top ten authors reveals a significant skew, with ‘MarvelsGrantMan136’ and ‘Neo2199’ being the most active. This pattern suggests that the television subreddit may rely on a small group of dedicated individuals for a substantial portion of its content, which could potentially influence the scope and variety of discussions within the community.\nContrastingly, the anime subreddit presents a unique scenario where bots, rather than human authors, are the primary content contributors. Interestingly, despite—or perhaps because of—the automated nature of their posts, these bot-generated discussions are engaging the community to a greater extent than typical human-authored posts on the platform. This could be attributed to the bots providing timely, consistently formatted, and relevant content that resonates well with the subreddit’s audience.\nThe high engagement with bot posts in the anime subreddit may also reflect the community’s preference for structured information, such as regular updates on anime releases, episode discussions, and well-organized recommendation lists. These automated posts may fulfill the community’s needs more effectively than the more varied human contributions found in other subreddits.\nIn light of this, the anime subreddit stands out as a unique case study in community engagement on social platforms, showcasing that automated systems, when well-tuned to the audience’s preferences, can play a pivotal role in fostering active online communities. This insight challenges the conventional wisdom that the most engaging content must be human-generated and highlights the potential for bots to contribute meaningfully to online discourse in interest-specific forums.\n \n\n  \n  Figure-6: This bar chart ranks the top 10 authors in the subreddit based on the number of posts they have made and the top comments received\n\n\n\n\n\nTop Reddit Posts Authors by Scores Engagement in the subreddit Discussion\nThe table shows a list from a subreddit, ranking the top 10 posts by score. For the movie subreddit, the highest-scoring post is an AMA with Tobey Maguire, indicating that interactive sessions with famous actors are highly valued in the community. This is further emphasized by the presence of another AMA with Keanu Reeves in the second position. The third highest post by Nicolas Cage suggests that personal engagement from actors or filmmakers garners significant attention.\nPosts regarding industry news and opinions, such as the win of Brendan Fraser at the Academy Awards and a call to prioritize voice actors over celebrities in animated features, reflect the community’s interest in both celebrating achievements and critiquing industry trends. A post about a ‘Dune’ sequel hints at the community’s enthusiasm for science fiction and blockbuster franchises.\nNotably, there is a discussion on diversity in casting, pointing towards a conscious reflection on representation in movies. The list also shows a mix of content authors, from individual users to likely official accounts like “lionsgate,” indicating a blend of community-driven content and industry participation in the subreddit.\nFor the television subreddit, The most popular post highlights a public figure, LeVar Burton, expressing his desire to become the new host of “Jeopardy!”, which is indicative of the community’s interest in show hostings and personalities associated with them. This is further emphasized by another post where Burton encourages the producers of “Jeopardy!” to consider him for the role, showcasing the community’s support for his candidacy.\nOther posts indicate strong community interest in television show news and updates, like the revival of “Futurama” and a potential third season for “Mindhunter.” The active engagement in these topics suggests that news about television series renewals and continuations is particularly resonant with the audience.\nThese posts reflect a community that is deeply engaged with the television industry, from show developments and castings to the achievements and remembrances of beloved television figures. The scores provide insight into what type of content the community values and discusses most, which includes industry news, show developments, and the accomplishments and milestones of individuals in television.\nMoving to the anime, The top post is about the death of Kentaro Miura, the creator of “Berserk,” which underscores the impact that influential figures in the anime industry have on the community. The high score indicates that news about significant personalities, especially those who have made a profound impact on the genre, resonates deeply with the audience.\nSeveral posts relate to announcements of new seasons for popular anime series like “The Devil is a Part-Timer,” “Spice and Wolf,” and “Konosuba.” This suggests that the subreddit is a hub for fans to discuss and share their excitement about continuing series and new developments within their favorite anime.\nThere is also a post about a prediction tournament for “Best Girl,” a common discussion topic in anime communities where fans vote for their favorite female characters. The popularity of such a post indicates that interactive and participatory events are engaging for the community members.\n\n \n\n  \n  Table-3: Ranks of authors from a subreddit based on the Scores their posts receive, highlighting the most engaging content creators\n\n\n\n\nLeading Content Creators based on top Scores\nThe bar chart depicts the top 10 authors by post count within the anime, movies, and television subreddits, with a specific focus on those receiving the highest scores, which could be indicative of the popularity of the posts.\n‘AutoLovepon’ leads in the anime subreddit with an exceptionally high post count, indicating a significant impact on the community, likely due to consistent, high-quality content, which could be automated. In the movies subreddit, ‘MarvelsGrantMan136’ dominates but is followed by a group of authors with notable contributions, reflecting a community with diverse yet influential voices. The television subreddit shows ‘MarvelsGrantMan136’ leading, with a narrower margin over ‘chanma50’, suggesting a broader spread of engagement across various authors. These patterns highlight different engagement dynamics, with a single dominant presence in anime and a more varied influence among authors in the movies and television subreddits, offering insights into community preferences and influencer identification.\n \n\n  \n  Figure-7: This bar chart ranks the top 10 authors in the subreddit based on the number of posts they have made and the top scores received\n\n\n\n\nAuthors with the highest number of posts\nThe bar chart provides an overview of the top 10 active authors in the anime, movies, and television subreddits, showing a clear disparity in activity levels across these categories.\nFor the movies subreddit, the top author has an exceptionally high post count, exceeding 20,000, which is significantly higher than the subsequent authors. This could imply a central role in the subreddit, possibly as a source of extensive information or regular discussion threads. However, the drop in post counts among the following authors is stark, indicating a less concentrated field of active contributors and suggesting a more varied source of content within the community.\nIn the television subreddit, the post counts among the top authors are more evenly distributed, with ‘MarvelsGrantMan136’ leading but with a smaller margin compared to the leaders in the anime and movies subreddits. This indicates a more balanced contribution from the top authors, which could result in a diverse range of discussions and viewpoints being represented in the subreddit.\nMoving to the anime subreddit, the leading author, presumably a bot named ‘AutoLovepon’, has a post count that far exceeds that of any human contributor, with over 6000 posts. This suggests a high level of automation in content generation, which is indicative of a structured and consistent posting strategy, possibly catering to the demand for updates, recommendations, or scheduled discussion threads. Given the nature of bot-generated content, this level of activity might provide a streamlined experience for users seeking information without the variability of human-authored posts.\nIn conclusion, these engagement models reflect the unique cultural dynamics of each subreddit, providing valuable insights for content creators, moderators, and marketers on how to approach each community effectively.\n \n\n  \n  Figure-8: This bar chart ranks the top 10 authors in the subreddit based on the number of posts they have made\n\n\n\n\n\nConclusion for Engagement Analysis:\nThe comparative analysis of the post counts from the top authors across the anime, movies, and television subreddits reveals distinct patterns of community engagement and content contribution. In the anime subreddit, the dominance of the bot ‘AutoLovepon’ highlights a preference for structured, automated content, which contrasts sharply with the human-driven contributions in the movies and television subreddits. In movies, a few authors, particularly ‘MarvelsGrantMan136’, contribute a majority of the content, suggesting a central role in driving discussions and shaping the subreddit’s narrative. Conversely, the television subreddit demonstrates a more balanced distribution of post counts among the top authors, indicating a diverse range of discussions and viewpoints. These patterns underscore the varying dynamics of online communities and the different roles that authors, whether human or automated, play in shaping the content and discussions within these digital spaces. This analysis not only provides insights into the unique characteristics of each subreddit but also underscores the importance of understanding audience preferences and engagement styles when creating or moderating content in online communities."
  },
  {
    "objectID": "nlp_exec_summary.html",
    "href": "nlp_exec_summary.html",
    "title": "Natural Language Processing - Executive Summary",
    "section": "",
    "text": "Understanding Digital Tastes in Cinema and Anime:\nIn the age of digital discourse, platforms like Reddit have become crucial in shaping the cultural conversation around entertainment. This section delves into the wealth of data on Reddit to extract what movies and anime are being suggested by users, transcending traditional top-ten lists by incorporating sentiment analysis and popularity metrics.\n\nReddit’s Favorite Films: A Community Perspective\nReddit’s MovieSuggestions subreddit is a lively place where movie buffs share their favorite picks. This isn’t just about what movies make the most money or get the best reviews from critics. It’s about people talking about all kinds of movies they love. You’ll find people talking just as excitedly about big-name movies like “Interstellar” and “Parasite” as they are about less mainstream ones like “Hereditary” and “The Thing.”\n\n\nSentiment Over Stars: Rethinking Movie Reviews\nInstead of just counting how many thumbs up or stars a movie gets, a deeper look into Rotten Tomatoes reviews was taken to really understand how people feel about these movies. The goal was to figure out the general mood of the reviews — are people happy or unhappy with the movie? From this, a new kind of movie rating was made that doesn’t just look at how many people liked the movie, but also how strongly they felt about it.\n\nFigure-1 (a)Figure-1 (b)\n  \n      \n      \n  \n  \n      \n      \n  \n  \n    \n      Figure-1: Comparative Visualization of Top 10 Suggested Movies on Reddit - 1(a) shows the list of movies while the 1(b) depicts their review ratings\n    \n  \n\n\nInsights\nThe study found out that the movies people talk about on Reddit aren’t always the ones with the highest scores from professional reviewers. Movies that get people talking, like “Hereditary,” seem to hold a special place in Reddit users’ hearts. It shows that on Reddit, what really matters is how much a movie gets people to talk and think, and how it connects with them on a personal level.\nReddit is a place where the charm of a movie comes from many different things. It could be how well it tells its story, how much it makes people feel, or even how it fits in with what’s happening in the world. Reddit users love to find and talk about movies that mean something special to them — whether they’re indie films with a powerful message or big spectacles with lots of special effects.\nThis look into Reddit shows how online communities are changing the game when it comes to what makes a movie worth recommending. It’s not just about how many people say a movie is good; it’s also about the discussions and connections that movies start among viewers.\n\n\n\nDiving Into Anime Favorites\nAfter taking a close look at movie trends, the same curiosity was turned toward anime. The goal was to see which anime series are getting buzz on Reddit. Just like with movies, the chatter on Reddit was matched with reviews from MyAnimeList, a popular anime community site.\nFirst, a list of the most-recommended anime on Reddit was made. It showed which anime series are getting the most love and suggestions from the Reddit crowd.\n\n\nDiscovering Anime Hits and Hidden Gems\nThe top ten anime picks on Reddit were spotlighted in a graphic that looked like a target with bars pointing outwards. The longer the bar, the more people were talking about that anime. “Shingeki no Kyojin,” known as “Attack on Titan,” was a clear favorite, getting the most mentions. Other favorites included “Steins;Gate” and “Code Geass,” which also saw a lot of recommendations. Even lesser-known series like “Made in Abyss” got a spot on the chart, proving that Reddit users have a wide range of interests.\n\n\nPopularity vs. Praise\nAn interesting trend emerged: the anime that were most popular didn’t always line up with the ones that got the best reviews. This showed that what people watch and talk about isn’t just about how good critics say it is. It’s also about what stories grab them, which characters they can’t forget, and how the anime fits into the culture at large.\n\n \n          \n            \n            Figure-2 (a)\n          \n          Figure-2 (b)\n  \n      \n  \n  \n      \n      \n  \n  \n    \n      Figure-2: Comparative Visualization of Top 10 Suggested Anime on Reddit - 2(a) shows the list of anime while the 2(b) depicts their review ratings\n    \n  \n\n\nInsights\nIn drawing conclusions from this exploration into anime’s popularity, it becomes evident that platforms like Reddit play a pivotal role in shaping how anime is perceived and appreciated. Here, the measure of an anime’s success transcends traditional critical ratings. It’s not just about the numbers or accolades it receives; instead, it hinges on the stories that linger in the minds of viewers, the characters that become almost real to them, and the emotional journeys these series facilitate.\nAnime series that might not top the critics’ charts have nonetheless carved out their niches within online communities. They initiate discussions, spark debates, and often lead to the formation of dedicated fanbases. These are the shows that might not headline major anime conventions or feature prominently on award lists, but they inspire art, fan fiction, and deep discussions about themes and character development.\nThis phenomenon underscores a unique aspect of cultural consumption in the digital age. Communities like Reddit become melting pots of diverse opinions and tastes, where an anime’s worth is gauged not just by its technical excellence or narrative perfection but by its ability to connect, resonate, and stay relevant in the fast-paced online discourse.\n\n\n\n\nConclusion: The Heart of Storytelling in Movies and Anime on Reddit\nThe insights gathered from this exploration into movies and anime reveal a fascinating shift in how stories are valued and appreciated, especially in online communities like Reddit. In these digital spaces, a film or anime series’ appeal isn’t solely measured by the scores it gets from critics. Instead, it’s about the conversations they spark, the emotions they stir up, and the connections they forge with their audience.\nMovies that stir up lively discussions, such as “Hereditary,” have a unique place in the hearts of Reddit users. It’s not just about being a blockbuster hit or having stunning visuals; it’s about how a story makes people think, feel, and relate to each other. These movies become more than just entertainment; they’re catalysts for conversation, thought, and sometimes, even change.\nSimilarly, in the world of anime, success on Reddit goes beyond traditional ratings. The most talked-about series aren’t always the ones that win awards or get perfect scores. They’re the ones that stay with viewers long after the screen goes dark, with characters and narratives that resonate on a deeply personal level. These series often spark in-depth discussions, fan creations, and strong communities of followers who find something special in their stories.\nBoth these analysis highlight a broader trend in the digital age: the true value of a movie or anime isn’t just in its technical achievements or expert reviews, but in its power to connect with people. In online forums like Reddit, a diverse tapestry of opinions and tastes comes together, making room for different kinds of stories to be discovered, discussed, and cherished.\nThis shift underscores the evolving nature of storytelling and audience engagement. In a world where traditional metrics of success are increasingly intertwined with digital discourse, platforms like Reddit are proving to be crucial spaces where the cultural significance of movies and anime is being redefined. Here, the impact of a story is measured not just in ratings or box office numbers, but in the richness of the discussions it inspires and the community it builds."
  },
  {
    "objectID": "nlp.html",
    "href": "nlp.html",
    "title": "Natural Language Processing - Technical Analysis Report",
    "section": "",
    "text": "Comprehensive Analysis Report on Reddit Discussions: Unveiling Trends in Movie Popularity\nThis analysis aims to discern prevailing trends in Reddit discussions related to movies. The primary goal is to compile a dataset featuring the most talked-about movies on the platform. Subsequently, this dataset will be cross-referenced with our external review data, particularly from platforms like Rotten Tomatoes. The objective is to determine if movies generating the most buzz on Reddit also receive positive critical acclaim or exhibit differing evaluations.\nBefore delving into detailed text cleaning processes, we conducted a preliminary analysis encompassing both movie and anime-related Reddit communities. Our overarching goal is to ultimately provide insights on Movies, Anime, and TV shows. In this initial phase, we performed a word count analysis on submissions from both movie and anime Reddits. Below are the top words identified, accompanied by their respective counts:\n\n \n\n  \n  Table-1: Count of words for movies\n\n\n \n\n  \n  Table-2: Count of words for anime\n\n\nThis initial exploration has revealed that discussions on Reddit heavily revolve around users’ favorite anime and movies. To gain deeper insights, our next step involves analyzing the comments more comprehensively to extract the specific names of the most-discussed movies and anime. By doing so, we aim to identify the titles that resonate most strongly within the community, shedding light on the exceptionally popular content among Reddit users.\nIn our analysis of Reddit comments related to movies, we initially employed TF-IDF vectorization on a DataFrame containing cleaned and tokenized text. While TF-IDF is a powerful technique for understanding the significance of words within individual documents relative to the entire dataset, its application in our specific context has revealed limitations.\nTF-IDF is inherently designed to highlight the importance of words in a document set, but its utility in extracting specific movie and anime references from Reddit comments appears to be constrained. Our objective is to identify and extract the most discussed or mentioned movie and anime titles, and for this purpose, alternative methods may prove more effective.\n\n\n\nFigure-1: Example of TF-IDF output\n\n\nRecognizing the unique nature of our analysis, we have decided to explore alternative approaches that directly cater to the extraction of movie and anime references from Reddit comments. This strategic shift is grounded in the understanding that while TF-IDF is valuable for certain tasks, it may not be the optimal choice for our current goal of pinpointing and analyzing explicit references to movies and anime in the Reddit data.\nBy adopting alternative methods tailored to our specific objective, we aim to enhance the precision and relevance of our analysis, ensuring a more effective exploration of the most discussed titles within the Reddit community. This adaptive approach aligns our methodology with the intricacies of the content present in Reddit comments, optimizing our ability to uncover and analyze meaningful movie and anime references.\n\n\nIdentifying Top Reddit-Recommended Movies\nThe social platform Reddit is a treasure trove of public opinion and preferences, particularly when it comes to movie recommendations. To extract the movies, we’ve implemented a data extraction and analysis pipeline to identify the most frequently suggested movies across various Reddit threads.\n\n\n\n\nFigure-2: Workflow Pipeline for Extracting Movie and Anime Suggestions from Reddit data\n\n\nMethodology:\n\nNamed Entity Recognition (NER): NER was applied to extract movie titles from unstructured text in Reddit discussions.\nPattern Matching: Further refinement was achieved through pattern matching techniques to ensure accurate identification of movie titles.\nContext Analysis: The context surrounding extracted entities was analyzed to validate the relevance of identified movie titles.\nExplode and Aggregate: The data was transformed through the “explode” operation, breaking down entries into individual suggestions. Aggregation techniques were then employed to count the occurresnces of each movie title, providing a quantitative measure. We initiated the process by collecting Reddit posts from threads likely to contain movie suggestions. This involved utilizing Reddit’s API to fetch posts from subreddits renowned for movie discussions. Upon retrieval, the posts underwent a standard preprocessing stage, which included lowercasing, tokenization, and the removal of stop words and punctuation. This step was crucial to prepare the text data for more sophisticated natural language processing (NLP) tasks.\n\nNamed Entity Recognition (NER) The cleansed text data was then processed through a Named Entity Recognition (NER) model. NER is an NLP technique that automatically identifies and classifies key information in text, such as the names of people, places, and, pertinent to our task, movies. We utilized a pre-trained NER model tailored to recognize movie titles within a larger corpus.\nText Processing Workflow\n\nDocument Assembler: The initial step involves converting each comment text into a structured document format. This process, facilitated by a Document Assembler, lays the foundation for a systematic and organized analysis.\nSentence Detector: Following document structuring, the content is segmented into sentences using a Sentence Detector. This step is crucial for breaking down the textual information into manageable units, preparing it for more granular analysis.\nTokenization: Tokenizer: Sentences are further deconstructed into individual tokens using a Tokenizer. This process is integral to understanding the intricacies of the text at a word level, facilitating a nuanced examination of user comments.\nWord Embeddings Model (glove_100d): To transform tokens into numerical vector representations, we employ a Word Embeddings Model, specifically glove_100d. This model captures semantic relationships between words, enabling a more profound analysis of the comment text.\nNERDL Model (ner_dl): The identified vectors undergo Named Entity Recognition using an advanced NERDL model. This step involves classifying entities within the vectors, distinguishing elements such as persons, organizations, and locations, contributing to a richer understanding of the comment content.\nEntity Chunking: Identified entities are then intelligently grouped into coherent chunks using a NER Converter. This chunking process enhances the organization and structure of the information, revealing patterns and relationships within the identified entities.\nSuggestion Extraction using User Defined Function (UDF): Focusing on entities classified as “PERSON” and “ORG,” a User Defined Function (UDF) is applied to extract suggestions from the identified chunks. This step allows for the extraction of meaningful insights related to individuals and organizations mentioned in the comments.\n\nPattern Matching In parallel to NER, we employed pattern matching algorithms to capture movie mentions that might not be recognized by NER. Pattern matching utilized a combination of keyword searches and lexical patterns that are commonly associated with movie titles.\n\nCommon Pattern Identification: Utilizing a Regex pattern (pattern = r’(?:“([^\"]+)”|([A-Z][a-z](?:+(?:[a-z]++)[A-Z][a-z]))(?: )?)’), we embark on identifying common patterns within the dataset. This pattern is designed to capture both quoted phrases and properly formatted movie titles with their release years.\nData Refinement using User Defined Functions (UDFs):Stopwords and Single-Letter,Movies Removal Stopwords Exclusion UDF: Applying a User Defined Function (UDF), we meticulously remove movies that consist solely of stopwords. This ensures that the dataset is refined to exclude movies with minimal informational content. Single-Letter Movies Exclusion UDF: Another UDF is employed to eliminate movies with only a single letter in their titles. This step is crucial for maintaining the integrity of the dataset by filtering out entries that may not contribute substantial information or context.\n\nContext Analysis To refine the results further, context analysis was performed. This method assessed the surrounding text of potential movie titles to discern whether the mention was indeed a suggestion. For example, phrases like “I recommend” or “you should watch” preceding a movie title indicated a suggestion.\nData Transformation The identified movie titles were transformed into a structured format suitable for analysis. The transformation involved “exploding” lists of movies found in individual posts into separate records to facilitate counting.\nAggregation Finally, we aggregated the results by counting the frequency of each unique movie title across the dataset. This step was implemented using group-by operations that tallied the number of suggestions per movie. The aggregation stage culminated in a ranked list of movies by the number of times they were suggested. This ranked list provided clear insights into the most popular movie recommendations on Reddit.\n\n\n\nFigure-3: Plot showing the top 10 suggested movies on reddit\n\n\nUpon analyzing user recommendations on Reddit, “Hereditary” stood out as the most frequently suggested movie. This observation prompted us to delve deeper into whether these highly recommended films were not only popular among users but also well-received in terms of positive sentiment.\nTo assess this, we turned to the extensive review data available on Rotten Tomatoes. Our goal was to determine if the movies recommended on Reddit also lay up high ratings and positive sentiments from critics and audiences alike. To achieve this, we conducted sentiment analysis on the review data, calculating sentiment scores for each film.\nThe sentiment analysis allowed us to quantify the balance between positive and negative sentiments expressed in the reviews. Subsequently, we devised a comprehensive rating metric that considered both the sentiment scores and overall sentiment polarity. This approach aimed to provide a nuanced understanding of how well-received the movies were, beyond conventional rating systems. By correlating the recommendations from Reddit with sentiment scores and ratings on Rotten Tomatoes, our analysis sought to reveal whether the most suggested movies on the platform not only captured the attention of users but also resonated positively with a broader audience, shedding light on the intersection of user preferences and critical acclaim.\n\n\nSentiment Analysis of Rotten Tomatoes Movie Reviews: Insights and Trends\n\nOur journey into sentiment analysis commenced with the comprehensive collection of review text for every movie listed on Rotten Tomatoes. This comprehensive dataset was the foundation for our analysis, containing a wide range of opinions from both expert critics and a variety of moviegoers.\n\n\n\nFigure-4: Workflow Pipeline for Sentiment Analysis on movie and anime reviews.\n\n\nData Cleaning Process\nDocument Conversion: To impart structure to the amassed review text, we employed a sophisticated Document Assembler. This transformative step converted the initially unstructured reviews into a meticulously organized format, laying a robust foundation for the subsequent analytical stages.\nTokenization: Embracing the power of a Tokenizer, we meticulously dissected the reviews into individual tokens. This intricate segmentation allowed us to discern the nuanced intricacies within each review, enabling us to capture the essence of expressed opinions at a remarkably granular level.\nNormalization: In pursuit of data uniformity, we judiciously normalized all tokens to lowercase using a specialized Normalizer. This meticulous adjustment eradicated potential inconsistencies stemming from variations in letter case, fostering a standardized dataset primed for in-depth analysis.\nLemmatization: Elevating the sophistication of our understanding, a Lemmatizer Model was applied to refine the reviews further. This process intelligently reduced words to their base root form, amplifying the model’s capability to grasp the fundamental meaning and sentiment intricately woven into each review.\nData Transformation: The meticulously processed data underwent a transformative phase, transitioning into a human-readable format facilitated by a Finisher. This critical step enhanced the interpretability of the dataset, setting the stage for subsequent insightful analyses.\nSentiment Analysis:\nDocument Structuring: The pre-processed data was once again converted into a structured document format, preparing it for the advanced stages of sentiment analysis.\nSentence Embeddings: Using the capabilities of the tfhub_use model, we converted the documents into numerical sentence embeddings. This step facilitated a deeper understanding of the semantic content within each review, capturing the intricacies of expressed opinions.\nSentiment Inference: Leveraging the power of the Sentiment DL Model (specifically, sentimentdl_use_twitter), we determined the sentiment of each review. Trained on diverse data, this model enabled precise inference, categorizing sentiments as positive or negative.\nTo refine the sentiment-based rating system, we’ve established a more nuanced metric known as the Weighted Rating (WR). This formula adjusts the movie rating by considering both the volume and the sentiment of the reviews. Here’s how the Weighted Rating is calculated:\n\\[\nWeighted Rating (WR) = \\frac{v}{v + m} \\times R + \\frac{m}{v + m} \\times C\n\\]\nWhere:\n\nWR is the Weighted Rating.\nR is the average sentiment rating of the movie.\nv is the number of reviews for the movie.\nm is the minimum number of reviews required for the movie to be considered in the rating system.\nCis the mean sentiment score across all movies included in the report.\n\nFor this calculation, we differentiate between positive and negative sentiment scores. These scores reflect the average sentiment of all reviews that were classified as positive or negative, respectively. This distinction allows for a more detailed sentiment analysis in our rating system.\nThe mean score of positive sentiment, if ‘C_positive’, is approximately 0.7526, suggesting that on average, movies receive favorable reviews. Conversely, the mean score of negative sentiment, C_negative, is approximately 0.2474, indicating a smaller proportion of reviews are negative. The median number of reviews required, m , is set to 4 but can be adjusted to fit different criteria or data sets.\nIn the data processing phase, we add two new columns to our data frame:\n\npositive_weighted_rating_df: This column applies the Weighted Rating formula using the average positive sentiment score for each movie, coupled with the mean positive sentiment score across the dataset.\nnegative_weighted_rating_df: Similarly, this column uses the average negative sentiment score for each movie, integrated with the mean negative sentiment score across the dataset.\n\nBy applying these formulas, we generate a Weighted Rating for each movie that reflects not only the average sentiment of its reviews but also how that sentiment weighs against the broader context of all movies in the report. This approach yields a more balanced and contextualized sentiment rating, distinguishing between movies with a strong consensus of opinion and those with more divided sentiment, regardless of whether that sentiment is positive or negative.\nDisplayed below is a comparative graph that delineates the top 10 movies with the highest positive sentiment ratings along with the top 10 movies with the highest negative sentiment ratings.\n \n\n  \n  Figure-5: Bar graph showing the ratings of top 10 movies with highest positive sentiments\n\n\nThe graph presents a selection of the most critically acclaimed films, each of which boasts a remarkable rating exceeding 9.5 on Rotten Tomatoes. These ratings, derived from aggregated critic reviews, underscore a near-unanimous consensus on the exceptional quality of these films, marking them as standout choices for audiences seeking the finest in film entertainment.\n \n\n  \n  Figure-6: Bar graph showing the ratings of top 10 movies with highest negative sentiments\n\n\nThe graph above inversely illustrates the relationship between high negative ratings and the prevalence of negative reviews. In this context, a higher rating corresponds to a greater proportion of negative feedback. The chart specifically spotlights the movies that have received the lowest ratings on Rotten Tomatoes, showcasing those that have, unfortunately, not resonated well with critics and audiences alike.\nThrough a comprehensive sentiment analysis conducted on the entire dataset, we have been able to distill the films that polarize opinion to the most and least favorably received. This analysis provides insightful contrasts, highlighting not only the critically acclaimed successes but also those films that have elicited less favorable reactions, offering a holistic view of the cinematic landscape as reflected in Rotten Tomatoes’ extensive review compendium.\nThe graph below combines two pieces of information: which movies are most often recommended on Reddit, and what reviewers think of them. By bringing these two sets of data together, we can see not just which movies are popular to suggest, but also how well they are received based on their review scores. This way, we get a clearer picture of the most talked-about movies and whether the buzz around them is positive or not.\n\n\n\nFigure-6: Plot showing the review ratings for the top 10 suggested movies on reddit\n\n\n\nAnalysis\nOur analysis reveals an intriguing aspect of movie recommendations and ratings. While some films are frequently suggested by people, their ratings do not always align with this high level of recommendation. For instance, ‘Hereditary’, ‘Alien’, and ‘Oldboy’ are often brought up in discussions and recommended, yet their ratings, although positive, aren’t exceptionally high. This discrepancy highlights a deeper layer of audience engagement.\nIt suggests that these movies have a unique appeal that resonates with viewers on a level beyond conventional ratings. Perhaps these films offer a distinctive storyline, groundbreaking cinematography, or memorable performances that deeply impact viewers, making them popular recommendations despite not having top-tier ratings. This phenomenon underscores the idea that the true value of a movie in the eyes of its audience can extend beyond numerical ratings and delve into more subjective, personal experiences. These films evidently have a special place in the hearts of their viewers, indicative of a more profound connection that transcends traditional rating metrics.\nOn platforms like Reddit, movie recommendations go beyond just highly-rated films. The reasons people suggest movies here are varied - it could be because of the film’s artistic quality, unique story, cultural significance, or how it emotionally connects with certain audiences. This mix of opinions leads to a deeper and more personal way of appreciating movies. It’s not just about what’s popular or critically acclaimed. These online communities are great for discovering lesser-known films that have special qualities appealing to different people.\n\n\n\nExploring Anime Recommendations: A Comparative Study\n\nAfter analyzing movie data and their reviews, we applied the same approach to Anime by examining discussions on Reddit and gathering review data from MyAnimeList. We used the same techniques, like identifying names using Named Entity Recognition (NER), and analyzing discussion patterns and context, to find out which Anime are most talked about on Reddit. This method can be used for any type of entertainment discussed on Reddit, as long as we can find external review data to compare it with.\nOnce we gathered the anime list, we focused on identifying the top 10 anime that are most frequently recommended on Reddit. This helped us pinpoint which anime series are particularly popular and highly recommended within the Reddit community.\n \n\n  \n  Figure-7: Radial bar chart representing top 10 suggested anime on Reddit\n\n\nThe graph displays a radial bar chart. Each radial bar corresponds to a specific anime title, and the length of the bar represents the frequency of suggestions on Reddit. The longest bar points towards “Shingeki no Kyojin,” indicating that this anime is the most suggested among the ones listed. Other notable titles include “Steins;Gate” and “Code Geass,” which also have long bars, showing that they are highly recommended within the Reddit community as well. The shortest bars, corresponding to titles like “Meido in Abisu” (likely “Made in Abyss”) and “Monsuta” (“Monster”), suggest that while these series are still among the top 10 suggested, they are recommended less frequently than the others.\nAfter gathering the external review data, we conducted a detailed analysis to uncover various insights about anime preferences. We categorized the highly rated anime based on their genres, pinpointing which types of anime received the best reviews. Additionally, we identified the most popular anime within each genre, giving us an understanding of which styles and stories resonate the most with audiences.\nWe didn’t stop there; we also looked at the overall ratings across all genres to determine which anime series stood out in terms of viewer ratings. By doing this, we created a picture of anime popularity and quality, segmented by genre and overall reception.\n \n\n  \n  Figure-8: Bar graph showing the ratings of top-rated anime titles across all genres.\n\n\nThe above graph visualizes the top-rated anime movies across various genres based on their scores. The bar graph shows a distribution of scores for each anime title, with the rating ranging from 9.00 to 9.23. The color scale, ranging from light to dark shades, emphasizes the rating, providing a visual representation of the rating intensity.\nTitles like “Fullmetal Alchemist Brotherhood,” “Hunter x Hunter 2011,” and “SteinsGate” stand out as the top-rated anime. These titles have achieved exceptionally high rating, indicating their widespread acclaim among viewers. The graph provides additional information upon hovering over the bars, including the title, rating, and associated genres. This interactive feature allows users to explore details for each anime. We further wanted to expand this analysis, by highlighting the frequency of specific genres within the top-rated titles.\n \n\n  \n  Figure-9: Plot showing the distribution of genre across top-rated anime titles.\n\n\nThe above graph visualizes the distribution of genres among the top-rated titles. Looking at the graph, it’s evident that certain genres are more prevalent among the top-rated anime, particularly Youth and School Life and Drama and Romance tend to be more prevalent among the top-rated anime titles,indicating a significant audience preference for stories revolving around school life and romantic dramas, possibly due to relatable themes or engaging narratives within these genres. The diversity of genres also demonstrates the varied tastes and interests of anime enthusiasts.\n \n\n  \n  Figure-10: Bar graph showing top 10 highly rated anime by genre\n\n\nThe above graph serves as an interactive tool to navigate through the most celebrated anime series, organized by genre, with a selection of 10 distinct genres.\nIt’s worth noting that some anime series have a multifaceted appeal, crossing over into multiple genres. Consequently, these versatile shows appear in several genre categories within the graph. This frequent occurrence among the top-tier anime suggests that the most acclaimed series often blend elements from different genres, enhancing their richness and broadening their appeal. The graph’s design likely accounts for this overlap, ensuring that each anime is represented in all the genres it’s associated with, providing a thorough and accurate representation of the anime landscape as per the genre classifications.\nTo see the most Popular Anime across each Genre we used popularity score in the dataset to get the anime list popular across different genres.\n \n\n  \n  Figure-11: Bar graph showing top 10 popular anime by genre\n\n\nThe data reveals an interesting distinction between the highest-rated anime and those that are most popular. Some shows that didn’t make it to the ‘top anime’ list based on ratings have found a spot on the ‘most popular’ list. This discrepancy highlights a key insight: an anime’s popularity doesn’t always correlate with its critical ratings.\nThese popular anime, sourced from MyAnimeList, resonate with a large audience, perhaps because of their engaging storylines, memorable characters, or cultural impact, despite not necessarily receiving the highest scores in reviews. This aspect of popularity, separate from critical acclaim, captures the essence of what viewers are actually watching and talking about.\nIn the next step of our analysis, we’ll compare this popularity data from MyAnimeList with the Reddit suggestions data. This comparison will further our understanding of viewer preferences and show how anime trends on Reddit align with the broader viewership statistics from MyAnimeList. Through this, we aim to uncover whether the anime that sparks the most conversation on Reddit are also the ones that are being watched the most according to MyAnimeList’s popularity metrics.\n\nMoving forward with our analysis, we aim to bridge the gap between recommendation frequency on Reddit and the critical reception of those recommended titles. To facilitate this, the subsequent graph has been crafted to showcase the review ratings of the anime that have been most frequently suggested on Reddit.\n\n\n\nFigure-12: Plot showing the review ratings for the top 10 suggested anime on reddit\n\n\nThe analysis of the anime series reveals a pattern similar to that observed with movies: being highly rated across various genres does not necessarily equate to being frequently suggested on Reddit. While a select few anime achieve high ratings and are still often recommended, it appears that this is not the norm for most.\nThis consistent observation underscores a unique aspect of community-driven platforms like Reddit. Certain anime series may not receive the highest accolades from critics or achieve top scores in every genre, yet they cultivate a dedicated following and generate significant buzz on Reddit. These shows may possess certain qualities—such as compelling storytelling, niche appeal, or a loyal fanbase—that endear them to viewers, making them popular in discussions even if they are not universally acclaimed.\nThis phenomenon highlights that some shows are underrated gems, whose value is recognized and celebrated within the Reddit community. Their popularity on such social platforms suggests that there are additional layers of appreciation and enjoyment that standard rating systems may not fully capture. These series resonate with the audience in a way that transcends conventional rankings, cementing their place in the cultural conversation on platforms like Reddit."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysis on Entertainment Reddits",
    "section": "",
    "text": "Introduction\nReddit functions as a massive virtual gathering where individuals from diverse backgrounds come together to share their stories, photos, and ideas within specialized communities called subreddits. Examining graph 1 below confirms Reddit’s popularity in major places like the USA, Canada, the UK, India, and more, where people engage in diverse conversations and shape the platform by voting on content, creating a dynamic and human-driven experience that mirrors the diversity of our online world. Plus, looking at graph 2 below, it’s safe to say that a lot of Reddit users are from Gen Z – that’s the young crowd. According to the blog, Entertainment is among the top indexing interest groups for Gen Z on Reddit. And since movies, TV series, and anime are often made with them in mind, we thought it’d be cool to take a closer look at what people are posting and talking about on Reddit’s big entertainment spots: the movies, television, and anime subreddits.\n\n\n\n\n\n\ngraph 1 source: link\n\n\n\n\n\n\n\ngraph 2 source: link\n\n\n\n\n\nAdditionally, we were curious about what regular folks on Reddit think about the movies, television, and anime compared to what the professional critics say. For this purpose, we combined external dataset which we will discuess about in more detail in our next section.\nNow, let’s explore the key subreddits central to this project: r/anime, r/television, r/televisionsuggestions, r/movies, r/Animesuggest, and r/MovieSuggestions.\n\nr/anime: This subreddit is dedicated to anime-related discussions, encompassing a wide range of topics, including reviews, recommendations, and general discourse about the anime medium.\nr/television: This subreddit caters to discussions about television shows, spanning various genres and formats. Users engage in conversations about current and past TV series, share recommendations, and discuss industry news.\nr/movies: This subreddit covers a wide range of topics related to films, including discussions about specific movies, industry news, and analyses of cinematic techniques.\nr/Animesuggest: Similar to r/televisionsuggestions but for anime, this subreddit is dedicated to helping users discover new anime titles based on their preferences.\nr/MovieSuggestions: Serving as a space specifically for movie recommendations, this subreddit is an ideal place for users seeking personalized suggestions for their next film to watch.\nr/televisionsuggestions: As a subreddit dedicated explicitly to TV show recommendations, this community serves as a hub for users seeking and providing suggestions for what to watch next.\n\nOur analysis delves into these subreddits, aiming not just to observe trends but to uncover the rhythms, blending data science techniques, visualizations, and machine learning to understand user sentiments and interactions.\n\n\n\n\n\n\n\nData Overview\nDiving into a whopping 412 GB of posts and 918 GB of comments, the dataset is like a big storybook with 109 million entries. It’s carefully organized by simplifying things—removing some details, changing time info to something we can understand, and putting it in a format that’s easy to explore, like preparing a canvas before painting. Now, it’s all set up and ready for us to start looking through and discovering what’s inside.\nExternal dataset: The project utilizes datasets from Kaggle’s “Clapper: Massive Rotten Tomatoes Movies and Reviews” and “MyAnimeList” collections. These datasets offer a rich source of information for analyzing trends, preferences, and sentiments in the domain of movies and anime. This approach aims to delve into the intricacies of viewer engagement and sentiment patterns across diverse content genres, providing a comprehensive understanding of audience behavior in the entertainment industry.\nThe Rotten Tomatoes dataset offers a detailed compilation of movie reviews and ratings, while the MyAnimeList dataset provides insights into anime popularity and viewer preferences. Together, these datasets form a robust foundation for cross-platform analysis.\nData Source 1 Data Source 2\n\n\nObjective\nOur mission is clear: to decipher the language of entertainment discussions on Reddit, extracting findings that resonate with both seasoned enthusiasts and those new to the subject matter. We will focus on the first two objectives — revealing what the data says and interpreting its significance by providing answers to the following questions.\n\nBusiness Goal: Optimize content strategy by understanding peak engagement times. Knowing when users are most active can guide when to post for maximum visibility and interaction.\nTechnical Proposal: Using EDA, we will conduct a time series analysis on the hour_of_day and day_of_week_str data for each subreddit. By aggregating post frequencies based on these time variables, we can visualize trends and identify peak activity periods. This analysis will provide insights into the most favorable times to post content on each subreddit, helping optimize the content strategy for enhanced user interaction and visibility.\nBusiness Goal: Identifying key contributors to help recognize influential users and understand their content preferences. This insight is valuable for community management and targeted marketing strategies.\nTechnical Proposal: Using EDA, analyze author data to quantify post frequency and engagement (likes, comments). Apply statistical measures to highlight top contributors and content analysis to understand the themes and types of their posts.\nBusiness Goal: This seeks to understand how the content influences user engagement, guiding content creators on the most engaging content.\nTechnical Proposal: Using EDA, we will compare the average score and number of comments between posts with different content using statistical methods.\nBusiness Goal: To Understand popular themes that can guide content creation and marketing strategies, ensuring alignment with audience interests.\nTechnical Proposal: Applying NLP techniques like topic modeling or keyword extraction to the titles and selftext of high-engagement posts. This analysis will identify prevalent themes and topics in popular content.\nBusiness Goal: Gauging the overall sentiment of posts in each subreddit to inform tone and messaging strategies for engaging with these communities effectively.\nTechnical Proposal: Performing sentiment analysis on the title and selftext of posts. This involves using NLP tools to classify content into sentiment categories (positive, negative, neutral) and comparing these across subreddits.\nBusiness Goal: Identifying unique lexicon can aid in creating more relatable and targeted content for each subreddit community.\nTechnical Proposal:Use TF-IDF analysis to distinguish words and phrases that are uniquely prevalent in each subreddit. This helps in understanding the distinctive language style of each community.\nBusiness Goal: Understanding how sentiment affects engagement can help in tailoring content for better reception and interaction.\nTechnical Proposal: Combine sentiment analysis results with engagement metrics (score, comments) to explore correlations. This involves statistical analysis to determine if there’s a significant relationship between sentiment and user engagement.\nBusiness Goal: This prediction model can guide content creators in optimizing their posts for higher engagement, leading to increased visibility and interaction.\nTechnical Proposal: Developing a predictive model using features like post length, presence of media, time of posting, and NLP-derived text features. Machine learning techniques like regression or classification can be employed to forecast engagement levels.\nBusiness Goal: Predicting posting time based on content can assist in understanding user behavior patterns and content preferences at different times.\nTechnical Proposal: Creating a model to predict the likely time of posting using features extracted from post content and style. This involves applying classification algorithms to correlate content features with posting times.\nBusiness Goal: Efficiently categorizing posts can aid in content moderation and ensure appropriate audience targeting.\nTechnical Proposal: Use text data and other relevant features to train a classification model that can distinguish between adult-oriented and general audience content. This involves using NLP techniques for feature extraction and applying classifiers like SVM or logistic regression."
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "",
    "section": "",
    "text": "conclusion"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "Hello and welcome!\nLorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry’s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\nContrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of “de Finibus Bonorum et Malorum” (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, “Lorem ipsum dolor sit amet..”, comes from a line in section 1.10.32.\nThe standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from “de Finibus Bonorum et Malorum” by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham."
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Anime and Movies: Machine Learning Classification of Subreddits\n\nFeature Engineering\nThe initial step in the data preprocessing pipeline involved enhancing the dataset with new features that could be crucial for the classification of Reddit posts.\nPost Length Calculation The total length of each post was calculated by summing the lengths of the post’s title and text.\nTime-Based Feature Extraction Time-related features were extracted from the ‘created_utc’ timestamp. These included the hour of the day, day of the week, day of the month, month, and year.\nMedia Presence Identification A boolean feature ‘has_media’ was created to indicate whether a post contains media.\nFeature Selection The dataset was refined to include only relevant features for the classification task, ensuring a focused and efficient modeling process.\n\n\nText Preprocessing\nTextual data from Reddit posts underwent several preprocessing steps to standardize and prepare it for machine learning analysis.\nCombining Text Fields The ‘title’ and ‘selftext’ fields were combined into a single ‘body’ text field, consolidating all textual information into one comprehensive feature.\nHandling Missing Values Rows with missing ‘domain’ values were removed to maintain data integrity and consistency.\nText Normalization The ‘body’ text was converted to lowercase, and newline characters and punctuations were removed. This normalization is crucial for reducing the complexity of text data, facilitating more effective machine learning analysis.\n\n\nText Vectorization\nThe processed text data was transformed into a numerical format suitable for machine learning models.\nTokenization and Stop Words Removal The body text was tokenized into individual words, and common stop words were removed to emphasize more meaningful content.\nFeature Vector Creation The HashingTF method was utilized to convert the processed text into numerical feature vectors. The IDF (Inverse Document Frequency) was applied to rescale these vectors, highlighting significant terms for differentiating between ‘Anime’ and ‘Movies’.\n\n\nFinal Data Preparation\nThe concluding steps in data preparation involved schema adjustments and data type conversions, optimizing the dataset for the modeling stage.\nSchema Adjustment and Cleanup: Unnecessary columns were removed from the dataset, and the final schema was verified to include only pertinent features.\nData Type Conversion: Boolean columns were cast to strings to align with the requirements of the machine learning algorithms in the subsequent stages."
  },
  {
    "objectID": "ml.html#anime-and-movies-machine-learning-classification-of-subreddits",
    "href": "ml.html#anime-and-movies-machine-learning-classification-of-subreddits",
    "title": "Machine Learning",
    "section": "Anime and Movies: Machine Learning Classification of Subreddits",
    "text": "Anime and Movies: Machine Learning Classification of Subreddits\nIn the vast and ever-expanding universe of Reddit, where countless subreddits coexist, the ability to classify posts accurately is crucial for both content curation and user experience. By distinguishing between ‘Anime’ and ‘Movies’ - two distinct categories with passionate followings - this classification project aims to streamline content discovery, enhance recommendation algorithms, and foster community engagement. As users navigate through the platform, accurately categorized posts ensure that they find the content that resonates with their interests swiftly. For content moderators and advertisers, such classification provides a clear understanding of discussion trends and audience preferences, enabling more targeted and effective engagement strategies. Ultimately, this machine learning endeavor seeks to contribute to a more personalized, organized, and engaging Reddit experience for every user.\n\nData Cleaning\nFeature Engineering\nThe initial step in the data preprocessing pipeline involved enhancing the dataset with new features that could be crucial for the classification of Reddit posts.\nPost Length Calculation The total length of each post was calculated by summing the lengths of the post’s title and text.\nTime-Based Feature Extraction Time-related features were extracted from the ‘created_utc’ timestamp. These included the hour of the day, day of the week, day of the month, month, and year.\nMedia Presence Identification A boolean feature ‘has_media’ was created to indicate whether a post contains media.\nFeature Selection The dataset was refined to include only relevant features for the classification task, ensuring a focused and efficient modeling process.\nText Preprocessing\nTextual data from Reddit posts underwent several preprocessing steps to standardize and prepare it for machine learning analysis.\nCombining Text Fields The ‘title’ and ‘selftext’ fields were combined into a single ‘body’ text field, consolidating all textual information into one comprehensive feature.\nHandling Missing Values Rows with missing ‘domain’ values were removed to maintain data integrity and consistency.\nText Normalization The ‘body’ text was converted to lowercase, and newline characters and punctuations were removed. This normalization is crucial for reducing the complexity of text data, facilitating more effective machine learning analysis.\nText Vectorization\nThe processed text data was transformed into a numerical format suitable for machine learning models.\nTokenization and Stop Words Removal The body text was tokenized into individual words, and common stop words were removed to emphasize more meaningful content.\nFeature Vector Creation The HashingTF method was utilized to convert the processed text into numerical feature vectors. The IDF (Inverse Document Frequency) was applied to rescale these vectors, highlighting significant terms for differentiating between ‘Anime’ and ‘Movies’.\nFinal Data Preparation\nThe concluding steps in data preparation involved schema adjustments and data type conversions, optimizing the dataset for the modeling stage.\nSchema Adjustment and Cleanup Unnecessary columns were removed from the dataset, and the final schema was verified to include only pertinent features.\nData Type Conversion Boolean columns were cast to strings to align with the requirements of the machine learning algorithms in the subsequent stages.\n\n\nData Pre-Processing for Modeling\nString Indexing Key categorical features such as ‘over_18’, ‘is_self’, ‘is_video’, ‘has_media’, and ‘subreddit’ were transformed using StringIndexer. This step converted categorical strings into numerical indices, making them suitable for machine learning models.\nOne-Hot Encoding The indexed categories were further encoded using OneHotEncoder. This process transformed the indexed categories into a binary vector representation, a necessary step for handling categorical data in many machine learning algorithms.\nVector Assembler A VectorAssembler was utilized to combine various feature columns into a single vector column. This included both the newly created feature vectors from one-hot encoding and the existing numerical features such as ‘score’, ‘num_comments’, ‘post_length’, ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’. This assembly created a unified feature vector essential for feeding into the machine learning models.\nPipeline Definition A Pipeline was defined incorporating all the stages of string indexing, one-hot encoding, and vector assembly. This approach streamlined the preprocessing steps and ensured consistency across the data.\nData Split train and test Following thorough data cleansing, the dataset was partitioned into training and testing sets with an 80-20 split.\nPipeline Execution The preprocessing pipeline was applied to the training and test data. This transformed the data according to the defined stages, ensuring that it was ready for model training and evaluation.\n\n\nModel Training and Evaluation\n\nModel Selection\nWe selected a Random Forest classifier to classify between Anime and Movie-related Reddit posts primarily because random first gives highest accuracy among all classification models and its robustness, particularly in scenarios involving large datasets with numerous variables. It can also automatically balance the data.\n\n\nModel Training\nInitially, we opted for simplicity and started with a Random Forest model, using its default parameters. This approach was somewhat like dipping our toes in the water to gauge the temperature. After training, the results we got were quite encouraging - not exactly groundbreaking, but definitely on the right track. This outcome provided a solid foundation for us to build upon and refine our model further.\n\n\n  \n    \n      \n        \n        Figure-1 (a): Confusion Matrix for Default Random Forest Model\n      \n    \n    \n      \n        \n        Figure-1 (b): ROC curve for Default Random Forest Model\n      \n    \n  \n  \n    \n      Figure-1\n    \n  \n\n\n\nThe first try at using a Random Forest classifier to sort Reddit posts into ‘Anime’ or ‘Movies’ was a good start. The model worked alright, as shown by a score of 0.76 out of 1 on a test called the ROC curve, which measures how well the model distinguishes between the two categories. However, the model wasn’t perfect and often mixed up posts, especially mistaking ‘Movies’ posts for ‘Anime’. This tells us that while the model did an okay job, there’s still quite a bit of room to make it better by changing its settings.\nThe first results show that using the basic settings for the model isn’t the best for this job of telling Anime and Movie posts apart. The model could do a much better job if we adjust its settings, like how many decision trees to use, how deep these trees should go, and how many posts it should look at before making a decision. Changing these could make the model much better at correctly identifying posts.\nTo elevate our initial model, we delved into hyperparameter tuning. We experimented with a variety of settings for ‘numTrees’, ‘maxDepth’, and ‘maxBins’, testing different combinations. Ultimately,landed on the configuration that significantly enhanced our model’s accuracy and efficiency: numTrees=100, maxDepth=10, and maxBins=64. The model showed significantly better performance after hyperparameter tuning.\n\n\n  \n    \n      \n        \n        Figure-2 (a): Confusion Matrix for Random Forest Model with Hyper parameters\n      \n    \n    \n      \n        \n        Figure-2 (b): ROC curve for Random Forest Model with Hyper parameters\n      \n    \n  \n  \n    \n      Figure-2\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy Train\nAccuracy Test\nF1 Score Train\nF1 Score Test\nPrecision Train\nPrecision Test\nRecall Train\nRecall Test\n\n\n\n\nRandomForest Default\n0.676\n0.675\n0.642\n0.642\n0.760\n0.760\n0.676\n0.675\n\n\nRandomForest Hyperparameters\n0.760\n0.759\n0.745\n0.744\n0.829\n0.828\n0.760\n0.759\n\n\n\nThe Hyperparameter tuning for the Random Forest classifier yielded a significant improvement in the model’s performance for classifying Reddit posts into ‘Anime’ or ‘Movies’. By adjusting the number of trees (‘numTrees’), the depth of each tree (‘maxDepth’), and the number of bins (‘maxBins’), the model’s ability to correctly identify the categories has been notably enhanced.\nThe confusion matrix post-tuning presents a dramatic decrease in misclassified instances, particularly in distinguishing ‘Movies’ from ‘Anime’. Furthermore, the ROC curve, with an area under the curve (AUC) of 0.95, indicates a superior model performance in differentiating between the two classes as compared to the pre-tuned state, which had an AUC of 0.76. This stark contrast in the AUC values before and after tuning underscores the impact of fine-tuning hyperparameters.\nThe source code for this model can be found here."
  },
  {
    "objectID": "ml.html#predicting-popularity-machine-learning-for-reddit-engagement-analysis",
    "href": "ml.html#predicting-popularity-machine-learning-for-reddit-engagement-analysis",
    "title": "Machine Learning",
    "section": "Predicting Popularity: Machine Learning for Reddit Engagement Analysis",
    "text": "Predicting Popularity: Machine Learning for Reddit Engagement Analysis\nIn the dynamic and diverse ecosystem of Reddit, where every submission vies for attention, being able to predict the popularity of a post holds immense value. The second model in this project endeavors to classify Reddit submissions as ‘popular’ or ‘not popular,’ serving a multitude of purposes. For content creators and marketers, understanding the elements that contribute to a post’s popularity can inform their strategy to capture the community’s interest more effectively. For the average user, this classification can enhance the personalization of their feed, bringing popular, engaging content to the forefront. Additionally, platform moderators can utilize insights from popularity predictions to better manage the influx of content and maintain the quality of user experience. This binary classification model, powered by machine learning, not only aims to decipher the attributes that propel a post to popularity but also to apply this knowledge in a way that enriches the Reddit landscape for all participants.\n\nData Cleaning\nFeature Engineering\nAlong with the existing features, the dataset was enhanced with new features that could be crucial for the classification of Reddit posts.\nTo enhance the accuracy of predicting a post’s popularity, we introduced ‘Sentiment Score’ and ‘Emotion’ as new features, recognizing that the tone and emotional context of a post greatly influence user engagement. The sentiment score captures the overall positivity or negativity of the content, while the emotion feature taps into the specific feelings a post might evoke, both of which are key indicators of a post’s potential to resonate with and captivate the Reddit community.\nSentiment Analysis The ‘body’ text was analyzed using the Spark NLP sentiment analysis model (sentimentdl_use_twitter) to extract sentiment score.\nEmotion Analysis The ‘body’ text was analyzed using the Spark NLP emotion analysis model (classifierdl_use_emotion) to extract different emotions.\nAll the other steps were the same as the above model.\n\n\nData Pre-Processing for Modeling\nTarget Variable Generation The ‘num_comments’ column was used to generate the target variable ‘is_popular’ by applying a threshold of 27 (mean number of comments). Posts with a score of 27 or above were classified as ‘popular’ while those with a score below 27 were classified as ‘not popular’.\nHandling Class Imbalance The dataset was balanced by downsampling the majority class (‘not popular’) to match the minority class (‘popular’).\n\n\n  \n    \n      \n        \n        Figure-3 (a): Target variable Distribution\n      \n    \n    \n      \n        \n        Figure-3 (b): Target variable Distribution after downsampling\n      \n    \n  \n  \n    \n      Figure-3\n    \n  \n\n\nString Indexing Key categorical features such as ‘over_18’, ‘is_self’, ‘is_video’, ‘has_media’, and ‘subreddit’ were transformed using StringIndexer. This step converted categorical strings into numerical indices, making them suitable for machine learning models.\nOne-Hot Encoding The indexed categories were further encoded using OneHotEncoder. This process transformed the indexed categories into a binary vector representation, a necessary step for handling categorical data in many machine learning algorithms.\nVector Assembler A VectorAssembler was utilized to combine various feature columns into a single vector column. This included both the newly created feature vectors from one-hot encoding and the existing numerical features such as ‘sentiment_score’, ‘score’, ‘post_length’, ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’. This assembly created a unified feature vector essential for feeding into the machine learning models.\nPipeline Definition A Pipeline was defined incorporating all the stages of string indexing, one-hot encoding, and vector assembly. This approach streamlined the preprocessing steps and ensured consistency across the data.\nPipeline Execution The preprocessing pipeline was applied to the training and test data. This transformed the data according to the defined stages, ensuring that it was ready for model training and evaluation.\n\n\nModel Training and Evaluation\n\nModel Selection\nFor predicting whether Reddit posts will be popular or not, we started with a simple Logistic Regression model. This model was chosen for its ease of use and good performance with basic yes/no type questions, like predicting if a post will be popular. However, to deal with the large and complex data from Reddit, we later switched to using a Decision Tree classifier. This model is better for handling lots of different factors in the data and makes it easier to understand how it decides if a post will be popular.\n\n\nModel Training\nIn the task of predicting the popularity of Reddit posts, we initially utilized a Logistic Regression model. This model, known for its straightforwardness and effectiveness in binary classification, served as a fundamental starting point. It yielded promising results, demonstrating high accuracy in training (93.41%) but a moderate accuracy in testing (75.11%). This discrepancy indicated that while the model performed well on familiar data, it was less effective with new, unseen data.\n\n\n  \n    \n      \n        \n        Figure-2 (a): Confusion Matrix for Logistic Regression Model\n      \n    \n    \n      \n        \n        Figure-2 (b): ROC curve for Logistic Regression Model\n      \n    \n  \n  \n    \n      Figure-2\n    \n  \n\n\n\nThe initial Decision Tree model provided insightful outcomes. It showed a moderate level of accuracy in predicting post popularity, as evidenced by the ROC curve and other performance metrics. However, there were still instances of incorrect predictions, signaling the need for further model optimization.\nTo address this and capture the complexities of Reddit’s data more effectively, we transitioned to a Decision Tree classifier. The Decision Tree model, adept at handling diverse datasets, showed a more balanced performance with training accuracy at 87.44% and testing accuracy at 87.20%. This indicated a better generalization capability of the model on new data compared to the Logistic Regression model.\n\n\n  \n    \n      \n        \n        Figure-2 (a): Confusion Matrix for Decision Tree Model\n      \n    \n    \n      \n        \n        Figure-2 (b): ROC curve for Decision Tree Model\n      \n    \n  \n  \n    \n      Figure-2\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy Train\nAccuracy Test\nF1 Score Train\nF1 Score Test\nPrecision Train\nPrecision Test\nRecall Train\nRecall Test\n\n\n\n\nLogistic Regression\n0.934118\n0.751146\n0.934017\n0.750600\n0.934704\n0.751036\n0.934118\n0.751146\n\n\nDecision Tree\n0.874378\n0.872044\n0.874431\n0.872105\n0.874632\n0.872316\n0.874378\n0.872044\n\n\n\nThe comparison of these two models highlights the importance of choosing the right algorithm for specific data characteristics. The Decision Tree’s improved ability to generalize, as evidenced by the more consistent accuracy between training and testing, underscores its suitability for the dynamic and varied content on Reddit. This analysis demonstrates the value of model selection and tuning in the field of popularity prediction on social media platforms."
  },
  {
    "objectID": "ml.html#predicting-popularity-machine-learning-for-reddit-engagement-analysis-1",
    "href": "ml.html#predicting-popularity-machine-learning-for-reddit-engagement-analysis-1",
    "title": "Machine Learning",
    "section": "Predicting Popularity: Machine Learning for Reddit Engagement Analysis",
    "text": "Predicting Popularity: Machine Learning for Reddit Engagement Analysis\nIn the dynamic and diverse ecosystem of Reddit, where every submission vies for attention, being able to predict the popularity of a post holds immense value. The second model in this project endeavors to classify Reddit submissions as ‘popular’ or ‘not popular,’ serving a multitude of purposes. For content creators and marketers, understanding the elements that contribute to a post’s popularity can inform their strategy to capture the community’s interest more effectively. For the average user, this classification can enhance the personalization of their feed, bringing popular, engaging content to the forefront. Additionally, platform moderators can utilize insights from popularity predictions to better manage the influx of content and maintain the quality of user experience. This binary classification model, powered by machine learning, not only aims to decipher the attributes that propel a post to popularity but also to apply this knowledge in a way that enriches the Reddit landscape for all participants.\n\nData Cleaning\nFeature Engineering\nAlong with the existing features, the dataset was enhanced with new features that could be crucial for the classification of Reddit posts.\nTo enhance the accuracy of predicting a post’s popularity, we introduced ‘Sentiment Score’ and ‘Emotion’ as new features, recognizing that the tone and emotional context of a post greatly influence user engagement. The sentiment score captures the overall positivity or negativity of the content, while the emotion feature taps into the specific feelings a post might evoke, both of which are key indicators of a post’s potential to resonate with and captivate the Reddit community.\nSentiment Analysis The ‘body’ text was analyzed using the Spark NLP sentiment analysis model (sentimentdl_use_twitter) to extract sentiment score.\nEmotion Analysis The ‘body’ text was analyzed using the Spark NLP emotion analysis model (classifierdl_use_emotion) to extract different emotions.\nAll the other steps were the same as the above model.\n\n\nData Pre-Processing for Modeling\nTarget Variable Generation The ‘num_comments’ column was used to generate the target variable ‘is_popular’ by applying a threshold of 27 (mean number of comments). Posts with a score of 27 or above were classified as ‘popular’ while those with a score below 27 were classified as ‘not popular’.\nHandling Class Imbalance The dataset was balanced by downsampling the majority class (‘not popular’) to match the minority class (‘popular’).\n\n\n  \n    \n      \n        \n        Figure-3 (a): Target variable Distribution\n      \n    \n    \n      \n        \n        Figure-3 (b): Target variable Distribution after downsampling\n      \n    \n  \n  \n    \n      Figure-3\n    \n  \n\n\nString Indexing Key categorical features such as ‘over_18’, ‘is_self’, ‘is_video’, ‘has_media’, and ‘subreddit’ were transformed using StringIndexer. This step converted categorical strings into numerical indices, making them suitable for machine learning models.\nOne-Hot Encoding The indexed categories were further encoded using OneHotEncoder. This process transformed the indexed categories into a binary vector representation, a necessary step for handling categorical data in many machine learning algorithms.\nVector Assembler A VectorAssembler was utilized to combine various feature columns into a single vector column. This included both the newly created feature vectors from one-hot encoding and the existing numerical features such as ‘sentiment_score’, ‘score’, ‘post_length’, ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’. This assembly created a unified feature vector essential for feeding into the machine learning models.\nPipeline Definition A Pipeline was defined incorporating all the stages of string indexing, one-hot encoding, and vector assembly. This approach streamlined the preprocessing steps and ensured consistency across the data.\nPipeline Execution The preprocessing pipeline was applied to the training and test data. This transformed the data according to the defined stages, ensuring that it was ready for model training and evaluation.\n\n\nModel Training and Evaluation\n\nModel Selection\nFor predicting whether Reddit posts will be popular or not, we started with a simple Logistic Regression model. This model was chosen for its ease of use and good performance with basic yes/no type questions, like predicting if a post will be popular. However, to deal with the large and complex data from Reddit, we later switched to using a Decision Tree classifier. This model is better for handling lots of different factors in the data and makes it easier to understand how it decides if a post will be popular.\n\n\nModel Training\nIn the task of predicting the popularity of Reddit posts, we initially utilized a Logistic Regression model. This model, known for its straightforwardness and effectiveness in binary classification, served as a fundamental starting point. It yielded promising results, demonstrating high accuracy in training (93.41%) but a moderate accuracy in testing (75.11%). This discrepancy indicated that while the model performed well on familiar data, it was less effective with new, unseen data.\n\n\n  \n    \n      \n        \n        Figure-2 (a): Confusion Matrix for Logistic Regression Model\n      \n    \n    \n      \n        \n        Figure-2 (b): ROC curve for Logistic Regression Model\n      \n    \n  \n  \n    \n      Figure-2\n    \n  \n\n\n\nThe initial Decision Tree model provided insightful outcomes. It showed a moderate level of accuracy in predicting post popularity, as evidenced by the ROC curve and other performance metrics. However, there were still instances of incorrect predictions, signaling the need for further model optimization.\nTo address this and capture the complexities of Reddit’s data more effectively, we transitioned to a Decision Tree classifier. The Decision Tree model, adept at handling diverse datasets, showed a more balanced performance with training accuracy at 87.44% and testing accuracy at 87.20%. This indicated a better generalization capability of the model on new data compared to the Logistic Regression model.\n\n\n  \n    \n      \n        \n        Figure-2 (a): Confusion Matrix for Decision Tree Model\n      \n    \n    \n      \n        \n        Figure-2 (b): ROC curve for Decision Tree Model\n      \n    \n  \n  \n    \n      Figure-2\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy Train\nAccuracy Test\nF1 Score Train\nF1 Score Test\nPrecision Train\nPrecision Test\nRecall Train\nRecall Test\n\n\n\n\nLogistic Regression\n0.934118\n0.751146\n0.934017\n0.750600\n0.934704\n0.751036\n0.934118\n0.751146\n\n\nDecision Tree\n0.874378\n0.872044\n0.874431\n0.872105\n0.874632\n0.872316\n0.874378\n0.872044\n\n\n\nThe comparison of these two models highlights the importance of choosing the right algorithm for specific data characteristics. The Decision Tree’s improved ability to generalize, as evidenced by the more consistent accuracy between training and testing, underscores its suitability for the dynamic and varied content on Reddit. This analysis demonstrates the value of model selection and tuning in the field of popularity prediction on social media platforms."
  },
  {
    "objectID": "ml.html#classifying-popularity-machine-learning-for-reddit-engagement-analysis",
    "href": "ml.html#classifying-popularity-machine-learning-for-reddit-engagement-analysis",
    "title": "Machine Learning",
    "section": "Classifying Popularity: Machine Learning for Reddit Engagement Analysis",
    "text": "Classifying Popularity: Machine Learning for Reddit Engagement Analysis\nIn the dynamic and diverse ecosystem of Reddit, where every submission vies for attention, being able to predict the popularity of a post holds immense value. The second model in this project endeavors to classify Reddit submissions as ‘popular’ or ‘not popular,’ serving a multitude of purposes. For content creators and marketers, understanding the elements that contribute to a post’s popularity can inform their strategy to capture the community’s interest more effectively. For the average user, this classification can enhance the personalization of their feed, bringing popular, engaging content to the forefront. Additionally, platform moderators can utilize insights from popularity predictions to better manage the influx of content and maintain the quality of user experience. This binary classification model, powered by machine learning, not only aims to decipher the attributes that propel a post to popularity but also to apply this knowledge in a way that enriches the Reddit landscape for all participants.\n\nData Cleaning\nFeature Engineering\nAlong with the existing features, the dataset was enhanced with new features that could be crucial for the classification of Reddit posts.\nTo enhance the accuracy of predicting a post’s popularity, we introduced ‘Sentiment Score’ and ‘Emotion’ as new features, recognizing that the tone and emotional context of a post greatly influence user engagement. The sentiment score captures the overall positivity or negativity of the content, while the emotion feature taps into the specific feelings a post might evoke, both of which are key indicators of a post’s potential to resonate with and captivate the Reddit community.\nSentiment Analysis The ‘body’ text was analyzed using the Spark NLP sentiment analysis model (sentimentdl_use_twitter) to extract sentiment score.\nEmotion Analysis The ‘body’ text was analyzed using the Spark NLP emotion analysis model (classifierdl_use_emotion) to extract different emotions.\nAll the other steps were the same as the above model.\n\n\nData Pre-Processing for Modeling\nTarget Variable Generation The ‘num_comments’ column was used to generate the target variable ‘is_popular’ by applying a threshold of 27 (mean number of comments). Posts with a score of 27 or above were classified as ‘popular’ while those with a score below 27 were classified as ‘not popular’.\nHandling Class Imbalance The dataset was balanced by downsampling the majority class (‘not popular’) to match the minority class (‘popular’).\n\n\n  \n    \n      \n        \n        Figure-3 (a): Target variable Distribution\n      \n    \n    \n      \n        \n        Figure-3 (b): Target variable Distribution after downsampling\n      \n    \n  \n  \n    \n      Figure-3\n    \n  \n\n\nString Indexing Key categorical features such as ‘over_18’, ‘is_self’, ‘is_video’, ‘has_media’, and ‘subreddit’ were transformed using StringIndexer. This step converted categorical strings into numerical indices, making them suitable for machine learning models.\nOne-Hot Encoding The indexed categories were further encoded using OneHotEncoder. This process transformed the indexed categories into a binary vector representation, a necessary step for handling categorical data in many machine learning algorithms.\nVector Assembler A VectorAssembler was utilized to combine various feature columns into a single vector column. This included both the newly created feature vectors from one-hot encoding and the existing numerical features such as ‘sentiment_score’, ‘score’, ‘post_length’, ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’. This assembly created a unified feature vector essential for feeding into the machine learning models.\nPipeline Definition A Pipeline was defined incorporating all the stages of string indexing, one-hot encoding, and vector assembly. This approach streamlined the preprocessing steps and ensured consistency across the data.\nPipeline Execution The preprocessing pipeline was applied to the training and test data. This transformed the data according to the defined stages, ensuring that it was ready for model training and evaluation.\n\n\nModel Training and Evaluation\n\nModel Selection\nFor predicting whether Reddit posts will be popular or not, we started with a simple Logistic Regression model. This model was chosen for its ease of use and good performance with basic yes/no type questions, like predicting if a post will be popular. However, to deal with the large and complex data from Reddit, we later switched to using a Decision Tree classifier. This model is better for handling lots of different factors in the data and makes it easier to understand how it decides if a post will be popular.\n\n\nModel Training\nIn the task of predicting the popularity of Reddit posts, we initially utilized a Logistic Regression model. This model, known for its straightforwardness and effectiveness in binary classification, served as a fundamental starting point. It yielded promising results, demonstrating high accuracy in training (93.41%) but a moderate accuracy in testing (75.11%). This discrepancy indicated that while the model performed well on familiar data, it was less effective with new, unseen data.\n\n\n  \n    \n      \n        \n        Figure-4 (a): Confusion Matrix for Logistic Regression Model\n      \n    \n    \n      \n        \n        Figure-4 (b): ROC curve for Logistic Regression Model\n      \n    \n  \n  \n    \n      Figure-4\n    \n  \n\n\n\nThe initial Decision Tree model provided insightful outcomes. It showed a moderate level of accuracy in predicting post popularity, as evidenced by the ROC curve and other performance metrics. However, there were still instances of incorrect predictions, signaling the need for further model optimization.\nTo address this and capture the complexities of Reddit’s data more effectively, we transitioned to a Decision Tree classifier. The Decision Tree model, adept at handling diverse datasets, showed a more balanced performance with training accuracy at 87.44% and testing accuracy at 87.20%. This indicated a better generalization capability of the model on new data compared to the Logistic Regression model.\n\n\n  \n    \n      \n        \n        Figure-5 (a): Confusion Matrix for Decision Tree Model\n      \n    \n    \n      \n        \n        Figure-5 (b): ROC curve for Decision Tree Model\n      \n    \n  \n  \n    \n      Figure-5\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy Train\nAccuracy Test\nF1 Score Train\nF1 Score Test\nPrecision Train\nPrecision Test\nRecall Train\nRecall Test\n\n\n\n\nLogistic Regression\n0.934\n0.751\n0.934\n0.750\n0.934\n0.751\n0.934\n0.751\n\n\nDecision Tree\n0.874\n0.872\n0.874\n0.872\n0.874\n0.872\n0.874\n0.872\n\n\n\nThe comparison of these two models highlights the importance of choosing the right algorithm for specific data characteristics. The Decision Tree’s improved ability to generalize, as evidenced by the more consistent accuracy between training and testing, underscores its suitability for the dynamic and varied content on Reddit. This analysis demonstrates the value of model selection and tuning in the field of popularity prediction on social media platforms.\nThe source code for this model can be found here."
  },
  {
    "objectID": "ml.html#predicting-submission-scores-a-machine-learning-approach-to-forecasting-reddit-engagement",
    "href": "ml.html#predicting-submission-scores-a-machine-learning-approach-to-forecasting-reddit-engagement",
    "title": "Machine Learning",
    "section": "Predicting Submission Scores: A Machine Learning Approach to Forecasting Reddit Engagement",
    "text": "Predicting Submission Scores: A Machine Learning Approach to Forecasting Reddit Engagement\nIn the dynamic and diverse ecosystem of Reddit, where every submission vies for attention, being able to predict the popularity of a post holds immense value. The second model in this project endeavors to classify Reddit submissions as ‘popular’ or ‘not popular,’ serving a multitude of purposes. For content creators and marketers, understanding the elements that contribute to a post’s popularity can inform their strategy to capture the community’s interest more effectively. For the average user, this classification can enhance the personalization of their feed, bringing popular, engaging content to the forefront. Additionally, platform moderators can utilize insights from popularity predictions to better manage the influx of content and maintain the quality of user experience. This binary classification model, powered by machine learning, not only aims to decipher the attributes that propel a post to popularity but also to apply this knowledge in a way that enriches the Reddit landscape for all participants.\n\nData Cleaning\nFeature Engineering\nAlong with the existing features, the dataset was enhanced with new features that could be crucial for the classification of Reddit posts.\nTo enhance the accuracy of predicting a post’s popularity, we introduced ‘Sentiment Score’ and ‘Emotion’ as new features, recognizing that the tone and emotional context of a post greatly influence user engagement. The sentiment score captures the overall positivity or negativity of the content, while the emotion feature taps into the specific feelings a post might evoke, both of which are key indicators of a post’s potential to resonate with and captivate the Reddit community.\nSentiment Analysis The ‘body’ text was analyzed using the Spark NLP sentiment analysis model (sentimentdl_use_twitter) to extract sentiment score.\nEmotion Analysis The ‘body’ text was analyzed using the Spark NLP emotion analysis model (classifierdl_use_emotion) to extract different emotions.\nAll the other steps were the same as the above model.\n\n\nData Pre-Processing for Modeling\nTarget Variable Generation The ‘num_comments’ column was used to generate the target variable ‘is_popular’ by applying a threshold of 27 (mean number of comments). Posts with a score of 27 or above were classified as ‘popular’ while those with a score below 27 were classified as ‘not popular’.\nHandling Class Imbalance The dataset was balanced by downsampling the majority class (‘not popular’) to match the minority class (‘popular’).\n\n\n  \n    \n      \n        \n        Figure-3 (a): Target variable Distribution\n      \n    \n    \n      \n        \n        Figure-3 (b): Target variable Distribution after downsampling\n      \n    \n  \n  \n    \n      Figure-3\n    \n  \n\n\nString Indexing Key categorical features such as ‘over_18’, ‘is_self’, ‘is_video’, ‘has_media’, and ‘subreddit’ were transformed using StringIndexer. This step converted categorical strings into numerical indices, making them suitable for machine learning models.\nOne-Hot Encoding The indexed categories were further encoded using OneHotEncoder. This process transformed the indexed categories into a binary vector representation, a necessary step for handling categorical data in many machine learning algorithms.\nVector Assembler A VectorAssembler was utilized to combine various feature columns into a single vector column. This included both the newly created feature vectors from one-hot encoding and the existing numerical features such as ‘sentiment_score’, ‘score’, ‘post_length’, ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’. This assembly created a unified feature vector essential for feeding into the machine learning models.\nPipeline Definition A Pipeline was defined incorporating all the stages of string indexing, one-hot encoding, and vector assembly. This approach streamlined the preprocessing steps and ensured consistency across the data.\nPipeline Execution The preprocessing pipeline was applied to the training and test data. This transformed the data according to the defined stages, ensuring that it was ready for model training and evaluation.\n\n\nModel Training and Evaluation\n\nModel Selection\nFor predicting whether Reddit posts will be popular or not, we started with a simple Logistic Regression model. This model was chosen for its ease of use and good performance with basic yes/no type questions, like predicting if a post will be popular. However, to deal with the large and complex data from Reddit, we later switched to using a Decision Tree classifier. This model is better for handling lots of different factors in the data and makes it easier to understand how it decides if a post will be popular.\n\n\nModel Training\nIn the task of predicting the popularity of Reddit posts, we initially utilized a Logistic Regression model. This model, known for its straightforwardness and effectiveness in binary classification, served as a fundamental starting point. It yielded promising results, demonstrating high accuracy in training (93.41%) but a moderate accuracy in testing (75.11%). This discrepancy indicated that while the model performed well on familiar data, it was less effective with new, unseen data.\n\n\n  \n    \n      \n        \n        Figure-2 (a): Confusion Matrix for Logistic Regression Model\n      \n    \n    \n      \n        \n        Figure-2 (b): ROC curve for Logistic Regression Model\n      \n    \n  \n  \n    \n      Figure-2\n    \n  \n\n\n\nThe initial Decision Tree model provided insightful outcomes. It showed a moderate level of accuracy in predicting post popularity, as evidenced by the ROC curve and other performance metrics. However, there were still instances of incorrect predictions, signaling the need for further model optimization.\nTo address this and capture the complexities of Reddit’s data more effectively, we transitioned to a Decision Tree classifier. The Decision Tree model, adept at handling diverse datasets, showed a more balanced performance with training accuracy at 87.44% and testing accuracy at 87.20%. This indicated a better generalization capability of the model on new data compared to the Logistic Regression model.\n\n\n  \n    \n      \n        \n        Figure-2 (a): Confusion Matrix for Decision Tree Model\n      \n    \n    \n      \n        \n        Figure-2 (b): ROC curve for Decision Tree Model\n      \n    \n  \n  \n    \n      Figure-2\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy Train\nAccuracy Test\nF1 Score Train\nF1 Score Test\nPrecision Train\nPrecision Test\nRecall Train\nRecall Test\n\n\n\n\nLogistic Regression\n0.934118\n0.751146\n0.934017\n0.750600\n0.934704\n0.751036\n0.934118\n0.751146\n\n\nDecision Tree\n0.874378\n0.872044\n0.874431\n0.872105\n0.874632\n0.872316\n0.874378\n0.872044\n\n\n\nThe comparison of these two models highlights the importance of choosing the right algorithm for specific data characteristics. The Decision Tree’s improved ability to generalize, as evidenced by the more consistent accuracy between training and testing, underscores its suitability for the dynamic and varied content on Reddit. This analysis demonstrates the value of model selection and tuning in the field of popularity prediction on social media platforms."
  },
  {
    "objectID": "ml.html#predicting-submission-scores-a-machine-learning-approach-to-forecasting-reddit-scores",
    "href": "ml.html#predicting-submission-scores-a-machine-learning-approach-to-forecasting-reddit-scores",
    "title": "Machine Learning",
    "section": "Predicting Submission Scores: A Machine Learning Approach to Forecasting Reddit Scores",
    "text": "Predicting Submission Scores: A Machine Learning Approach to Forecasting Reddit Scores\nIn the busy world of Reddit, a post’s score, which is the total of its upvotes minus its downvotes, is really important for understanding how much users like the content. We’re looking at different things like what the post is about, when it was posted, and how users interact with it, to predict the score of a Reddit post. Being able to guess a post’s score helps us figure out what makes a post appealing to users. This is great for people who create content and those who manage the site, as it helps them know what their audience likes. We’re using advanced technology to figure out the secrets behind a successful Reddit post, aiming to make the platform even more engaging for its users.\n\nData Cleaning\nThe cleaning process for this model was similar to the previous model. The only difference was that we did not Vectorize (use TF-IDF) for the text data primarily because the focus of this model is different compared to previous models. Text vectorization techniques like TF-IDF are powerful for understanding and analyzing the content of text data, especially in tasks like classification where the text’s topic or sentiment is crucial. In predicting submission scores, the emphasis is likely on quantifiable metrics such as user interaction data (e.g., number of comments, time since posted) and post characteristics (e.g., length of the post, presence of links or media), which have a more direct and measurable impact on a post’s popularity as indicated by its score.\n\n\nData Pre-Processing for Modeling\nString Indexing Key categorical features such as ‘over_18’, ‘is_self’, ‘is_video’, ‘has_media’, and ‘subreddit’ were transformed using StringIndexer. This step converted categorical strings into numerical indices, making them suitable for machine learning models.\nOne-Hot Encoding The indexed categories were further encoded using OneHotEncoder. This process transformed the indexed categories into a binary vector representation, a necessary step for handling categorical data in many machine learning algorithms.\nVector Assembler A VectorAssembler was utilized to combine various feature columns into a single vector column. This included both the newly created feature vectors from one-hot encoding and the existing numerical features such as ‘sentiment_score’, ‘num_comments’, ‘post_length’, ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’. This assembly created a unified feature vector essential for feeding into the machine learning models.\nPipeline Definition A Pipeline was defined incorporating all the stages of string indexing, one-hot encoding, and vector assembly. This approach streamlined the preprocessing steps and ensured consistency across the data.\nPipeline Execution The preprocessing pipeline was applied to the training and test data. This transformed the data according to the defined stages, ensuring that it was ready for model training and evaluation.\n\n\nModel Training and Evaluation\n\nModel Selection\nFor predicting Reddit post scores, we first used Linear Regression. This method is straightforward and good for starting out, as it helps us see how different things about a post might affect its popularity. But Reddit’s data can be quite complex, so we then switched to using a Decision Tree Regressor. This method is better at handling the tricky and detailed patterns found in social media data, like when posts are made and how people interact with them, giving us a clearer picture of what makes a post score high or low.\n\n\nModel Training\nIn analyzing the performance of the two models employed for predicting Reddit post scores, Linear Regression and Decision Tree, distinct outcomes were observed. The Linear Regression model achieved a Root Mean Square Error (RMSE) of 1351.79 on training data and 1385.97 on testing data, with R-squared (R2) values of 0.25 and 0.3, respectively. These figures suggest moderate accuracy with a slightly better fit on the testing data. On the other hand, the Decision Tree model showed a slightly lower RMSE of 1324.6 in training, but a higher RMSE of 1447.39 in testing, indicating it was more accurate in training but less so with new data. The R2 values were 0.28 for training and 0.29 for testing, closely mirroring those of Linear Regression. Overall, while both models offered insights into the factors influencing post scores, their effectiveness was somewhat limited, pointing to the need for further refinement or exploration of more sophisticated models to enhance prediction accuracy.\nThese RMSE scores depict how good our model is. The lower the RMSE, the better the model is at predicting the score of a post. The RMSE for the Linear Regression model is 1351.79 on the training data and 1385.97 on the testing data. The RMSE for the Decision Tree model is 1324.6 on the training data and 1447.39 on the testing data. Such high RMSE does not always mean that the model is performing bad. The RMSE also depends on the range of the target variable. An model with RMSE of 1200 when the target variable range is 100-200 is a bad model. But an RMSE of 1200 when the target variable range is 10000-20000 is a good model. In our case, the target variable range is 0-20000. So, the RMSE of 1351.79 for Linear Regression and 1324.6 for Decision Tree are not bad.\n\n\n\nFigure-7: Parity Plot for Decision Tree Regressor\n\n\n\n\n\n\nModel\nRMSE Train\nRMSE Test\nR2 Train\nR2 Test\n\n\n\n\nLinear Regression\n1351.79\n1385.97\n0.25\n0.28\n\n\nDecision Tree\n1324.6\n1447.39\n0.28\n0.22\n\n\n\nTrying to predict the scores of Reddit posts, which are calculated by subtracting downvotes from upvotes, turned out to be quite tough and the results weren’t as good as hoped. One big issue is that the same score can mean very different things. For example, a score of 1 could be because only one person liked the post and nobody disliked it, or it could be that 10,000 people liked it but 9,999 didn’t. This makes it really hard to predict what’s going on with a post just based on its score.\nAlso, a score doesn’t always tell the whole story about how users feel about a post. A post with lots of likes and dislikes probably means people have strong opinions about it, while a post with a few likes might have just not been seen by many people. This kind of difference is a big challenge for models like Linear Regression and Decision Trees. These models find it difficult to understand the real reasons behind a post’s score, especially because a score comes from both likes and dislikes. So, while these models can give some general ideas, they aren’t very good at accurately guessing a Reddit post’s score due to how complex and unclear the scoring can be.\nThe source code for this model can be found here."
  },
  {
    "objectID": "ml_exec_summary.html",
    "href": "ml_exec_summary.html",
    "title": "Machine Learning - Executive Summary",
    "section": "",
    "text": "Our objective was to categorize Reddit posts into two distinct groups: Anime and Movies. We chose a classifier called Random Forest for this. The classifier is adept at discerning patterns and distinguishing between varied types of data.\nAt first, we started with a basic model for our classifier to see how good the model can predict. The initial results were encouraging, suggesting we were on the right track, yet they weren’t exceptional.The classifier could differentiate between Anime and Movies, but it wasn’t always accurate. Realizing the potential for improvement, we fine-tuned the classifier’s settings. It’s like fine-tuning a musical instrument for the best sound. We adjusted how many decision-making paths it should take, how deep it should look into details, and how it groups information. These adjustments made a big difference.\nPost-tuning, the classifier became much more adept at correctly labeling posts as either Anime or Movies. The improvement was evident in its increased accuracy and fewer misclassifications."
  },
  {
    "objectID": "ml_exec_summary.html#decoding-reddits-popular-posts-a-machine-learning-journey",
    "href": "ml_exec_summary.html#decoding-reddits-popular-posts-a-machine-learning-journey",
    "title": "Machine Learning - Executive Summary",
    "section": "Decoding Reddit’s Popular Posts: A Machine Learning Journey",
    "text": "Decoding Reddit’s Popular Posts: A Machine Learning Journey\nOur goal here was to predict which Reddit posts become popular. This insight is beneficial for everyone on Reddit, from content creators to everyday users. We started by enriching the data with new features like ‘Sentiment Score’ and ‘Emotion’, essential for understanding a post’s impact. Then, we prepared our data for machine learning by defining ‘popular’ posts based on the number of comments and balancing our dataset to avoid biases.\nOur first model, a Logistic Regression, gave us good initial results but struggled with complex data. So, we switched to a Decision Tree classifier, better suited for Reddit’s diverse content. This model proved more effective, showing consistent performance in identifying popular posts.\nThis project highlighted the importance of choosing the right machine learning model for the task. The Decision Tree classifier, with its ability to handle varied data, was a key player in accurately predicting post popularity on Reddit. It also, gave us insights on what features affect the popularity of the posts, something that reddit users can use to improve their content on reddit."
  },
  {
    "objectID": "ml_exec_summary.html#understanding-reddit-post-scores-a-machine-learning-approach",
    "href": "ml_exec_summary.html#understanding-reddit-post-scores-a-machine-learning-approach",
    "title": "Machine Learning - Executive Summary",
    "section": "Understanding Reddit Post Scores: A Machine Learning Approach",
    "text": "Understanding Reddit Post Scores: A Machine Learning Approach\nIn the third part of our project, we tried to predict how people engage with Reddit posts, would be based on their scores, which are calculated by subtracting downvotes from upvotes. Our aim was to figure out what makes a post engaging to Reddit users. This task was challenging because Reddit’s scoring can be tricky – for example, a post with a score of one could either have one person liking it or thousands of likes and almost as many dislikes.\nWe started with a simple method called Linear Regression to get a basic idea of how scores work. But we soon realized we needed a more detailed approach to really understand Reddit’s scoring. So, we switched to using a Decision Tree Regressor, which is better at handling complex data. This model helped us see more clearly what affects a post’s score.\nHowever, we found that both models had their limits. The way Reddit calculates scores made it hard for our models to be really accurate. Sometimes the scores didn’t give a clear picture of how users felt about a post.\nTo wrap up, this part of the project showed us how tough it can be to guess the engagement of Reddit posts. It also taught us that choosing the right method and making adjustments to it is key, especially for data as complex as this. Our work here opens up more opportunities to explore social media data, helping us get better at predicting how people interact with content online."
  },
  {
    "objectID": "eda.html#analysis-report",
    "href": "eda.html#analysis-report",
    "title": "Exploratory Data Analysis",
    "section": "Analysis Report",
    "text": "Analysis Report\nIn this analysis, we utilized Submissions Reddit data stored in an Azure Machine Learning workspace blob store in parquet format, employing PySpark for distributed data processing and Pandas for local data manipulation and analysis.\nTo kick off our exploration of entertainment subreddits, we aimed for a broad understanding of how submissions are distributed across entertainment-related subreddits. To achieve this goal, we created a lollipop graph with post counts of subreddits on the x-axis and different entertainment subreddits on the y-axis.\n\n\n\nFigure-1: Count of each subreddit in the dataset from 2021-2023\n\n\nFrom Figure 1, it’s evident that the ‘anime’ subreddit is the most active with 404,298 posts, showcasing a very active community with a strong interest in anime-related content. Following closely is the ‘movies’ subreddit, also bustling with activity at 382,085 posts. Both ‘anime’ and ‘movie’ subreddits outshine the ‘television’ subreddit in post counts, revealing higher user engagement in these topics. A similar trend can be observed among the subreddits dedicated to suggestions with the ‘AnimeSuggestions’ subreddit having a higher post count followed by ‘MovieSuggestions’ and ‘televisionsuggestions’. This indicates that there is a substantial interest in community-driven recommendations for anime. The ‘MovieSuggestions’ subreddit has a moderate number of posts, while ‘televisionsuggestions’ has the least, reflecting lower user engagement for television recommendations on the Reddit platform.\nNext, we filtered the data to keep only the subset of columns relevant to our analysis. The selected columns include information about the submission, such as the subreddit, author, title, selftext, creation timestamp, number of comments, score, and various other attributes related to the submission’s characteristics. After selecting specific columns, we aimed to understand the dataset’s structure and quality. To achieve this, we obtained the count of missing values in each column of the dataset. Table 1 represents a summary of missing values in our dataset, where each row corresponds to a different feature, and the ‘Missing Values’ column quantifies the number of missing values for each feature.\n\n \n\n  \n  Table-1: Count of missing values of all the columns for submissions dataset\n\n\nTable-1 shows that columns such as ‘author’, ‘title’, ‘selftext’, ‘created_utc’, ‘num_comments’, ‘score’, ‘over_18’, ‘pinned’, and ‘locked’ show complete data with zero missing values, suggesting they are mandatory fields in the platform’s post submission process. While, a significant number of missing values are observed in the ‘disable_comments’, ‘distinguished’, and ‘media’ columns. This could indicate that these fields are optional or applicable only to certain posts. This makes sense for instance, ‘distinguished’ could denote a special status assigned to certain posts, which would naturally be less common. Since the columns with the missing values were not relevant to our business goals and also removing missing values from these columns could remove posts with optional features. So we decided to retain the rows with missing values and it would also preserve the completeness of the dataset.\nMoving further, three new columns were added to the data by transforming the original DataFrame:\n\nFirstly, we extracted various time-related features like ‘hour_of_day’, ‘day_of_week’, ‘day_of_month’, ‘month’, and ‘year’ from the ‘created_utc’ timestamp. These features can be useful for analyzing trends or patterns in the data based on temporal information.\nSecondly, we wanted to analyze the overall length of posts, so we added a new column ‘post_length’ to the data. The values in this column are calculated based on the sum of the lengths of the ‘title’ and ‘selftext’ columns for each row.\nThirdly, we created a new column called ‘has_media’ that is set to “True” if a post has media content (like images or videos) and “False” if it doesn’t. This makes it easier to identify which posts include some form of media and which do not.\n\nAfter these transformations were done, the columns like “media,” “created_utc,” “disable_comments,” and “distinguished,” which were no longer necessary for our analysis, were dropped.\nThe following table shows the final columns and their descriptions that were used for our analysis.\n\n\n\n\nTable-2: Description of key variables in the Reddit data\n\nMoving forward, we performed data manipulation to generate structured datasets encompassing top comments for specific subreddits, author post counts, and time series analysis. These datasets will serve as a foundation for extracting insights into user engagement, content popularity, temporal evolution, and author contributions on the Reddit platform through the creation of meaningful visualizations.\nThe detailed process and code can be found here for data cleaning and here for data manipulation.\n\nUnderstanding trends in the engagement of posts from 2021-2023\nNext, we were curious to see how the general trend in the engagement across prominent subreddits —‘anime,’ ‘movies,’ and ‘television’ evolve over different periods of time. In order to achieve this we firstly decided to analyse how number of posts and the scores varied over the period of two years.\n \n\n  \n  Figure-2: This graph illustrates the normalized post count trends across three subreddits (anime, movies, and television) over a span of two years, from January 2021 to April 2023. The peaks and troughs indicate fluctuations in user engagement and post frequency within the Reddit community.\n\n\nFigure-2 attempts to capture the trend in the number of posts made across the three subreddits over the time period of 2021-2023. To facilitate a more accurate assessment of relative fluctuations in user engagement and post frequency, normalized post counts were used. Overall, the subreddits exhibit a more gradual decline, implying a slow yet consistent decrease in the number of posts and interactions. The overarching decline across all three subreddits raises questions about the factors influencing these changes.However, when comparing the three sections, we can observe that the movies and anime subreddits show a general decrease in the number of posts. On the other hand, the engagement, in terms of posts made, remains relatively constant for the television subreddit. The possibility of shifting platform dynamics, evolving content consumption patterns, or the rise of alternative entertainment forums could be contributing to this trend. It indicates a potential shift in the digital landscape where traditional subreddit forums may no longer command the same level of attention as before. Certain high peaks could possibly correlate to significant new releases in any of the three categories, resulting in increased engagement and discussions on the platform. For instance, we can see a peak starting from March 2021, which could equate to the release of Zack Snyder’s much-hyped movie, Justice League.”\n \n\n  \n  Figure-3: This graph illustrates the scores across three subreddits (anime, movies, and television) over a span of two years, from January 2021 to April 2023. The peaks and troughs indicate fluctuations in user engagement and scores within the Reddit community.\n\n\nFigure 3 shows the trends in changes in the average scores from 2021 to 2023. When comparing Figures 2 and 3, we observe that, in general, scores remain relatively constant for the anime section during this period, despite a considerable fluctuating decline in the number of posts. However, for movies and television, there is a general slight upward trend in scores, in contrast to the step downward trend in the number of posts. This suggests that, for these two categories, the number of posts made is slightly inversely proportional to the rating. This could be due to the availability of fewer posts to view, resulting in an increase in scores for those written during that period.\nNext, we wanted to see if there are any trends in the number of posts and average score depending on the time of the month. This was to figure out if there was a day of the month were the number of engagement on the platform were showing a particular trend either high or low.\n \n\n  \n  Figure-4: Number of posts submitted on different days of the month from 2021-2023\n\n\nFigure 4 compares the number of posts across the three subreddits by the day of the month. In this figure, it is challenging to pinpoint any specific day of the month where the number of posts is particularly high. The downward trend at the end of the month is attributed to the variation in the number of days each month, as not every month has 31 days.\n \n\n  \n  Figure-5: Average score of posts submitted on different days of the month from 2021-2023\n\n\nWhen examining Figure 5, which compares the average scores for each day of the month, it is apparent that the scores generally remain constant with occasional bumps in all three categories. However, television shows the highest ratings despite having the fewest number of posts. This observation seems to confirm an inverse relationship between the number of posts and the scores. Furthermore, we aimed to streamline our analysis to understand how trends in the number of posts and scores vary when comparing different days of the week and hours of the day.\n \n\n  \n  Figure-6: Number of posts during the week and time of the day for the subreddits\n\n\nFigure-6 presents the distribution of posts across days of the week and hours of the day for the subreddits ‘anime,’ ‘movies,’ and ‘television.’ This visualization suggests that the ‘television’ subreddit has its own unique pattern of user interaction, potentially reflecting the airing schedule of popular shows or weekly events that drive discussions, especially during the evening hours from 3 PM to 5 PM. Overall, all three subreddits show a more spread-out activity throughout the week, indicating a consistent level of engagement without significant peaks or troughs.\n \n\n  \n  Figure-7: Number of posts during the week and time of the day for the subreddits\n\n\nFigure-7 illustrates the distribution of average scores across days of the week and hours of the day for the subreddits ‘anime,’ ‘movies,’ and ‘television.’ The plot suggests that people are generally more active in reading and voting for posts each day of the week, particularly during the late afternoon hours of 2 PM to 4 PM. This trend is also directly proportional to the number of posts made during those hours.\nOverall, we can assert that interaction activities peak on these Reddit threads during the late afternoon hours. These insights underscore the importance of timing in Reddit community engagement. For marketers and content creators, aligning content releases with these observed peaks could enhance user engagement. For platform moderators, it could inform the scheduling of events or AMAs (Ask Me Anything sessions) to ensure higher participation rates. Additionally, this data could assist in the strategic placement of advertisements during specific hours of a particular day, ensuring they reach the most active audience segments.\n\n\nExploring how Reddit post engagement dynamics is influenced by subreddit characteristics.\nNext, we delved into the diverse aspects of user engagement dynamics on Reddit posts, investigating variations related to characteristics such as score, post length, number of comments, and the inclusion of media content. To do this analysis we have created a bubble plot comparing the post engagement by Length and Score across the three subreddits. Additionally,the posts with media and those without media within the anime, movies, and television subreddits on Reddit are analysed.\n \n\n  \n  Figure-8: Correlation between post lengths and scores within anime, movies, and television subreddits on Reddit.\n\n\nFigure 8 illustrates the engagement dynamics of Reddit posts, comparing post length to user engagement across subreddits dedicated to anime, movies, and television. Each dot represents an individual post, with its size corresponding to the score, which is a proxy for the post’s popularity or engagement level.\nA cursory analysis reveals a dense clustering of posts with scores under 10,000 across all subreddits, with post lengths predominantly falling below 2000 characters. This suggests that shorter posts are more common, regardless of the subreddit category. Interestingly, there is a visible trend where posts with higher scores tend to have shorter lengths, indicating that more concise posts may resonate better with the audience or are more likely to be engaged with.\nThe larger-sized dots, indicating posts with exceptionally high scores, are predominantly short and are scattered across all three subreddits. This may indicate that highly engaging posts, which are likely to go viral or hit the front page of Reddit, tend to be concise.\nThis insight can inform content creators and marketers about optimal post lengths for audience engagement in different entertainment categories on Reddit.\n \n\n  \n  Figure-9: Correlation between post lengths and scores within submissions that have media as well as those that don't have media.\n\n\nFigure 9 illustrates the engagement dynamics of Reddit posts, comparing post length to user engagement within submissions that have media as well as those that don’t have media. Each dot represents an individual post, with its size corresponding to the score, which is a proxy for the post’s popularity or engagement level.\nFrom Figure 9, it seems that posts with media tend to have a higher score regardless of post length, as indicated by the concentration of orange dots across all lengths, especially in the higher score region. There are some high-scoring posts without media, but these are less frequent as the score increases. This suggests that including media in a post could potentially lead to higher engagement on Reddit.\nWe further analysed the percentage of posts with and without media across the three subreddits.\n \n\n  \n  Figure-10: Grouped bar plot showing the percentage of posts with media and those without media within the anime, movies, and television subreddits on Reddit.\n\n\nFrom Figure 10 we can see that the percentage of posts with media is significantly higher than those without across all three subreddits. The “movies” subreddit has the highest percentage of posts with media (89.75%), followed by “television” (83.64%), and “anime” (82.56%). Conversely, the percentage of posts without media is the lowest in the “movies” subreddit (10.25%), which correlates with the earlier observation that media content is prevalent in high-engagement posts.\nOverall, these three graphs gives us insights about engagement on Reddit which suggest that not only is the presence of media a factor, but so is the length of the post. Content creators could use this information to optimize their posts for better engagement by creating concise posts that include media, and targeting their efforts towards subreddits where these types of posts perform well.\n\n\nIdentify the most engaging and active authors\nFurthermore, we wanted to analyze the post counts of authors with top comments and score as well as the post counts of the most active authors for the three subreddits separately as all these subreddits are distinct and warrant their own analysis. This analysis would be beneficial for various purposes, including recognizing community leaders, understanding content popularity, and potentially collaborating with influential contributors to enhance community engagement or promotional activities.\nTo do so, we first identified the authors of the posts with highest number of comments for the three subreddit separately.\n\n \n\n  \n  Table-3: Ranks of authors from a subreddit based on the number of comments their posts receive, highlighting the most engaging content creators\n\n\nTable 3 presents the top 10 posts with the highest number of comments, categorizing them based on movie, television, and anime subreddits. High comment counts typically signify that an author’s contributions resonate well with the community, sparking active discussions among the subreddit’s users. The table not only identifies the most engaging authors across subreddits but also emphasizes the importance of creating content that encourages active participation within the community. Furthermore, this data offers insights into the types of posts that cultivate robust discussions on Reddit.\nNow that we have identified authors receiving highest number of comments on their posts we wanted to look how active these authors have been on reddit.\n \n\n  \n  Figure-11: Bar chart ranking the post counts of authors who have received highest number of comments on their post \n\n\nFigure-11 presents the post counts attributed to the authors who have received highest number of comments on their post within the movies, anime, and television subreddits. These counts are a direct indicator of the quantity of content contributed by individual authors rather than the quality or engagement level of the posts.\nThe movies subreddit exhibits a concentration of activity from a few highly active authors, potentially impacting the diversity of topics and perspectives within the community. Notably, authors like “LETS_MAKE_IT_AWKWARD” and “officialtobeymaguire” have achieved top 10 highest comments with only one post on Reddit, showcasing the influence of specific contributors.\nSimilarly, in the television subreddit, a skewed distribution among the top ten authors, with ‘MarvelsGrantMan136’ and ‘Neo2199’ being the most active, suggests a reliance on a small group for a significant portion of content. On the other hand, authors like “ewzetf”, “Midnight_OIL_”, and “thetanhausergate” achieved top 10 highest comments with fewer than four posts, indicating impactful contributions despite lower post counts.\nIn contrast, the anime subreddit experiences a unique scenario with bots as primary content contributors. Despite their automated nature, these bots engage the community more effectively than typical human-authored posts, potentially due to timely, consistently formatted, and relevant content. This challenges the notion that engaging content must be human-generated, showcasing the potential for well-tuned bots to contribute meaningfully to online discourse.\nFurthermore, we aimed to assess what kind of content gets the most number of scores. The Scores are calculated based on the number of upvotes minus the number of downvotes.\n\n \n\n  \n  Table-4: Ranks of authors from a subreddit based on the scores their posts receive, highlighting the most engaging content creators\n\n\nThe table 4 shows a list from each category of subreddit, ranking the top 10 posts by score. For the movie subreddit, the highest-scoring post is an AMA with Keanu Reeves, indicating that interactive sessions with famous actors are highly valued in the community. This is further emphasized by the presence of another AMA with Tobey Maguire in the second position. The third highest post by Nicolas Cage suggests that personal engagement from actors or filmmakers garners significant attention. Posts regarding industry news and opinions, such as the win of Brendan Fraser at the Academy Awards and a call to prioritize voice actors over celebrities in animated features, reflect the community’s interest in both celebrating achievements and critiquing industry trends. A post about a ‘Dune’ sequel hints at the community’s enthusiasm for science fiction and blockbuster franchises.\nFor the television subreddit, the most popular post highlights a public figure, LeVar Burton, expressing his desire to become the new host of “Jeopardy!”, which is indicative of the community’s interest in show hostings and personalities associated with them. This is further emphasized by another post where Burton encourages the producers of “Jeopardy!” to consider him for the role, showcasing the community’s support for his candidacy. Other posts indicate strong community interest in television show news and updates, like the revival of “Futurama” and a potential third season for “Mindhunter.” The active engagement in these topics suggests that news about television series renewals and continuations is particularly resonant with the audience.\nMoving to the anime, The top post is about the death of Kentaro Miura, the creator of “Berserk,” which underscores the impact that influential figures in the anime industry have on the community. The high score indicates that news about significant personalities, especially those who have made a profound impact on the genre, resonates deeply with the audience. Several posts relate to announcements of new seasons for popular anime series like “The Devil is a Part-Timer,” “Spice and Wolf,” and “Konosuba.” This suggests that the subreddit is a hub for fans to discuss and share their excitement about continuing series and new developments within their favorite anime. There is also a post about a prediction tournament for “Best Girl,” a common discussion topic in anime communities where fans vote for their favorite female characters. The popularity of such a post indicates that interactive and participatory events are engaging for the community members.\nNow that we have identified authors receiving the highest scores on their posts, we want to examine how active these authors have been on Reddit.\n \n\n  \n  Figure-12: Bar chart ranking the post counts of authors who have received highest scores on their post\n\n\nFigure 12 presents the post counts attributed to the authors who have received top scores on their post within the movies, anime, and television subreddits.\nIn the movies subreddit, ‘MarvelsGrantMan136’ dominates but is followed by a group of authors with notable contributions, reflecting a community with diverse yet influential voices. The television subreddit shows ‘MarvelsGrantMan136’ leading, with a narrower margin over ‘chanma50’, suggesting a broader spread of engagement across various authors. ‘AutoLovepon’ leads in the anime subreddit with an exceptionally high post count, indicating a significant impact on the community, likely due to consistent, high-quality content, which could be automated. These patterns highlight different engagement dynamics, with a single dominant presence in anime and a more varied influence among authors in the movies and television subreddits.\nLooking at Table 4 and Figure 12, we can also say that high scores don’t equate to a high post count. This can be understood by MarvelsGrantMan136’s entry, where the author has one of the highest engagement as well as posts; however, lionsgate is the post with the highest engagement but doesn’t have even 1/3000 times the number of posts. A similar trend can also be observed for anime and television, and therefore we can conclude that there is no correlation between the author’s scores and post count.\nFinally, we wanted to identify active authors in the anime, movies, and television subreddits to recognize the authors who consistently engage with and contribute to these communities.\n \n\n  \n  Figure-13: This bar chart ranks the top 10 authors in the subreddit based on the number of posts they have made\n\n\nThe Figure 13 provides an overview of the top 10 active authors in the anime, movies, and television subreddits, showing a clear disparity in activity levels across these categories.\nFor the movies subreddit, the top author has an exceptionally high post count, exceeding 20,000, which is significantly higher than the subsequent authors. This could imply a central role in the subreddit, possibly as a source of extensive information or regular discussion threads. However, the drop in post counts among the following authors is stark, indicating a less concentrated field of active contributors and suggesting a more varied source of content within the community.\nIn the television subreddit, the post counts among the top authors are more evenly distributed, with ‘MarvelsGrantMan136’ leading but with a smaller margin compared to the leaders in the anime and movies subreddits. This indicates a more balanced contribution from the top authors, which could result in a diverse range of discussions and viewpoints being represented in the subreddit.\nMoving to the anime subreddit, the leading author, presumably a bot named ‘AutoLovepon’, has a post count that far exceeds that of any human contributor, with over 6000 posts. This suggests a high level of automation in content generation, which is indicative of a structured and consistent posting strategy, possibly catering to the demand for updates, recommendations, or scheduled discussion threads. Given the nature of bot-generated content, this level of activity might provide a streamlined experience for users seeking information without the variability of human-authored posts.\nIn conclusion, these engagement models reflect the unique cultural dynamics of each subreddit, providing valuable insights for content creators, moderators, and marketers on how to approach each community effectively.\nThe source code for generating the plots can be found here."
  },
  {
    "objectID": "eda.html#executive-summary",
    "href": "eda.html#executive-summary",
    "title": "Exploratory Data Analysis",
    "section": "Executive Summary",
    "text": "Executive Summary\nTo summarize, we explored how the subreddits are distributed in our dataset, aiming to understand the balance or imbalance. This analysis helps us notice patterns and strategize for further exploration. We observed a notable size difference between the Anime and Movie subreddits compared to the Television subreddit, this could be because of varying popularity, We’ve decided to focus our attention on the Anime and Movie Reddit data for our further analysis.\nDoes Time matter? \nWe noticed a decline in the number of posts across all subreddits, reaching its peak from January to July 2021. While this period coincided with the pandemic when social media usage was likely high, it doesn’t provide significant insights for our analysis.Digging more into the temporal aspects, we explored how post counts vary with time of day, day of the week, and more. Intriguingly, we found no distinct cyclic pattern linked to specific days of the month. This implies that post scores are probably shaped by content availability and user interest, rather than the timing within a month. The consistent engagement in ‘anime’ and ‘television’ subreddits suggests an ongoing compelling content, this suggests that capturing user attention isn’t strongly correlated with specific times, days, or months.\nHow to draw attention?\nTo keep it short, we compared post length to user engagement across anime, movies, and television subreddits. What we found is that shorter posts, usually under 2000 characters, are more common across all subreddits, especially those with scores under 10,000. Surprisingly, highly engaging posts, often going viral, tend to be concise. So, for content creators and marketers, this insight suggests that brevity might be the key to capturing audience attention in various entertainment categories on Reddit. Addititonally, incorporating media into posts could be an effective strategy for increasing engagement. However, it’s important to consider other factors that might influence engagement, such as the time of posting, the specific subreddit community, and the quality of the media content.\nTop content creators and their engagement with the users\nWe identified the most engaging authors in each subreddit based on comments, scores, and post counts. Interestingly, in the television subreddit, the author with the highest score is also the one with the most posts. However, in the movie subreddit, this correlation doesn’t hold. Notably, in the anime subreddit, bots are the ones ruling both popularity and engagement.\nFrom this we see that each subreddit has unique engagement dynamics. In the TV subreddit, the top author is both prolific and engaging, but this trend is less clear in movies. The prevalence of bots driving engagement in anime challenges the idea that the most engaging content has to be human-created. It emphasizes the importance of understanding each community’s dynamics in assessing author roles in content creation and discussions."
  },
  {
    "objectID": "eda_exec_summary.html",
    "href": "eda_exec_summary.html",
    "title": "Exploratory Data Analysis - Executive Summary",
    "section": "",
    "text": "Digging deep into data :\nWe started things off by searching for missing values in our dataset. Once we found them, we replaced/filled the gaps for key variables with the appropriate info, and we decided to let go of the less important ones. This way, we kept what really mattered and polished up the data for a smoother analysis ride.\nNext, we explored how the subreddits are distributed in our dataset, aiming to understand the balance or imbalance. This analysis helps us notice patterns and strategize for further exploration. We observed a notable size difference between the Anime and Movie subreddits compared to the Television subreddit, this could be because of varying popularity, We’ve decided to focus our attention on the Anime and Movie Reddit data for our further analysis.\n\n\nDoes Time matter?\nWe noticed a decline in the number of posts across all subreddits, reaching its peak from January to July 2021. While this period coincided with the pandemic when social media usage was likely high, it doesn’t provide significant insights for our analysis.Digging more into the temporal aspects, we explored how post counts vary with time of day, day of the week, and more. Intriguingly, we found no distinct cyclic pattern linked to specific days of the month. This implies that post scores are probably shaped by content availability and user interest, rather than the timing within a month. The consistent engagement in ‘anime’ and ‘television’ subreddits suggests an ongoing compelling content, this suggests that capturing user attention isn’t strongly correlated with specific times, days, or months.\n\n\nHow to draw attention?\nTo keep it short, we compared post length to user engagement across anime, movies, and television subreddits. What we found is that shorter posts, usually under 2000 characters, are more common across all subreddits, especially those with scores under 10,000. Surprisingly, highly engaging posts, often going viral, tend to be concise. So, for content creators and marketers, this insight suggests that brevity might be the key to capturing audience attention in various entertainment categories on Reddit. Addititonally, incorporating media into posts could be an effective strategy for increasing engagement. However, it’s important to consider other factors that might influence engagement, such as the time of posting, the specific subreddit community, and the quality of the media content.\n\n\nTop content creators and their engagement with the users\nWe identified the most engaging authors in each subreddit based on comments, scores, and post counts. Interestingly, in the television subreddit, the author with the highest score is also the one with the most posts. However, in the movie subreddit, this correlation doesn’t hold. Notably, in the anime subreddit, bots are the ones ruling both popularity and engagement.\nFrom this we see that each subreddit has unique engagement dynamics. In the TV subreddit, the top author is both prolific and engaging, but this trend is less clear in movies. The prevalence of bots driving engagement in anime challenges the idea that the most engaging content has to be human-created. It emphasizes the importance of understanding each community’s dynamics in assessing author roles in content creation and discussions."
  },
  {
    "objectID": "eda_exec_summary.html#does-time-matter",
    "href": "eda_exec_summary.html#does-time-matter",
    "title": "Exploratory Data Analysis - Executive Summary",
    "section": "Does Time matter?",
    "text": "Does Time matter?\nWe noticed a decline in the number of posts across all subreddits, reaching its peak from January to July 2021. While this period coincided with the pandemic when social media usage was likely high, it doesn’t provide significant insights for our analysis.Digging more into the temporal aspects, we explored how post counts vary with time of day, day of the week, and more. Intriguingly, we found no distinct cyclic pattern linked to specific days of the month. This implies that post scores are probably shaped by content availability and user interest, rather than the timing within a month. The consistent engagement in ‘anime’ and ‘television’ subreddits suggests an ongoing compelling content, this suggests that capturing user attention isn’t strongly correlated with specific times, days, or months."
  },
  {
    "objectID": "eda_exec_summary.html#how-to-draw-attention",
    "href": "eda_exec_summary.html#how-to-draw-attention",
    "title": "Exploratory Data Analysis - Executive Summary",
    "section": "How to draw attention?",
    "text": "How to draw attention?\nTo keep it short, we compared post length to user engagement across anime, movies, and television subreddits. What we found is that shorter posts, usually under 2000 characters, are more common across all subreddits, especially those with scores under 10,000. Surprisingly, highly engaging posts, often going viral, tend to be concise. So, for content creators and marketers, this insight suggests that brevity might be the key to capturing audience attention in various entertainment categories on Reddit. Addititonally, incorporating media into posts could be an effective strategy for increasing engagement. However, it’s important to consider other factors that might influence engagement, such as the time of posting, the specific subreddit community, and the quality of the media content."
  },
  {
    "objectID": "eda_exec_summary.html#top-content-creators-and-their-engagement-with-the-users",
    "href": "eda_exec_summary.html#top-content-creators-and-their-engagement-with-the-users",
    "title": "Exploratory Data Analysis - Executive Summary",
    "section": "Top content creators and their engagement with the users",
    "text": "Top content creators and their engagement with the users\nWe identified the most engaging authors in each subreddit based on comments, scores, and post counts. Interestingly, in the television subreddit, the author with the highest score is also the one with the most posts. However, in the movie subreddit, this correlation doesn’t hold. Notably, in the anime subreddit, bots are the ones ruling both popularity and engagement.\nFrom this we see that each subreddit has unique engagement dynamics. In the TV subreddit, the top author is both prolific and engaging, but this trend is less clear in movies. The prevalence of bots driving engagement in anime challenges the idea that the most engaging content has to be human-created. It emphasizes the importance of understanding each community’s dynamics in assessing author roles in content creation and discussions."
  }
]