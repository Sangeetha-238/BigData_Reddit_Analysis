{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59faa85-3a66-4488-ac01-9a94973a5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"sk2224-projectdata\"\n",
    "!aws s3 mb s3://{bucket_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac43a4c-90c7-4333-8c10-294a7febc15e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# install spark-nlp\n",
    "%pip install spark-nlp==5.1.3\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f252d-17b2-49c5-a5f8-6ffc5c9bdf6f",
   "metadata": {},
   "source": [
    "### Starting Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbe5fe6-6a0c-4b07-b0f4-cd63f2d2f5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-44e4036b-aa68-4a54-9d07-ccdb0aeaabac;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.1.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.15.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      ":: resolution report :: resolve 3890ms :: artifacts dl 416ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.1.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.15.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 by [com.amazonaws#aws-java-sdk-bundle;1.11.828] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   77  |   0   |   0   |   4   ||   73  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-44e4036b-aa68-4a54-9d07-ccdb0aeaabac\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 73 already retrieved (0kB/47ms)\n",
      "23/11/21 01:33:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
    "    )\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc0fce-2844-4a85-bd95-5cea5d03c7b7",
   "metadata": {},
   "source": [
    "### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a189c51f-b028-4cee-8ef6-12b4d38a1b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7b6cd-22bd-404d-8d25-e1615c9d467d",
   "metadata": {},
   "source": [
    "### Reading Sumbmissions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fb2f5a-a80f-49da-b30d-380045d2e355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "reading submissions from s3a://sk2224-projectdata/submissions/suggestions/yyyy=*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/21 01:33:53 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 267 ms, sys: 15.4 ms, total: 283 ms\n",
      "Wall time: 8.51 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/21 01:34:00 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bucket = \"sk2224-projectdata\"\n",
    "session = sagemaker.Session()\n",
    "output_prefix_data_comments = \"submissions/suggestions/yyyy=*\"\n",
    "s3_path = f\"s3a://{bucket}/{output_prefix_data_comments}\"\n",
    "print(f\"reading submissions from {s3_path}\")\n",
    "submissions = spark.read.parquet(s3_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a12d09b-97f3-4a90-afc2-c5a756d0c634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adserver_click_url: string (nullable = true)\n",
      " |-- adserver_imp_pixel: string (nullable = true)\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- brand_safe: boolean (nullable = true)\n",
      " |-- contest_mode: boolean (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- crosspost_parent: string (nullable = true)\n",
      " |-- crosspost_parent_list: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- approved_at_utc: string (nullable = true)\n",
      " |    |    |-- approved_by: string (nullable = true)\n",
      " |    |    |-- archived: boolean (nullable = true)\n",
      " |    |    |-- author: string (nullable = true)\n",
      " |    |    |-- author_flair_css_class: string (nullable = true)\n",
      " |    |    |-- author_flair_text: string (nullable = true)\n",
      " |    |    |-- banned_at_utc: string (nullable = true)\n",
      " |    |    |-- banned_by: string (nullable = true)\n",
      " |    |    |-- brand_safe: boolean (nullable = true)\n",
      " |    |    |-- can_gild: boolean (nullable = true)\n",
      " |    |    |-- can_mod_post: boolean (nullable = true)\n",
      " |    |    |-- clicked: boolean (nullable = true)\n",
      " |    |    |-- contest_mode: boolean (nullable = true)\n",
      " |    |    |-- created: double (nullable = true)\n",
      " |    |    |-- created_utc: double (nullable = true)\n",
      " |    |    |-- distinguished: string (nullable = true)\n",
      " |    |    |-- domain: string (nullable = true)\n",
      " |    |    |-- downs: long (nullable = true)\n",
      " |    |    |-- edited: boolean (nullable = true)\n",
      " |    |    |-- gilded: long (nullable = true)\n",
      " |    |    |-- hidden: boolean (nullable = true)\n",
      " |    |    |-- hide_score: boolean (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- is_crosspostable: boolean (nullable = true)\n",
      " |    |    |-- is_reddit_media_domain: boolean (nullable = true)\n",
      " |    |    |-- is_self: boolean (nullable = true)\n",
      " |    |    |-- is_video: boolean (nullable = true)\n",
      " |    |    |-- likes: string (nullable = true)\n",
      " |    |    |-- link_flair_css_class: string (nullable = true)\n",
      " |    |    |-- link_flair_text: string (nullable = true)\n",
      " |    |    |-- locked: boolean (nullable = true)\n",
      " |    |    |-- media: string (nullable = true)\n",
      " |    |    |-- mod_reports: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- num_comments: long (nullable = true)\n",
      " |    |    |-- num_crossposts: long (nullable = true)\n",
      " |    |    |-- num_reports: string (nullable = true)\n",
      " |    |    |-- over_18: boolean (nullable = true)\n",
      " |    |    |-- parent_whitelist_status: string (nullable = true)\n",
      " |    |    |-- permalink: string (nullable = true)\n",
      " |    |    |-- pinned: boolean (nullable = true)\n",
      " |    |    |-- quarantine: boolean (nullable = true)\n",
      " |    |    |-- removal_reason: string (nullable = true)\n",
      " |    |    |-- report_reasons: string (nullable = true)\n",
      " |    |    |-- saved: boolean (nullable = true)\n",
      " |    |    |-- score: long (nullable = true)\n",
      " |    |    |-- secure_media: string (nullable = true)\n",
      " |    |    |-- selftext: string (nullable = true)\n",
      " |    |    |-- selftext_html: string (nullable = true)\n",
      " |    |    |-- spoiler: boolean (nullable = true)\n",
      " |    |    |-- stickied: boolean (nullable = true)\n",
      " |    |    |-- subreddit: string (nullable = true)\n",
      " |    |    |-- subreddit_id: string (nullable = true)\n",
      " |    |    |-- subreddit_name_prefixed: string (nullable = true)\n",
      " |    |    |-- subreddit_type: string (nullable = true)\n",
      " |    |    |-- suggested_sort: string (nullable = true)\n",
      " |    |    |-- thumbnail: string (nullable = true)\n",
      " |    |    |-- thumbnail_height: string (nullable = true)\n",
      " |    |    |-- thumbnail_width: string (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- ups: long (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_reports: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- view_count: string (nullable = true)\n",
      " |    |    |-- visited: boolean (nullable = true)\n",
      " |    |    |-- whitelist_status: string (nullable = true)\n",
      " |-- disable_comments: boolean (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- domain_override: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- embed_type: string (nullable = true)\n",
      " |-- embed_url: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- hidden: boolean (nullable = true)\n",
      " |-- hide_score: boolean (nullable = true)\n",
      " |-- href_url: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imp_pixel: string (nullable = true)\n",
      " |-- is_crosspostable: boolean (nullable = true)\n",
      " |-- is_reddit_media_domain: boolean (nullable = true)\n",
      " |-- is_self: boolean (nullable = true)\n",
      " |-- is_video: boolean (nullable = true)\n",
      " |-- link_flair_css_class: string (nullable = true)\n",
      " |-- link_flair_text: string (nullable = true)\n",
      " |-- locked: boolean (nullable = true)\n",
      " |-- media: struct (nullable = true)\n",
      " |    |-- event_id: string (nullable = true)\n",
      " |    |-- oembed: struct (nullable = true)\n",
      " |    |    |-- author_name: string (nullable = true)\n",
      " |    |    |-- author_url: string (nullable = true)\n",
      " |    |    |-- cache_age: long (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- height: long (nullable = true)\n",
      " |    |    |-- html: string (nullable = true)\n",
      " |    |    |-- provider_name: string (nullable = true)\n",
      " |    |    |-- provider_url: string (nullable = true)\n",
      " |    |    |-- thumbnail_height: long (nullable = true)\n",
      " |    |    |-- thumbnail_url: string (nullable = true)\n",
      " |    |    |-- thumbnail_width: long (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      " |    |    |-- width: long (nullable = true)\n",
      " |    |-- reddit_video: struct (nullable = true)\n",
      " |    |    |-- dash_url: string (nullable = true)\n",
      " |    |    |-- duration: long (nullable = true)\n",
      " |    |    |-- fallback_url: string (nullable = true)\n",
      " |    |    |-- height: long (nullable = true)\n",
      " |    |    |-- hls_url: string (nullable = true)\n",
      " |    |    |-- is_gif: boolean (nullable = true)\n",
      " |    |    |-- scrubber_media_url: string (nullable = true)\n",
      " |    |    |-- transcoding_status: string (nullable = true)\n",
      " |    |    |-- width: long (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- media_embed: struct (nullable = true)\n",
      " |    |-- content: string (nullable = true)\n",
      " |    |-- height: long (nullable = true)\n",
      " |    |-- scrolling: boolean (nullable = true)\n",
      " |    |-- width: long (nullable = true)\n",
      " |-- mobile_ad_url: string (nullable = true)\n",
      " |-- num_comments: long (nullable = true)\n",
      " |-- num_crossposts: long (nullable = true)\n",
      " |-- original_link: string (nullable = true)\n",
      " |-- over_18: boolean (nullable = true)\n",
      " |-- parent_whitelist_status: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- pinned: boolean (nullable = true)\n",
      " |-- post_hint: string (nullable = true)\n",
      " |-- preview: struct (nullable = true)\n",
      " |    |-- enabled: boolean (nullable = true)\n",
      " |    |-- images: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |-- variants: struct (nullable = true)\n",
      " |    |    |    |    |-- gif: struct (nullable = true)\n",
      " |    |    |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |-- mp4: struct (nullable = true)\n",
      " |    |    |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |-- nsfw: struct (nullable = true)\n",
      " |    |    |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |-- obfuscated: struct (nullable = true)\n",
      " |    |    |    |    |    |-- resolutions: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |    |    |    |    |    |-- source: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- height: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- width: long (nullable = true)\n",
      " |-- promoted: boolean (nullable = true)\n",
      " |-- promoted_by: string (nullable = true)\n",
      " |-- promoted_display_name: string (nullable = true)\n",
      " |-- promoted_url: string (nullable = true)\n",
      " |-- retrieved_on: timestamp (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- secure_media: struct (nullable = true)\n",
      " |    |-- event_id: string (nullable = true)\n",
      " |    |-- oembed: struct (nullable = true)\n",
      " |    |    |-- author_name: string (nullable = true)\n",
      " |    |    |-- author_url: string (nullable = true)\n",
      " |    |    |-- cache_age: long (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- height: long (nullable = true)\n",
      " |    |    |-- html: string (nullable = true)\n",
      " |    |    |-- provider_name: string (nullable = true)\n",
      " |    |    |-- provider_url: string (nullable = true)\n",
      " |    |    |-- thumbnail_height: long (nullable = true)\n",
      " |    |    |-- thumbnail_url: string (nullable = true)\n",
      " |    |    |-- thumbnail_width: long (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- version: string (nullable = true)\n",
      " |    |    |-- width: long (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- secure_media_embed: struct (nullable = true)\n",
      " |    |-- content: string (nullable = true)\n",
      " |    |-- height: long (nullable = true)\n",
      " |    |-- media_domain_url: string (nullable = true)\n",
      " |    |-- scrolling: boolean (nullable = true)\n",
      " |    |-- width: long (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- spoiler: boolean (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- suggested_sort: string (nullable = true)\n",
      " |-- third_party_trackers: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- third_party_tracking: string (nullable = true)\n",
      " |-- third_party_tracking_2: string (nullable = true)\n",
      " |-- thumbnail: string (nullable = true)\n",
      " |-- thumbnail_height: long (nullable = true)\n",
      " |-- thumbnail_width: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- whitelist_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submissions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874677d3-559d-4a1a-8cea-7a5f701533b2",
   "metadata": {},
   "source": [
    "#### Removing unwanted rows, and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3eb95f8-ea4d-4a6d-a1b1-f50fc76180e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out rows where 'text' or 'author' is '[deleted]'\n",
    "submissions_filtered = submissions.filter((submissions.selftext != '[deleted]') & (submissions.selftext != '[removed]') & (submissions.author != '[deleted]') & (submissions.author != '[removed]')& (submissions.title != '[deleted]') &  (submissions.title != '[removed]')) \n",
    "\n",
    "# Show the filtered DataFrame\n",
    "submissions_filtered = submissions_filtered.select(\"subreddit\", \"author\", \"title\", \"selftext\",\n",
    "                             \"created_utc\", \"num_comments\", \"score\", \n",
    "                             \"over_18\", \"media\", \"pinned\", \"locked\", \n",
    "                             \"disable_comments\", \"domain\", \"hidden\", \n",
    "                             \"distinguished\", \"hide_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d750f47-01e0-4eed-b728-d733e7afac29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+--------------------+--------------------+-------------------+------------+-----+-------+-----+------+------+----------------+--------------------+------+-------------+----------+\n",
      "|       subreddit|           author|               title|            selftext|        created_utc|num_comments|score|over_18|media|pinned|locked|disable_comments|              domain|hidden|distinguished|hide_score|\n",
      "+----------------+-----------------+--------------------+--------------------+-------------------+------------+-----+-------+-----+------+------+----------------+--------------------+------+-------------+----------+\n",
      "|    Animesuggest|      RektoriusYT|Never watched mec...|So basically for ...|2021-02-18 15:46:14|          12|    3|  false| null| false| false|            null|   self.Animesuggest| false|         null|     false|\n",
      "|    Animesuggest|           bff_op|Anime like Highsc...|Hello I need sugg...|2021-02-18 15:50:06|           6|    1|  false| null| false| false|            null|   self.Animesuggest| false|         null|     false|\n",
      "|MovieSuggestions|    scottymac0707|        Blockbusters|Drop your best bl...|2021-02-18 15:50:53|           8|    3|  false| null| false| false|            null|self.MovieSuggest...| false|         null|     false|\n",
      "|MovieSuggestions|       stone78221|Family Movies lik...|I like Conviction...|2021-02-18 15:51:41|           4|    1|  false| null| false| false|            null|self.MovieSuggest...| false|         null|     false|\n",
      "|MovieSuggestions|Mighty_Dragon_001|Looking for movie...|I really really l...|2021-02-18 15:54:03|           5|    4|  false| null| false| false|            null|self.MovieSuggest...| false|         null|     false|\n",
      "+----------------+-----------------+--------------------+--------------------+-------------------+------------+-----+-------+-----+------+------+----------------+--------------------+------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submissions_filtered.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b3e55-366c-418a-98cb-37aebce441a0",
   "metadata": {},
   "source": [
    "#### Combining 'title' and 'selftext' columns into a new column 'RedditText'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "200a82ea-c173-4c0e-a3df-d02d81801b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# Combine 'title' and 'selftext' columns into a new column 'RedditText'\n",
    "submissions_combined = submissions_filtered.withColumn(\n",
    "    \"RedditText\", concat_ws(\" \", \"title\", \"selftext\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa0a6f8-ff37-420b-af95-507226bc2853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+--------------------+-------------------+------------+-----+\n",
      "|       subreddit|           author|          RedditText|        created_utc|num_comments|score|\n",
      "+----------------+-----------------+--------------------+-------------------+------------+-----+\n",
      "|    Animesuggest|      RektoriusYT|Never watched mec...|2021-02-18 15:46:14|          12|    3|\n",
      "|    Animesuggest|           bff_op|Anime like Highsc...|2021-02-18 15:50:06|           6|    1|\n",
      "|MovieSuggestions|    scottymac0707|Blockbusters Drop...|2021-02-18 15:50:53|           8|    3|\n",
      "|MovieSuggestions|       stone78221|Family Movies lik...|2021-02-18 15:51:41|           4|    1|\n",
      "|MovieSuggestions|Mighty_Dragon_001|Looking for movie...|2021-02-18 15:54:03|           5|    4|\n",
      "+----------------+-----------------+--------------------+-------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 5 rows of the DataFrame with the new column\n",
    "submissions_combined.select(\"subreddit\", \"author\", \"RedditText\", \"created_utc\", \"num_comments\", \"score\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15e8133e-6278-4e47-8732-ad498753e077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions_combined = submissions_combined.select(\"subreddit\", \"author\", \"RedditText\", \"created_utc\", \"num_comments\", \"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92f6df-9869-480d-9815-794baecc5107",
   "metadata": {},
   "source": [
    "### Creating Pipeline for text Cleaning on the data\n",
    "\n",
    "Setting up  a Spark NLP pipeline for text preprocessing:\n",
    "\n",
    "DocumentAssembler:\n",
    "\n",
    "Gathers input text data into a Spark DataFrame.\n",
    "Input Column: \"RedditText\"\n",
    "Output Column: \"document\"\n",
    "Tokenizer:\n",
    "\n",
    "Breaks down documents into individual words.\n",
    "Input Column: \"document\"\n",
    "Output Column: \"token\"\n",
    "Normalizer:\n",
    "\n",
    "Converts text to lowercase.\n",
    "Input Column: \"token\"\n",
    "Output Column: \"normalized\"\n",
    "Lemmatizer:\n",
    "\n",
    "Performs lemmatization on normalized words.\n",
    "Input Column: \"normalized\"\n",
    "Output Column: \"lemma\"\n",
    "StopWordsCleaner:\n",
    "\n",
    "Removes common English stopwords.\n",
    "There is no library in spark nlp helce using nltk stopwords\n",
    "Input Column: \"lemma\"\n",
    "Output Column: \"clean_lemma\"\n",
    "Finisher:\n",
    "\n",
    "Converts processed tokens into human-readable output.\n",
    "Input Column: \"clean_lemma\"\n",
    "Pipeline:\n",
    "\n",
    "Defines the sequence of stages in the NLP pipeline.\n",
    "The resulting \"clean_lemma\" column contains preprocessed text ready for further analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf31d8d-f5dc-4c0b-9810-bbd4c356af47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                LemmatizerModel, StopWordsCleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75177933-8623-4d56-ae16-a5877d6a0691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"RedditText\")\\\n",
    "    .setOutputCol(\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7024c5ae-604d-4711-b795-56e1eaaf7d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regex Tokenizer to break words\n",
    "tokenizer = Tokenizer() \\\n",
    "     .setInputCols(['document']) \\\n",
    "     .setOutputCol('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd739ffd-ab0d-4865-b75b-6ee253e006a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalizing and setting case insensitive to be true\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['token']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b16f225-07c5-40b2-9b4e-08daead90b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19ba4c12-3e14-4821-8a12-ae835e0b2905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Now you can use stopwords from nltk.corpus\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f161f236-0287-4040-9bc6-30d17b5500a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemma']) \\\n",
    "     .setOutputCol('clean_lemma') \\\n",
    "     .setCaseSensitive(False) \\\n",
    "     .setStopWords(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7831fcc5-a551-4a8a-97d7-2abff741f0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finisher converts tokens to human-readable output\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['clean_lemma']) \\\n",
    "     .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21c4c4df-e284-4fe0-8062-224dc9da554c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6ca153-f9d1-452b-b9ba-e6eedf9cd968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        tokenizer,\n",
    "        normalizer,\n",
    "        lemmatizer,  # Add the lemmatizer stage here\n",
    "        stopwords_cleaner.setInputCols(['lemma']),\n",
    "        finisher\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dd791c8-15ca-489a-83ea-83bbc59e62b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# Create an empty DataFrame with the same schema as your actual data\n",
    "empty_df = spark.createDataFrame([], schema=submissions_combined.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "646dd74f-2b81-4189-9f65-30e93fefef08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/spark-core_2.12-3.4.0.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline model on the empty DataFrame\n",
    "pipeline_model = pipeline.fit(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05d1a291-28e5-4481-a75f-a56e00921700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform your actual DataFrame using the fitted pipeline model\n",
    "submission_clean = pipeline_model.transform(submissions_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ccdccd-0262-4021-b1d6-0bfed40c6d78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|finished_clean_lemma|\n",
      "+--------------------+\n",
      "|[never, watch, me...|\n",
      "|[anime, like, hig...|\n",
      "|[blockbuster, dro...|\n",
      "|[family, movie, l...|\n",
      "|[look, movie, lik...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submission_clean.select(submission_clean.finished_clean_lemma).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56d3728c-ff32-4c43-8e69-e8d1180ea657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subreddit',\n",
       " 'author',\n",
       " 'RedditText',\n",
       " 'created_utc',\n",
       " 'num_comments',\n",
       " 'score',\n",
       " 'document',\n",
       " 'token',\n",
       " 'normalized',\n",
       " 'lemma',\n",
       " 'clean_lemma',\n",
       " 'finished_clean_lemma']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b106ba72-5c28-4717-86b8-967a760d0985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove 'lemma', 'clean_lemma' from the DataFrame\n",
    "submission_clean = submission_clean.drop('lemma', 'clean_lemma',\n",
    " 'document',\n",
    " 'token',\n",
    " 'normalized',)\n",
    "\n",
    "# Rename 'finished_clean_lemma' to 'clean_RedditText'\n",
    "submission_clean = submission_clean.withColumnRenamed('finished_clean_lemma', 'clean_RedditText')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db58a3c0-4420-4ab4-8480-97f0eab7b581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+--------------------+-------------------+------------+-----+--------------------+\n",
      "|       subreddit|           author|          RedditText|        created_utc|num_comments|score|    clean_RedditText|\n",
      "+----------------+-----------------+--------------------+-------------------+------------+-----+--------------------+\n",
      "|    Animesuggest|      RektoriusYT|Never watched mec...|2021-02-18 15:46:14|          12|    3|[never, watch, me...|\n",
      "|    Animesuggest|           bff_op|Anime like Highsc...|2021-02-18 15:50:06|           6|    1|[anime, like, hig...|\n",
      "|MovieSuggestions|    scottymac0707|Blockbusters Drop...|2021-02-18 15:50:53|           8|    3|[blockbuster, dro...|\n",
      "|MovieSuggestions|       stone78221|Family Movies lik...|2021-02-18 15:51:41|           4|    1|[family, movie, l...|\n",
      "|MovieSuggestions|Mighty_Dragon_001|Looking for movie...|2021-02-18 15:54:03|           5|    4|[look, movie, lik...|\n",
      "+----------------+-----------------+--------------------+-------------------+------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submission_clean.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcb369-a18c-47bf-83d0-5684bd34cb48",
   "metadata": {},
   "source": [
    "### Finding the most used words in the data for Movie and Anime Subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f17b09-ffc5-4e65-ab8e-d72bd9b0fe8d",
   "metadata": {},
   "source": [
    "Conversion: The code first converts the array of strings in the 'clean_RedditText' column into a single string, using a space as the separator.\n",
    "\n",
    "Split and Explode: It then splits the string into individual words and explodes the resulting array, creating a new row for each word.\n",
    "\n",
    "Grouping and Counting: After that, it groups the DataFrame by the 'word' column and counts the occurrences of each word.\n",
    "\n",
    "Sorting: Finally, it sorts the result by the count of occurrences in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57dbafef-6f31-4c12-803f-5650bba0cfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'subreddit' is a column in your DataFrame\n",
    "submission_clean_movie = submission_clean.filter(submission_clean['subreddit'] == 'MovieSuggestions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "553cee4b-79e0-4bba-819d-d120e53ca49e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+-------------------+------------+-----+--------------------+\n",
      "|       subreddit|              author|          RedditText|        created_utc|num_comments|score|    clean_RedditText|\n",
      "+----------------+--------------------+--------------------+-------------------+------------+-----+--------------------+\n",
      "|MovieSuggestions|       scottymac0707|Blockbusters Drop...|2021-02-18 15:50:53|           8|    3|[blockbuster, dro...|\n",
      "|MovieSuggestions|          stone78221|Family Movies lik...|2021-02-18 15:51:41|           4|    1|[family, movie, l...|\n",
      "|MovieSuggestions|   Mighty_Dragon_001|Looking for movie...|2021-02-18 15:54:03|           5|    4|[look, movie, lik...|\n",
      "|MovieSuggestions|  theRealestAintReal|Detective movies ...|2021-06-30 22:21:40|          13|    3|[detective, movie...|\n",
      "|MovieSuggestions|Lazy-Paleontologist9|Larger than life ...|2021-06-30 22:24:27|          11|    2|[large, life, fil...|\n",
      "+----------------+--------------------+--------------------+-------------------+------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submission_clean_movie.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "316e5b45-48d6-419a-ba49-716ce908e78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import explode, split\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "#'clean_RedditText' is the column containing tokenized and cleaned words\n",
    "words_column = 'clean_RedditText'\n",
    "\n",
    "# Convert array of strings to a single string with space as a separator\n",
    "submission_clean_movie = submission_clean_movie.withColumn('clean_text', concat_ws(' ', words_column))\n",
    "\n",
    "# Split the words and explode the array to create a new row for each word\n",
    "word_count = submission_clean_movie.select(explode(split('clean_text', ' ')).alias('word'))\n",
    "\n",
    "# Group by word and count occurrences\n",
    "word_count = word_count.groupBy('word').count()\n",
    "\n",
    "# Sort by count in descending order\n",
    "word_count = word_count.sort(desc('count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f4e8dde-23eb-4744-bfcb-0f46ef0817b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=======================================================>(96 + 1) / 97]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     word|count|\n",
      "+---------+-----+\n",
      "|    movie|72187|\n",
      "|     like|27869|\n",
      "|     look|17926|\n",
      "|    watch|17677|\n",
      "|       im|15842|\n",
      "|     film|14465|\n",
      "|     good|13604|\n",
      "|      see|10841|\n",
      "|     love| 9366|\n",
      "|something| 8858|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show the top words\n",
    "word_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86296e58-508c-41f6-9eef-7d0a2972f459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'subreddit' is a column in your DataFrame\n",
    "submission_clean_anime = submission_clean.filter(submission_clean['subreddit'] == 'Animesuggest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "672dc6b4-d262-4e25-a2ab-706e66a657be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import explode, split\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "#'clean_RedditText' is the column containing tokenized and cleaned words\n",
    "words_column = 'clean_RedditText'\n",
    "\n",
    "# Convert array of strings to a single string with space as a separator\n",
    "submission_clean_anime = submission_clean_anime.withColumn('clean_text', concat_ws(' ', words_column))\n",
    "\n",
    "# Split the words and explode the array to create a new row for each word\n",
    "word_count_a = submission_clean_anime.select(explode(split('clean_text', ' ')).alias('word'))\n",
    "\n",
    "# Group by word and count occurrences\n",
    "word_count_a = word_count_a.groupBy('word').count()\n",
    "\n",
    "# Sort by count in descending order\n",
    "word_count_a = word_count_a.sort(desc('count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48cf77aa-f757-4428-ad09-fad4c0235827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=======================================================>(96 + 1) / 97]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     word|count|\n",
      "+---------+-----+\n",
      "|    anime|73632|\n",
      "|     like|45544|\n",
      "|    watch|34677|\n",
      "|     look|23720|\n",
      "|       im|23468|\n",
      "|     good|19125|\n",
      "|      one|17144|\n",
      "|something|16997|\n",
      "|       mc|15713|\n",
      "|character|14876|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "word_count_a.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a2cc5-9621-4f8c-8d55-169a46867013",
   "metadata": {},
   "source": [
    "Looking at the words people use the most, it seems like people on Reddit really enjoy chatting about their favorite anime and movies. Now, we're going to dig into the comments and pick out the names of the movies and anime that everyone is talking about the most. This way, we can find out which ones are super popular among the community."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d72db-c2ae-4630-8dee-4a81177acc04",
   "metadata": {},
   "source": [
    "### TF-IDF to find important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8011304e-3d25-4e7c-a2f8-7fc37efb88ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adbf37ea-4396-4401-8c3a-777b27df298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the tokenized words into sentences for TF-IDF vectorization\n",
    "concat_udf = udf(lambda x: ' '.join(x), StringType())\n",
    "submission_clean_movie = submission_clean_movie.withColumn(\"concatenated_text\", concat_udf(submission_clean_movie[\"clean_RedditText\"]))\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"concatenated_text\", outputCol=\"words\")\n",
    "submission_clean_movie = tokenizer.transform(submission_clean_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1fbcd-d287-4816-88ff-ba028b3c803d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# TF\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "submission_clean_movie = hashingTF.transform(submission_clean_movie)\n",
    "\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(submission_clean_movie)\n",
    "submission_clean_movie = idfModel.transform(submission_clean_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26d81ac0-08da-448a-9144-dccb92c86b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_scores = idfModel.idf.toArray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "623d296d-c120-49c9-a8cc-093bef1716fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                           |words                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,1,3,7,8,13,15,17,19],[0.328260144767276,1.2564512272285042,0.18337126468235918,0.3113800523433715,0.47305072296526773,0.35463092534401797,0.31670543709976823,0.29719711749051475,0.07176626435254482])                                                                                                                                                                                                                                     |[blockbuster, drop, good, blockbuster, movie, choice, look, one, watch, afternoon, thank, suggestion, advance]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|(20,[0,1,3,4,6,10,11,12,13,17,19],[0.328260144767276,0.6282256136142521,0.18337126468235918,0.8329179030414992,0.4918452395525049,0.6234350097115241,0.7833015867288391,1.4139115577825587,0.35463092534401797,0.5943942349810295,0.14353252870508965])                                                                                                                                                                                            |[family, movie, like, conviction, like, conviction, movie, sister, try, save, brother, similar, kind, movie, show, family, loyalty, care, stand, together, different, genre, crime, comedy, drama]                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|(20,[0,1,3,4,5,8,10,11,12,15,16,17,19],[0.328260144767276,0.6282256136142521,0.18337126468235918,0.4164589515207496,0.989029437525459,0.15768357432175592,0.6234350097115241,0.39165079336441955,0.5655646231130235,0.9501163112993047,0.8256013657718139,0.5943942349810295,0.10764939652881723])                                                                                                                                                 |[look, movie, like, contact, really, really, love, film, mix, futuristic, space, alien, time, strong, story, awesome, protagonist, someone, recommend, great, movie, like, one]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|(20,[0,1,3,4,5,7,8,10,12,13,14,15,18,19],[0.656520289534552,1.2564512272285042,1.100227588094155,0.4164589515207496,1.978058875050918,0.3113800523433715,0.47305072296526773,0.41562333980768273,0.28278231155651173,0.7092618506880359,0.7401704405258923,0.6334108741995365,0.6001222500965673,0.25118192523390687])                                                                                                                             |[detective, movie, like, bone, collector, along, come, spider, im, look, detective, movie, fun, watch, keep, engage, throughout, film, im, really, interest, smart, detective, movie, clever, story, im, open, oscar, worthy, movie, indie, b, movie, fit, bill]                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "|(20,[0,2,3,4,5,6,7,8,9,10,11,12,15,17,18,19],[0.984780434301828,1.98734770360836,0.9168563234117959,0.4164589515207496,0.4945147187627295,0.4918452395525049,0.9341401570301145,0.31536714864351184,0.4329524983232148,0.20781166990384137,0.7833015867288391,0.28278231155651173,0.6334108741995365,0.8915913524715442,0.6001222500965673,0.07176626435254482])                                                                                   |[large, life, film, fill, challenge, big, question, know, film, along, line, space, odyssey, tree, life, basically, film, inherently, deep, provoke, lot, question, may, even, answer, dont, mind, genre, even, film, lighthouse, would, consider, along, line]                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|(20,[0,1,3,4,5,6,8,10,11,12,13,14,15,17,18,19],[0.656520289534552,0.6282256136142521,0.36674252936471835,0.4164589515207496,0.4945147187627295,0.1639484131841683,0.31536714864351184,0.20781166990384137,1.5666031734576782,0.28278231155651173,2.1277855520641076,0.7401704405258923,1.266821748399073,0.29719711749051475,0.6001222500965673,0.07176626435254482])                                                                              |[didnt, like, shaun, dead, world, end, think, alright, definitely, check, hot, fuzz, one, good, comedy, movie, history, put, hot, fuzz, long, time, see, two, think, ok, hot, fuzz, different, level, holy, shit]                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|(20,[0,1,2,3,4,6,7,8,10,12,13,15,16,17,19],[0.656520289534552,0.6282256136142521,0.49683692590209,0.36674252936471835,0.4164589515207496,0.3278968263683366,1.245520209373486,0.15768357432175592,0.6234350097115241,0.28278231155651173,0.7092618506880359,1.266821748399073,0.8256013657718139,1.4859855874525738,0.07176626435254482])                                                                                                          |[movie, doormatpeople, pleasinggenerally, nice, people, finally, decide, stand, look, moviesseries, genuinely, nice, people, finally, snap, point, decide, stand, change, approach, towards, life, preferably, story, center, around, niceness, take, toll, everyday, life, thank, advance]                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|(20,[0,2,3,6,8,9,10,11,12,13,15,16,17,18,19],[0.328260144767276,0.49683692590209,0.5501137940470775,0.3278968263683366,0.15768357432175592,0.4329524983232148,0.20781166990384137,0.39165079336441955,0.28278231155651173,0.35463092534401797,0.9501163112993047,0.41280068288590693,0.29719711749051475,1.2002445001931346,0.17941566088136207])                                                                                                  |[look, movie, im, look, movie, similar, vein, like, zero, dark, thirty, spy, game, kingdom, etc, basically, political, intrigue, type, stuff, deal, specifically, middle, east, suggestion]                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|(20,[0,3,4],[0.328260144767276,0.18337126468235918,0.4164589515207496])                                                                                                                                                                                                                                                                                                                                                                            |[without, remorse, trailer]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|(20,[0,1,4,7,8,10,11,12,13,17,18,19],[0.328260144767276,1.2564512272285042,1.2493768545622488,0.622760104686743,0.31536714864351184,0.41562333980768273,0.39165079336441955,0.28278231155651173,0.35463092534401797,1.188788469962059,0.6001222500965673,0.10764939652881723])                                                                                                                                                                     |[movie, like, mommy, peanut, butter, falcon, manchester, sea, hunt, also, would, like, everyone, drop, letterboxd, username, know, everybody, watch, thank, advance, shruthikv, username]                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|(20,[0,3,4,7,9,10,11,13,15,17],[0.656520289534552,0.5501137940470775,0.8329179030414992,0.3113800523433715,0.4329524983232148,0.20781166990384137,0.39165079336441955,0.7092618506880359,0.31670543709976823,0.8915913524715442])                                                                                                                                                                                                                  |[protagonist, introvert, protagonist, introvert, different, take, people, around, mock, silly, shit, people, real, life, like, mr, robot]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,10,11,12,13,15,17,18,19],[1.313040579069104,0.6282256136142521,0.49683692590209,0.18337126468235918,0.8329179030414992,0.4945147187627295,0.8197420659208415,0.622760104686743,1.2614685945740474,0.6234350097115241,1.1749523800932586,0.28278231155651173,0.35463092534401797,0.31670543709976823,0.5943942349810295,1.2002445001931346,0.07176626435254482])                                                             |[good, recent, slasher, movie, im, mood, watch, something, like, scream, happy, death, day, right, something, corny, good, plot, well, make, also, suburban, theme, would, nice, would, well, except, something, lovable, scream, overall, good, watch, slasher, type, movie, suggestion, appreicated, thank]                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|(20,[0,3,8,11,14,15,16,19],[0.656520289534552,0.36674252936471835,0.15768357432175592,0.39165079336441955,0.37008522026294616,0.31670543709976823,1.2384020486577207,0.03588313217627241])                                                                                                                                                                                                                                                         |[suggestion, film, student, movie, think, film, student, watch, would, love, see, suggest]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|(20,[0,2,3,4,5,6,7,8,9,10,11,13,14,15,17,19],[0.328260144767276,0.49683692590209,0.5501137940470775,2.082294757603748,0.4945147187627295,0.6557936527366732,0.9341401570301145,0.15768357432175592,0.8659049966464296,0.8312466796153655,0.39165079336441955,0.7092618506880359,0.37008522026294616,0.31670543709976823,0.5943942349810295,0.17941566088136207])                                                                                   |[gritty, new, yorkcity, drama, watch, lot, movie, within, genre, im, love, citytime, period, long, gritty, feel, movie, like, mean, street, dog, day, afternoon, taxi, driver, uncut, gem, see, requiem, dream, kind, like, right, thing, hour, thank, help]                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|(20,[0,2,5,6,8,10,12,13,15,19],[0.328260144767276,0.49683692590209,0.4945147187627295,0.4918452395525049,0.47305072296526773,0.20781166990384137,0.28278231155651173,0.35463092534401797,0.31670543709976823,0.07176626435254482])                                                                                                                                                                                                                 |[great, movie, watch, stoney, baloney, look, new, stuff, watch, stone, whether, trippy, comedy, leave, suggestion]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,13,15,16,17,18,19],[1.313040579069104,2.5129024544570084,1.49051077770627,0.36674252936471835,0.8329179030414992,0.989029437525459,0.4918452395525049,0.622760104686743,0.31536714864351184,0.8659049966464296,0.8312466796153655,1.1749523800932586,1.4185237013760719,0.31670543709976823,0.8256013657718139,1.4859855874525738,0.6001222500965673,0.07176626435254482])                                          |[movie, dont, stop, moment, would, like, watch, movie, never, stop, little, subjective, think, mean, film, never, leave, hang, fall, asleep, always, something, happen, doesnt, need, necesserily, fast, pace, something, make, care, go, guess, boring, part, example, project, x, dont, breathe, anyway, idk, express, clearly, dont, post, often, thx]                                                                                                                                                                                                                                                                                                             |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[1.969560868603656,1.2564512272285042,2.98102155541254,1.4669701174588734,2.082294757603748,0.989029437525459,1.1476388922891783,1.868280314060229,1.4191521688958033,1.2988574949696443,0.6234350097115241,1.1749523800932586,1.131129246226047,0.7092618506880359,1.8504261013147307,0.9501163112993047,1.6512027315436277,1.188788469962059,2.400489000386269,0.2870650574101793])      |[look, old, dumb, fun, movie, ive, recently, watch, tokyo, drift, first, time, love, remind, different, time, use, watch, tv, happen, upon, random, thing, hook, remind, old, murican, badass, eg, chuck, norris, avoid, death, hour, straight, skinny, asian, martial, artist, eg, bruce, lee, beat, buff, guy, film, also, funny, stuff, like, rush, hour, come, america, love, feel, mindlessly, glue, actionpacked, blockbuster, flick, hour, im, big, movie, guy, feel, free, drop, popular, title, without, assume, already, know, id, love, revisit, something, forget, even, watch, tv, year, ago, edit, know, tokyo, drift, id, prefer, stuff, somewhat, old]|\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.328260144767276,1.8846768408427563,0.99367385180418,0.36674252936471835,1.2493768545622488,1.978058875050918,0.8197420659208415,0.9341401570301145,0.6307342972870237,2.164762491616074,0.41562333980768273,0.7833015867288391,1.6966938693390703,0.7092618506880359,0.37008522026294616,1.266821748399073,1.2384020486577207,0.8915913524715442,0.6001222500965673,0.3229481895864517])|[blizzard, soul, also, know, rifleman, okay, real, good, sugestion, war, drama, movie, blizzard, soul, also, sometimes, name, rifleman, boy, join, latvian, rifleman, regiment, ww, independence, war, im, shure, english, dub, subtitle, dunno, find, tough, movie, good, one, movie, get, emotional, movie, realy, good, atmosphere, even, say, caries, historic, weight, im, say, well, tough, act, sometimes, bit, stiff, atmosphere, gorgeus, story, tell, meaningfull, beutifull, realy, recomend]                                                                                                                                                              |\n",
      "|(20,[0,2,3,4,7,8,9,10,11,12,13,17,19],[0.984780434301828,0.99367385180418,0.36674252936471835,1.2493768545622488,0.622760104686743,0.31536714864351184,1.2988574949696443,0.41562333980768273,0.7833015867288391,0.28278231155651173,0.35463092534401797,0.29719711749051475,0.21529879305763447])                                                                                                                                                 |[look, movie, single, father, hi, im, work, personal, project, right, im, look, movie, focus, relationship, single, father, child, preferably, son, come, term, death, wivesmothers, respectively, help, would, really, appreciate, lt]                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19],[0.656520289534552,2.5129024544570084,0.99367385180418,0.5501137940470775,1.6658358060829983,0.4945147187627295,0.3278968263683366,1.5569002617168577,1.1037850202522914,0.8659049966464296,1.2468700194230482,1.1749523800932586,1.4139115577825587,2.1277855520641076,0.6334108741995365,0.8256013657718139,0.8915913524715442,2.400489000386269,0.43059758611526894])                      |[action, movie, bored, dad, dad, doesnt, really, like, stuff, tv, since, like, one, movie, channel, air, good, movie, every, blue, moon, hes, always, ask, get, action, movie, watch, dont, watch, action, movie, im, rec, far, ive, show, john, wick, trilogy, like, well, enough, fall, asleep, scene, drag, especially, long, morocco, fight, scene, parabellum, fall, asleep, easily, also, show, old, guard, didnt, watch, say, like, also, like, chinese, action, movie, like, crouch, tiger, hide, dragon, thank]                                                                                                                                              |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 193, in manager\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 874, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submission_clean_movie.select(\"features\", \"words\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc33ec-b582-4459-bcaf-37445e449af3",
   "metadata": {},
   "source": [
    "TF-IDF vectorization on a DataFrame containing cleaned and tokenized Reddit comments related to movies. The process begins by concatenating the tokenized words into a single text column using a User Defined Function (UDF). Subsequently, a Tokenizer is employed to split the concatenated text into individual words. The term frequencies of these words are then calculated using HashingTF, creating a sparse feature vector. The code further computes the Inverse Document Frequency (IDF) to weigh down common words and highlight distinctive ones. Finally, the TF-IDF features are obtained, and the resulting DataFrame displays both the TF-IDF features and the original words. This representation provides a numerical foundation for the textual data, enabling applications in natural language processing tasks such as text classification or clustering within the context of movie-related Reddit discussions. Fine-tuning parameters or preprocessing steps may be required based on the specific analytical goals and characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ecef7-00df-4778-b7c7-a170d9923254",
   "metadata": {},
   "source": [
    "While this approach offers valuable insights into key words and their numerical representations through TF-IDF, its utility for our specific analysis is limited. The TF-IDF vectorization is designed to capture the significance of words in individual documents relative to the entire dataset. However, in our context of extracting movie and anime names from Reddit comments, this numerical representation may not be the most effective. Instead, we will explore alternative methods to identify and extract specific movie and anime references from the comments, allowing us to delve deeper into the most mentioned or discussed titles. This decision is rooted in the recognition that TF-IDF, while beneficial for certain tasks, may not be the optimal choice for our current objective of extracting and analyzing movie and anime references from the Reddit data."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
