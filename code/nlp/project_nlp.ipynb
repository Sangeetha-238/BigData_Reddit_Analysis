{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827213fe-227b-4700-bbfa-7f48da550b37",
   "metadata": {},
   "source": [
    "# NATURAL LANGUAGE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e619bd0-50ae-4fa2-9a3d-3457dd6ae9ac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425fc27c-2360-4db6-a2bd-406d2cb80a56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - openjdk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       h06a4308_0         123 KB\n",
      "    certifi-2023.11.17         |  py310h06a4308_0         158 KB\n",
      "    openjdk-11.0.13            |       h87a67e3_0       341.0 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       341.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  openjdk            pkgs/main/linux-64::openjdk-11.0.13-h87a67e3_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.7.2~ --> pkgs/main::ca-certificates-2023.08.22-h06a4308_0 \n",
      "  certifi            conda-forge/noarch::certifi-2023.7.22~ --> pkgs/main/linux-64::certifi-2023.11.17-py310h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openjdk-11.0.13      | 341.0 MB  |                                       |   0% \n",
      "ca-certificates-2023 | 123 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "certifi-2023.11.17   | 158 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "ca-certificates-2023 | 123 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pyspark==3.4.0\n",
      "  Using cached pyspark-3.4.0-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7 (from pyspark==3.4.0)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spark-nlp==5.1.3\n",
      "  Obtaining dependency information for spark-nlp==5.1.3 from https://files.pythonhosted.org/packages/cd/7d/bc0eca4c9ec4c9c1d9b28c42c2f07942af70980a7d912d0aceebf8db32dd/spark_nlp-5.1.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached spark_nlp-5.1.3-py2.py3-none-any.whl.metadata (53 kB)\n",
      "Using cached spark_nlp-5.1.3-py2.py3-none-any.whl (537 kB)\n",
      "Installing collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-5.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# install spark-nlp\n",
    "%pip install spark-nlp==5.1.3\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d2755-5198-4ac7-9700-35399aaa6722",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94c795-e658-401b-8536-1da097f8ca28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.executor.cores\", \"3\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\"\n",
    "    )\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# spark = (\n",
    "#     SparkSession.builder.appName(\"PySparkApp\")\n",
    "#     .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "#     .config(\n",
    "#         \"fs.s3a.aws.credentials.provider\",\n",
    "#         \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
    "#     )\n",
    "#     .getOrCreate()\n",
    "# )\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d949b-85c7-46db-a22e-27e8c78fbfa3",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86264bea-19b6-4234-857d-91a746b1ce23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b50182f-784b-427f-aa82-9614eb8edfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.0\n",
      "sparknlp version: 5.1.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"sparknlp version: {sparknlp.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a33cf-458c-49d9-8abd-44528c4d577d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2965f34c-dd03-4c7a-8409-b817faa5e666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "reading comments from s3a://project-group34/project/comments/yyyy=*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/24 22:32:41 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 191 ms, sys: 16.4 ms, total: 207 ms\n",
      "Wall time: 6.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bucket = \"project-group34\"\n",
    "session = sagemaker.Session()\n",
    "output_prefix_data_comments = \"project/comments/yyyy=*\"\n",
    "s3_path = f\"s3a://{bucket}/{output_prefix_data_comments}\"\n",
    "print(f\"reading comments from {s3_path}\")\n",
    "comments = spark.read.parquet(s3_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3de33fb-8b6c-4e53-a7fd-7cad7ad64964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comments = comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44851682-34f5-451f-83c3-6e1864b44534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- retrieved_on: timestamp (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e028b72-b313-41d3-8c35-d32366ffd6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|       subreddit|         author|                body| parent_id|     id|        created_utc|score|controversiality|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|    Animesuggest|        Athenza|{Now and Then, He...| t3_m3ygv3|gqscelh|2021-03-13 10:15:52|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Ima, Soko ni Ir...|t1_gqscelh|gqscf1z|2021-03-13 10:16:05|    1|               0|\n",
      "|    Animesuggest|      [deleted]|           [deleted]| t3_m3vnjl|gqscjse|2021-03-13 10:18:25|    1|               0|\n",
      "|MovieSuggestions|      katnip_fl|       Jacobs Ladder| t3_m3rw47|gqscl5i|2021-03-13 10:19:07|    2|               0|\n",
      "|    Animesuggest|        Athenza|{Kino no Tabi: Th...| t3_m3xpu6|gqscnqz|2021-03-13 10:20:26|    1|               0|\n",
      "|    Animesuggest|    Dropsoftime|Try Mahouka kouko...| t3_m43dco|gqscnr8|2021-03-13 10:20:26|    3|               0|\n",
      "|MovieSuggestions|   alienstabler|[Holes (2003)](ht...| t3_l20wrm|gqscozr|2021-03-13 10:21:04|    1|               0|\n",
      "|    Animesuggest|       Roboragi|**Kino no Tabi: T...|t1_gqscnqz|gqscp63|2021-03-13 10:21:10|    1|               0|\n",
      "|    Animesuggest|crash-scientist|I didn’t mean to ...|t1_gqs4syw|gqscp6i|2021-03-13 10:21:10|    2|               0|\n",
      "|    Animesuggest|        dorting|    Watch Evangelion| t3_m3vnjl|gqscp9a|2021-03-13 10:21:13|    2|               0|\n",
      "|MovieSuggestions| ThalesHedonist|V for Vendetta\\n\\...| t3_m3rw47|gqscpsz|2021-03-13 10:21:29|    3|               0|\n",
      "|    Animesuggest|        Athenza|{Vampire Hunter D...| t3_m3wy06|gqscspa|2021-03-13 10:22:51|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Vampire Hunter ...|t1_gqscspa|gqsct5l|2021-03-13 10:23:05|    2|               0|\n",
      "|MovieSuggestions|   jaymewheeler|Synchronic was co...| t3_m3rw47|gqscu76|2021-03-13 10:23:37|    2|               0|\n",
      "|    Animesuggest|        Arvidex|- {Wonder Egg Pei...| t3_m3vnjl|gqscuva|2021-03-13 10:23:57|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Wonder Egg Prio...|t1_gqscuva|gqscvqx|2021-03-13 10:24:25|    1|               0|\n",
      "|    Animesuggest|        mgd5800|{Nejimaki Seirei ...| t3_m43dco|gqscxbt|2021-03-13 10:25:12|    2|               0|\n",
      "|MovieSuggestions|     SwissBliss|Climax!!!!! Sound...| t3_m3rw47|gqscxjk|2021-03-13 10:25:19|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Nejimaki Seirei...|t1_gqscxbt|gqscy94|2021-03-13 10:25:40|    2|               0|\n",
      "|    Animesuggest|     DyeDye1234|{is the order a r...| t3_m41ujb|gqsd2ku|2021-03-13 10:27:55|    1|               0|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display a subset of columns\n",
    "comments.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"id\", \"created_utc\", \"score\", \"controversiality\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a88822-d093-4f36-a039-ef010069a135",
   "metadata": {},
   "source": [
    "### DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d420acb-8838-4688-bbf6-adf92e693b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out rows where 'body' or 'author' is '[deleted]'\n",
    "comments_filtered = comments.filter((comments.body != '[deleted]') & (comments.author != '[deleted]'))\n",
    "\n",
    "# Show the filtered DataFrame\n",
    "comments_filtered = comments_filtered.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"id\", \"created_utc\", \"score\", \"controversiality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e777ed5-c00b-4985-862b-65bc91bb48ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|       subreddit|         author|                body| parent_id|     id|        created_utc|score|controversiality|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|    Animesuggest|        Athenza|{Now and Then, He...| t3_m3ygv3|gqscelh|2021-03-13 10:15:52|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Ima, Soko ni Ir...|t1_gqscelh|gqscf1z|2021-03-13 10:16:05|    1|               0|\n",
      "|MovieSuggestions|      katnip_fl|       Jacobs Ladder| t3_m3rw47|gqscl5i|2021-03-13 10:19:07|    2|               0|\n",
      "|    Animesuggest|        Athenza|{Kino no Tabi: Th...| t3_m3xpu6|gqscnqz|2021-03-13 10:20:26|    1|               0|\n",
      "|    Animesuggest|    Dropsoftime|Try Mahouka kouko...| t3_m43dco|gqscnr8|2021-03-13 10:20:26|    3|               0|\n",
      "|MovieSuggestions|   alienstabler|[Holes (2003)](ht...| t3_l20wrm|gqscozr|2021-03-13 10:21:04|    1|               0|\n",
      "|    Animesuggest|       Roboragi|**Kino no Tabi: T...|t1_gqscnqz|gqscp63|2021-03-13 10:21:10|    1|               0|\n",
      "|    Animesuggest|crash-scientist|I didn’t mean to ...|t1_gqs4syw|gqscp6i|2021-03-13 10:21:10|    2|               0|\n",
      "|    Animesuggest|        dorting|    Watch Evangelion| t3_m3vnjl|gqscp9a|2021-03-13 10:21:13|    2|               0|\n",
      "|MovieSuggestions| ThalesHedonist|V for Vendetta\\n\\...| t3_m3rw47|gqscpsz|2021-03-13 10:21:29|    3|               0|\n",
      "|    Animesuggest|        Athenza|{Vampire Hunter D...| t3_m3wy06|gqscspa|2021-03-13 10:22:51|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Vampire Hunter ...|t1_gqscspa|gqsct5l|2021-03-13 10:23:05|    2|               0|\n",
      "|MovieSuggestions|   jaymewheeler|Synchronic was co...| t3_m3rw47|gqscu76|2021-03-13 10:23:37|    2|               0|\n",
      "|    Animesuggest|        Arvidex|- {Wonder Egg Pei...| t3_m3vnjl|gqscuva|2021-03-13 10:23:57|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Wonder Egg Prio...|t1_gqscuva|gqscvqx|2021-03-13 10:24:25|    1|               0|\n",
      "|    Animesuggest|        mgd5800|{Nejimaki Seirei ...| t3_m43dco|gqscxbt|2021-03-13 10:25:12|    2|               0|\n",
      "|MovieSuggestions|     SwissBliss|Climax!!!!! Sound...| t3_m3rw47|gqscxjk|2021-03-13 10:25:19|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Nejimaki Seirei...|t1_gqscxbt|gqscy94|2021-03-13 10:25:40|    2|               0|\n",
      "|    Animesuggest|     DyeDye1234|{is the order a r...| t3_m41ujb|gqsd2ku|2021-03-13 10:27:55|    1|               0|\n",
      "|    Animesuggest|       Roboragi|**Gochuumon wa Us...|t1_gqsd2ku|gqsd3ca|2021-03-13 10:28:18|    1|               0|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b6c736-63ab-48a9-ad83-b8d01bd74b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments_filtered = comments_filtered.where(col(\"subreddit\").isin(\"MovieSuggestions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947b6caf-ade3-4bd9-83af-504ad2266559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 384.9 MB\n",
      "[OK!]\n",
      "ner_dl_bert download started this may take some time.\n",
      "Approximate size to download 15.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# # Define the pipeline stages\n",
    "# document_assembler = DocumentAssembler() \\\n",
    "#     .setInputCol(\"body\") \\\n",
    "#     .setOutputCol(\"document\")\n",
    "\n",
    "# sentence_detector = SentenceDetector() \\\n",
    "#     .setInputCols([\"document\"]) \\\n",
    "#     .setOutputCol(\"sentence\")\n",
    "\n",
    "# tokenizer = Tokenizer() \\\n",
    "#     .setInputCols([\"sentence\"]) \\\n",
    "#     .setOutputCol(\"token\")\n",
    "\n",
    "# # Use a pretrained embeddings model, for example, BERT\n",
    "# embeddings = BertEmbeddings.pretrained(\"bert_base_cased\", \"en\") \\\n",
    "#     .setInputCols([\"sentence\", \"token\"]) \\\n",
    "#     .setOutputCol(\"embeddings\")\n",
    "\n",
    "# ner_model = NerDLModel.pretrained(\"ner_dl_bert\", \"en\") \\\n",
    "#     .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "#     .setOutputCol(\"ner\")\n",
    "\n",
    "# ner_converter = NerConverter() \\\n",
    "#     .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "#     .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# # Build the pipeline\n",
    "# nlp_pipeline = Pipeline(stages=[\n",
    "#     document_assembler,\n",
    "#     sentence_detector,\n",
    "#     tokenizer,\n",
    "#     embeddings,\n",
    "#     ner_model,\n",
    "#     ner_converter\n",
    "# ])\n",
    "\n",
    "# # Apply the pipeline to your DataFrame\n",
    "# model = nlp_pipeline.fit(comments_filtered_movies)\n",
    "# result = model.transform(comments_filtered_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eca482-e01f-46c0-bef7-cdf0d85c31da",
   "metadata": {},
   "source": [
    "### MOVIE SUGGESTIONS EXTRACTION USING NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0b79e-9454-42ee-aa3f-3d9cba5051ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel, NerConverter\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline stages\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"body\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Use GloVe embeddings\n",
    "embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\", \"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# Use a lighter NER model\n",
    "ner_model = NerDLModel.pretrained(\"ner_dl\", \"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# Build the pipeline\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    embeddings,\n",
    "    ner_model,\n",
    "    ner_converter\n",
    "])\n",
    "\n",
    "# Apply the pipeline to your DataFrame\n",
    "model = nlp_pipeline.fit(comments_filtered)\n",
    "result = model.transform(comments_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5701312-6234-4c8d-90cf-6115201169fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = result.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"id\", \"created_utc\", \"score\", \"controversiality\", \"ner_chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf7fe31-d1f3-483a-a6c1-7a5800eb7fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+\n",
      "|       subreddit|        author|                body|parent_id|     id|        created_utc|score|controversiality|           ner_chunk|\n",
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|t3_m3rw47|gqscl5i|2021-03-13 10:19:07|    2|               0|[{chunk, 0, 12, J...|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|t3_l20wrm|gqscozr|2021-03-13 10:21:04|    1|               0|                  []|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|t3_m3rw47|gqscpsz|2021-03-13 10:21:29|    3|               0|[{chunk, 6, 19, V...|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|t3_m3rw47|gqscu76|2021-03-13 10:23:37|    2|               0|                  []|\n",
      "|MovieSuggestions|    SwissBliss|Climax!!!!! Sound...|t3_m3rw47|gqscxjk|2021-03-13 10:25:19|    2|               0|[{chunk, 94, 99, ...|\n",
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b1ce5f-3f64-445f-9fdb-3abeca3b39f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Define a UDF to filter and extract movie names\n",
    "def extract_movies(chunks):\n",
    "    movie_names = [chunk.result for chunk in chunks if chunk.metadata['entity'] in ['PERSON', 'ORG']]\n",
    "    return movie_names\n",
    "\n",
    "extract_movie_names_udf = udf(extract_movies, ArrayType(StringType()))\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "movies_df = result.withColumn(\"movie_names\", extract_movie_names_udf(F.col(\"ner_chunk\")))\n",
    "\n",
    "# # Display the results\n",
    "# movies_df.select(\"body\", \"movie_names\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6330f600-0952-4de7-a000-8920992ac0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+------------------+\n",
      "|       subreddit|        author|                body|parent_id|     id|        created_utc|score|controversiality|           ner_chunk|       movie_names|\n",
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|t3_m3rw47|gqscl5i|2021-03-13 10:19:07|    2|               0|[{chunk, 0, 12, J...|                []|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|t3_l20wrm|gqscozr|2021-03-13 10:21:04|    1|               0|                  []|                []|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|t3_m3rw47|gqscpsz|2021-03-13 10:21:29|    3|               0|[{chunk, 6, 19, V...|[Vendetta\\n\\nPulp]|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|t3_m3rw47|gqscu76|2021-03-13 10:23:37|    2|               0|                  []|                []|\n",
      "|MovieSuggestions|    SwissBliss|Climax!!!!! Sound...|t3_m3rw47|gqscxjk|2021-03-13 10:25:19|    2|               0|[{chunk, 94, 99, ...|                []|\n",
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d3957-9459-4cf6-86db-4842375c7594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_df.write.parquet(\"s3a://project-group34/project/suggestions/all_movies/ner/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ce9d0-20bb-40a0-9fd8-14df88980c20",
   "metadata": {},
   "source": [
    "### MOVIE SUGGESTIONS EXTRACTION USING REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79b4d39-2bf3-4f0d-a818-dc75766c2ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.executor.cores\", \"3\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\"\n",
    "    )\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9f17fa-e68b-4f74-b173-ba8af6ddf9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd02d47-e510-4e80-9016-bc7b23120b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/25 19:35:08 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_df = spark.read.parquet(\"s3a://project-group34/project/suggestions/all_movies/ner/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775fa5ab-e8d9-4565-b0ee-791bb970c8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+------------------+\n",
      "|       subreddit|        author|                body|parent_id|     id|        created_utc|score|controversiality|           ner_chunk|       movie_names|\n",
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|t3_m3rw47|gqscl5i|2021-03-13 10:19:07|    2|               0|[{chunk, 0, 12, J...|                []|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|t3_l20wrm|gqscozr|2021-03-13 10:21:04|    1|               0|                  []|                []|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|t3_m3rw47|gqscpsz|2021-03-13 10:21:29|    3|               0|[{chunk, 6, 19, V...|[Vendetta\\n\\nPulp]|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|t3_m3rw47|gqscu76|2021-03-13 10:23:37|    2|               0|                  []|                []|\n",
      "|MovieSuggestions|    SwissBliss|Climax!!!!! Sound...|t3_m3rw47|gqscxjk|2021-03-13 10:25:19|    2|               0|[{chunk, 94, 99, ...|                []|\n",
      "+----------------+--------------+--------------------+---------+-------+-------------------+-----+----------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f71f554-ac90-40cc-a3b7-270a4b9364f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField\n",
    "\n",
    "# import spacy\n",
    "import re\n",
    "\n",
    "# # Load spaCy model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Define schema for the UDF output\n",
    "# movie_schema = StructType([\n",
    "#     StructField(\"movie_positions\", ArrayType(ArrayType(StringType()))),\n",
    "#     StructField(\"movie_names\", ArrayType(StringType()))\n",
    "# ])\n",
    "\n",
    "# # UDF to extract movie names\n",
    "# @udf(movie_schema)\n",
    "# def extract_movie_names_udf(text):\n",
    "#     doc = nlp(text)\n",
    "#     movie_positions = []\n",
    "#     movie_names = []\n",
    "\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == \"ORG\" or ent.label_ == \"PERSON\":\n",
    "#             movie_positions.append([ent.start_char, ent.end_char])\n",
    "#             movie_names.append(ent.text)\n",
    "\n",
    "#     return (movie_positions, movie_names)\n",
    "\n",
    "# UDF to remove movie names\n",
    "@udf(StringType())\n",
    "def remove_movie_names_udf(text, movie_names):\n",
    "    if movie_names:\n",
    "        for name in movie_names:\n",
    "            text = text.replace(name, ' ')\n",
    "        return ' '.join(text.split())\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# UDF to extract movie names using regex\n",
    "@udf(ArrayType(StringType()))\n",
    "def extract_movie_names_regex_udf(text, movie_names):\n",
    "    movie_name_pattern = r'(?:\\\"([^\\\"]+)\\\"|([A-Z][a-z]*(?:\\s+(?:[a-z]+\\s+)*[A-Z][a-z]*)*)(?: \\(\\d{4}\\))?)'\n",
    "\n",
    "    movie_matches = re.findall(movie_name_pattern, text)\n",
    "    movies = [match[0] or match[1] or match[2] for match in movie_matches]\n",
    "    return movie_names + movies\n",
    "\n",
    "# Remove movie names from the 'body' text\n",
    "df_removed_movie_names = movies_df.withColumn(\"body_no_movies\", remove_movie_names_udf(movies_df[\"body\"], movies_df[\"movie_names\"]))\n",
    "\n",
    "# If you still want to use the regex method to supplement the NER extraction\n",
    "df_final = df_removed_movie_names.withColumn(\"additional_movie_names\", extract_movie_names_regex_udf(df_removed_movie_names[\"body_no_movies\"], df_removed_movie_names[\"movie_names\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650710b5-93ed-4e6a-9a06-db79c132e5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.select(\"subreddit\", \"author\", \"body\", \"created_utc\", \"score\", \"controversiality\", \"additional_movie_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a0e16c-0636-48d1-a7a8-55f3804cc180",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-------------------+-----+----------------+----------------------+\n",
      "|       subreddit|        author|                body|        created_utc|score|controversiality|additional_movie_names|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+----------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|2021-03-13 10:19:07|    2|               0|       [Jacobs Ladder]|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|2021-03-13 10:21:04|    1|               0|               [Holes]|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|  [Vendetta\\n\\nPulp...|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|2021-03-13 10:23:37|    2|               0|          [Synchronic]|\n",
      "|MovieSuggestions|    SwissBliss|Climax!!!!! Sound...|2021-03-13 10:25:19|    2|               0|  [Climax, Sounds, ...|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99f4093-46a3-4b13-b16b-4552e64f7338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "eng_stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56618de-947e-48cb-9217-5632507c0325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "def remove_stop_word_from_movie_names(movies):\n",
    "    # Filter out single-word movie names that are in the stop words list\n",
    "    return [movie for movie in movies if not (len(movie.split()) == 1 and movie.lower() in eng_stopwords)]\n",
    "\n",
    "remove_stop_word_udf = udf(remove_stop_word_from_movie_names, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26181e2-3222-4943-a839-abb6243e0608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.withColumn(\"movie_names_final\", remove_stop_word_udf(df_final[\"additional_movie_names\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a661d923-6587-4213-89df-3d8ff00ed87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.select(\"subreddit\", \"author\", \"body\", \"created_utc\", \"score\", \"controversiality\", \"movie_names_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3756089-8449-4a00-b7dc-80cbc4c795f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a UDF to filter out single-letter movie names\n",
    "def remove_single_letter_movies(movie_names):\n",
    "    return [name for name in movie_names if len(name.strip()) > 1]\n",
    "\n",
    "remove_single_letter_movies_udf = udf(remove_single_letter_movies, ArrayType(StringType()))\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "df_final = df_final.withColumn(\"movie_names_final_cleaned\", remove_single_letter_movies_udf(\"movie_names_final\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e704fdaa-eeda-4e91-a5fc-067f94f4ae08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.select(\"subreddit\", \"author\", \"body\", \"created_utc\", \"score\", \"controversiality\", \"movie_names_final_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19bd1b8f-3ebd-4139-b72a-87bee952a073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|       subreddit|             author|                body|        created_utc|score|controversiality|movie_names_final_cleaned|\n",
      "+----------------+-------------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|MovieSuggestions|          katnip_fl|       Jacobs Ladder|2021-03-13 10:19:07|    2|               0|          [Jacobs Ladder]|\n",
      "|MovieSuggestions|       alienstabler|[Holes (2003)](ht...|2021-03-13 10:21:04|    1|               0|                  [Holes]|\n",
      "|MovieSuggestions|     ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|\n",
      "|MovieSuggestions|       jaymewheeler|Synchronic was co...|2021-03-13 10:23:37|    2|               0|             [Synchronic]|\n",
      "|MovieSuggestions|         SwissBliss|Climax!!!!! Sound...|2021-03-13 10:25:19|    2|               0|     [Climax, Sounds, ...|\n",
      "|MovieSuggestions|        frankocozzo|• Sorry To Bother...|2021-03-13 10:29:35|    2|               0|     [Bacurau  \\n• Coh...|\n",
      "|MovieSuggestions|Organized-Konfusion|I would also sugg...|2021-03-13 10:31:39|    2|               0|     [I would also sug...|\n",
      "|MovieSuggestions|      jonny_designs|Midsommar. Was no...|2021-03-13 10:37:18|    2|               0|     [Midsommar, Was n...|\n",
      "|MovieSuggestions|     LaughingGor108|Reservoir Dogs\\n\\...|2021-03-13 10:39:56|    1|               0|     [Reservoir Dogs\\n...|\n",
      "|MovieSuggestions|           jonnyzat|             Hoodlum|2021-03-13 10:43:46|    1|               0|                [Hoodlum]|\n",
      "|MovieSuggestions|     LaughingGor108|Crime/Thriller:\\n...|2021-03-13 10:46:55|    1|               0|     [No Mercy, Asura,...|\n",
      "|MovieSuggestions|     LaughingGor108|Don't Breathe\\n\\n...|2021-03-13 10:50:09|    1|               0|     [Don't Breathe, O...|\n",
      "|MovieSuggestions|           ALT236-1|This is a new one...|2021-01-18 23:56:21|    1|               0|                  [Thank]|\n",
      "|MovieSuggestions|   ChickenInAPotpie|Just realized the...|2021-01-18 23:58:12|    2|               0|                       []|\n",
      "|MovieSuggestions|            maaximo|     Children of Men|2021-01-18 23:59:41|    5|               0|        [Children of Men]|\n",
      "|MovieSuggestions|           ALT236-1|So many, thank yo...|2021-01-18 23:59:50|    1|               0|     [Grand Budapest H...|\n",
      "|MovieSuggestions|         Tevesh_CKP|        Pacific Rim.|2021-01-19 00:01:32|    1|               0|            [Pacific Rim]|\n",
      "|MovieSuggestions|         Snoo_93607|Be careful with i...|2021-01-19 00:03:10|    2|               0|                       []|\n",
      "|MovieSuggestions|         Tevesh_CKP|Wolf Warrior inst...|2021-01-19 00:03:28|    1|               0|           [Wolf Warrior]|\n",
      "|MovieSuggestions|           ALT236-1|The anime? Wow, h...|2021-01-19 00:04:15|    1|               0|             [Wow, Thank]|\n",
      "+----------------+-------------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c66411-5008-4af3-80ba-c4169a3f1bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.write.parquet(\"s3a://project-group34/project/suggestions/all_movies/cleaned_with_regex/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd56bd0-e74c-4397-b4a4-75ce215cccd5",
   "metadata": {},
   "source": [
    "### EXPLODING SUGGESTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17139f6-e01a-4a96-b585-fce8427ae5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.executor.cores\", \"3\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\"\n",
    "    )\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4364e33d-e613-411b-b691-c99fd59d024f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb06a42-0243-4c33-a2ff-6ec20a6fb99e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/25 20:48:39 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final = spark.read.parquet(\"s3a://project-group34/project/suggestions/all_movies/cleaned_with_regex/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e8006d-8e62-43af-b70a-c0b454be3884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|       subreddit|        author|                body|        created_utc|score|controversiality|movie_names_final_cleaned|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|2021-03-13 10:19:07|    2|               0|          [Jacobs Ladder]|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|2021-03-13 10:21:04|    1|               0|                  [Holes]|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|2021-03-13 10:23:37|    2|               0|             [Synchronic]|\n",
      "|MovieSuggestions|    SwissBliss|Climax!!!!! Sound...|2021-03-13 10:25:19|    2|               0|     [Climax, Sounds, ...|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a68d353-4736-4e39-8ff9-9997e7734f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col, count, split\n",
    "\n",
    "# Flatten the movie_names column\n",
    "df_flattened = df_final.withColumn(\"movie_name\", explode(col(\"movie_names_final_cleaned\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a01a806-96bd-4d68-b07e-8f1cedc3206f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of non-movie names to be removed\n",
    "non_movie_terms = [\n",
    "    \"Movie\", \"Suggestions\", \"Please\", \"Directv\", \"Thanks\", \"Editing\", \"Thank\",\n",
    "    \"Netflix\", \"Amazon Prime Video\", \"Google Play Movies\", \"Amazon Video\", \"Vudu\",\n",
    "    \"Tubi Tv\", \"Hoopla\", \"Apple Itunes\", \"Fandangonow\", \"Hulu\", \"Rotten Tomatoes\",\n",
    "    \"Dailymotion\", \"Fubotv\", \"Dplay\", \"Showtime\", \"Hbo Now\", \"Amc On Demand\",\n",
    "    \"Notes\", \"Great\", \"Also\", \"Note\", \"Tube\", \"Zz\", \"Db\", \"One\", \"Make\", \"Yes\",\n",
    "    \"Good\", \"Oh\", \"Yeah\", \"Love\", \"P.S\", \"Man\", \"Replying\", \"In the comments on this post I\",\n",
    "    \"Piracy\", \"Title\", \"Characters Minimum\", \"Maybe\", \"Fv\", \"OP\", \"Definitely\",\n",
    "    \"Edit\", \"Came\", \"Mr\", \"American\", \"Really\", \"Well\", \"Life\", \"Sorry\", \"French\",\n",
    "    \"But I\", \"Japanese\", \"Never\", \"Lol\", \"Watch\", \"House\", \"Link\", \"Like\", \"Dead\",\n",
    "    \"!&lt\", \"Absolutely\", \"Mother\", \"Girl\", \"Nobody\", \n",
    "    \"Redbox\", \"M the Creator\", \"Metacritic\", \"Korean\", \"Dprogram\",\n",
    "    \"Microsoft Store\", \"Showtime Amazon Channel\", \"Watched\", \"Hbo Now Amazon Channel\",\n",
    "    \"IMO\", \"Matched\", \"Loved\", \"Still\", \"Seen\", \"Go\", \"List\", \"Let\", \"Best\", \"Day\",\n",
    "    \"Men\", \"Time\", \"World\", \"Even\", \"Identity\", \"Manchester\", \"And I\", \"Devil\", \"Super\",\n",
    "    \"Cbs\", \"Disney\", \"Amazing\", \"English\", \"Baby\", \"Blue\", \"Check\", \"Dr\", \"Nice\",\n",
    "    \"Character Minimum\", \"Excellent\", \"Night\", \"True\", \"I'm\", \"Pretty\", \"Hope\", \"Evil\",\n",
    "    \"Two\", \"Spider\", \"Hollywood\", \"Murder\", \"Probably\", \"Sling Tv\", \"Reddit\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e70c28a-00df-4986-9e08-9a2014e63520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out the non-movie names and streaming services\n",
    "df_flattened = df_flattened.filter(~col(\"movie_name\").isin(non_movie_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d373d16-91ef-4f29-a7e3-4929870afe35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|       subreddit|        author|                body|        created_utc|score|controversiality|movie_names_final_cleaned|          movie_name|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|2021-03-13 10:19:07|    2|               0|          [Jacobs Ladder]|       Jacobs Ladder|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|2021-03-13 10:21:04|    1|               0|                  [Holes]|               Holes|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|    Vendetta\\n\\nPulp|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|V for fiction Dan...|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|2021-03-13 10:23:37|    2|               0|             [Synchronic]|          Synchronic|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f1837e-43a0-49e5-9f82-d742591a5b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened.write.parquet(\"s3a://project-group34/project/suggestions/all_movies/flattened/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50857e02-c4ab-437b-806b-ff02467d1b45",
   "metadata": {},
   "source": [
    "### GROUPING SUGGESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9a83849-8875-4923-9caa-897ce55fcc2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.executor.cores\", \"3\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\"\n",
    "    )\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2a8d98d-65f0-4e6f-9d6c-4f7358d141a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a051e4-dc35-4c80-a2af-436c76315e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened = spark.read.parquet(\"s3a://project-group34/project/suggestions/all_movies/flattened/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcd05785-b473-41b7-82c3-5e31b72cb12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|       subreddit|        author|                body|        created_utc|score|controversiality|movie_names_final_cleaned|          movie_name|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|2021-03-13 10:19:07|    2|               0|          [Jacobs Ladder]|       Jacobs Ladder|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|2021-03-13 10:21:04|    1|               0|                  [Holes]|               Holes|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|    Vendetta\\n\\nPulp|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|V for fiction Dan...|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|2021-03-13 10:23:37|    2|               0|             [Synchronic]|          Synchronic|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed4d69f8-a5ee-4ea5-9979-0591bd56120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_frequency = df_flattened.groupBy(\"movie_name\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca437fc1-2e52-4121-9d49-4688c303cf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|movie_name|count|\n",
      "+----------+-----+\n",
      "|       Uoc|   20|\n",
      "|     Sword|   44|\n",
      "|        Gb|   19|\n",
      "|       Kin|   43|\n",
      "|    Heaven|  425|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_movie_frequency.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5628b4e2-6619-4ae3-a6e5-a24434c360b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Sort by count in descending order\n",
    "df_top_20_movies = df_movie_frequency.sort(desc('count')).limit(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc07c160-3dc8-4b6f-89ba-fe9ccac9fceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|    movie_name|count|\n",
      "+--------------+-----+\n",
      "|    Hereditary| 2733|\n",
      "|      Parasite| 2578|\n",
      "|  Interstellar| 2557|\n",
      "|         Alien| 2489|\n",
      "|     Prisoners| 2478|\n",
      "|     The Thing| 2468|\n",
      "|     Midsommar| 2446|\n",
      "|       Arrival| 2375|\n",
      "|    Fight Club| 2338|\n",
      "|        Oldboy| 2337|\n",
      "|  Blade Runner| 2317|\n",
      "|  Annihilation| 2171|\n",
      "|       Memento| 2159|\n",
      "|     Coherence| 2011|\n",
      "|     Inception| 1954|\n",
      "|Shutter Island| 1928|\n",
      "|           Saw| 1899|\n",
      "|  Nightcrawler| 1890|\n",
      "|The Lighthouse| 1829|\n",
      "|           Big| 1753|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top_20_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04d28105-d725-42e5-a483-d4ca4697e249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top_20_movies_pd = df_top_20_movies.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ca8293e-153e-49c3-aae6-3581f9f622dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_top_20_movies_pd.to_csv(\"../../data/csv/top20_movies_suggested.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf105a-f711-4199-8ae9-f94c63813742",
   "metadata": {},
   "source": [
    "### MERGE WITH EXTERNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498ef9ee-d03d-42df-b0b9-96a49d04f16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sentiment = spark.read.parquet(\"s3a://project-group34/project/sentiment_analysis/average_scores_per_movie/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152203a9-a95e-4140-907c-412f45d45b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+----------------------+-----------+\n",
      "|               title|average_positive_score|average_negative_score|num_reviews|\n",
      "+--------------------+----------------------+----------------------+-----------+\n",
      "|            The Menu|    0.8769120351379525|   0.12308796544559403|        315|\n",
      "|Jim Gaffigan: Obs...|                   1.0|          7.713538E-10|          5|\n",
      "|   Winter in Wartime|    0.7367684066794117|    0.2632315926923039|         67|\n",
      "|                7500|    0.7694758345625764|   0.23052416603253476|        157|\n",
      "|10 Things I Hate ...|     0.678140454627421|    0.3218595443279501|         77|\n",
      "+--------------------+----------------------+----------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sentiment.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf47f33e-be15-48d5-b33c-c1c7cdd3a2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Constants from your dataset\n",
    "C_positive = 0.7525733910082344  # Mean score of positive scores\n",
    "C_negative = 0.24742646776123378 # Mean score of negative scores\n",
    "m = 4  # Median number of reviews\n",
    "\n",
    "# Adding a new column for weighted rating\n",
    "positive_weighted_rating_df = df_sentiment.withColumn(\"weighted_rating\", \n",
    "                                   (col(\"num_reviews\") / (col(\"num_reviews\") + m) * col(\"average_positive_score\")) + \n",
    "                                   (m / (col(\"num_reviews\") + m) * C_positive))\n",
    "\n",
    "# Adding a new column for weighted rating\n",
    "negative_weighted_rating_df = df_sentiment.withColumn(\"weighted_rating\", \n",
    "                                   (col(\"num_reviews\") / (col(\"num_reviews\") + m) * col(\"average_negative_score\")) + \n",
    "                                   (m / (col(\"num_reviews\") + m) * C_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "714a3505-31b4-414c-8055-04e0b2932466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get top 20 movies with highest average positive scores\n",
    "top_20_positive = positive_weighted_rating_df.orderBy(desc(\"weighted_rating\")).limit(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abed9822-9e49-410a-a22a-f72d2591bb16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+----------------------+-----------+------------------+\n",
      "|               title|average_positive_score|average_negative_score|num_reviews|   weighted_rating|\n",
      "+--------------------+----------------------+----------------------+-----------+------------------+\n",
      "|Jim Allison: Brea...|                   1.0|  8.53145166666667E-22|         48|0.9809671839237104|\n",
      "|Hava Nagila (The ...|    0.9867567089655173|  0.013243287766424139|        116|0.9789505983669412|\n",
      "|      Trifling Women|    0.9992484054545456|  7.515981201820878E-4|         44|0.9786921542506863|\n",
      "|Blinky Bill the M...|    0.9980725209090909|  0.001927482015539...|         44|0.9776142600840194|\n",
      "|Molly's Theory of...|           0.999998057|  1.942951721449868E-6|         40|0.9775049055462031|\n",
      "|Blind Willow, Sle...|                   1.0|  8.522315000009178...|         32|0.9725081545564704|\n",
      "|California Typewr...|          0.9936297735|  0.006370226588242396|         40|0.9717155569098395|\n",
      "|          Half Magic|    0.9950310882352942|  0.004968912791776545|         34| 0.969509225369288|\n",
      "|   Things Never Said|    0.9922669266666667|  0.007733078447161946|         36|0.9682975731008235|\n",
      "|     I'm Leaving Now|    0.9990313485714285|  9.686501978153861E-4|         28|0.9682241038760293|\n",
      "|        The Farthest|    0.9999902925925925|   9.70705925925926E-6|         27|0.9680655310978367|\n",
      "|Bill Cunningham N...|    0.9795781553424656|  0.020421847234691988|         73|0.9677857000523757|\n",
      "|Richard Linklater...|    0.9953919132258064|  0.004608088904645...|         31|0.9676412249723696|\n",
      "|       Breaking Fast|    0.9993891259259259|  6.108749145002055E-4|         27|0.9675419343236431|\n",
      "|    Moonage Daydream|    0.9717051444774194|  0.028294855095545027|        155|0.9661923959624714|\n",
      "|              Suzi Q|    0.9946260866666667|  0.005373910904266718|         30|0.9661492989421452|\n",
      "|Salvatore: Shoema...|        0.992385378125|  0.007614620893583769|         32|0.9657396017786927|\n",
      "|Is the Man Who Is...|    0.9876368760526316|  0.012363124857894738|         38|0.9652498774769747|\n",
      "|The Eyes of Orson...|    0.9827869632608698|  0.017213035551343958|         46| 0.964369877480659|\n",
      "|       Gentleman Jim|    0.9999992286956522|  7.678868595652176E-7|         23| 0.963343549038257|\n",
      "+--------------------+----------------------+----------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_20_positive.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6519e871-5555-4b46-b768-d6c4770830d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|       subreddit|        author|                body|        created_utc|score|controversiality|movie_names_final_cleaned|          movie_name|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|MovieSuggestions|     katnip_fl|       Jacobs Ladder|2021-03-13 10:19:07|    2|               0|          [Jacobs Ladder]|       Jacobs Ladder|\n",
      "|MovieSuggestions|  alienstabler|[Holes (2003)](ht...|2021-03-13 10:21:04|    1|               0|                  [Holes]|               Holes|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|    Vendetta\\n\\nPulp|\n",
      "|MovieSuggestions|ThalesHedonist|V for Vendetta\\n\\...|2021-03-13 10:21:29|    3|               0|     [Vendetta\\n\\nPulp...|V for fiction Dan...|\n",
      "|MovieSuggestions|  jaymewheeler|Synchronic was co...|2021-03-13 10:23:37|    2|               0|             [Synchronic]|          Synchronic|\n",
      "+----------------+--------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dcd5e73-1478-4e0d-82ea-54ee2b5451fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, levenshtein\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ccd9c48-9da0-4097-9da0-a8b28e842699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_titles = [row['movie_name'] for row in df_top_20_movies.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11610975-9a36-418f-8132-3c7039919ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hereditary',\n",
       " 'Parasite',\n",
       " 'Interstellar',\n",
       " 'Alien',\n",
       " 'Prisoners',\n",
       " 'The Thing',\n",
       " 'Midsommar',\n",
       " 'Arrival',\n",
       " 'Fight Club',\n",
       " 'Oldboy',\n",
       " 'Blade Runner',\n",
       " 'Annihilation',\n",
       " 'Memento',\n",
       " 'Coherence',\n",
       " 'Inception',\n",
       " 'Shutter Island',\n",
       " 'Saw',\n",
       " 'Nightcrawler',\n",
       " 'The Lighthouse',\n",
       " 'Big']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76324bb6-7a9b-47e6-be77-6910bb73347b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the sentiment data DataFrame using the list\n",
    "filtered_sentiment_df = positive_weighted_rating_df.filter(positive_weighted_rating_df['title'].isin(movie_titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5580e980-fd05-4529-8136-bb2c1d8bb192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+----------------------+-----------+------------------+\n",
      "|         title|average_positive_score|average_negative_score|num_reviews|   weighted_rating|\n",
      "+--------------+----------------------+----------------------+-----------+------------------+\n",
      "|           Big|    0.8549865664698026|   0.14501343196273178|         57| 0.848270948406749|\n",
      "|Shutter Island|    0.7935697030268212|   0.20643029873821836|        259|0.7929461849733066|\n",
      "|The Lighthouse|    0.8567953555230218|    0.1432046450670607|        403| 0.855771061031476|\n",
      "|    Hereditary|    0.6772520104153956|    0.3227479907131384|        383|0.6780305259770788|\n",
      "|       Arrival|    0.9132867864014926|   0.08671321548572934|        440|0.9118389179745263|\n",
      "|         Alien|    0.6957981419639608|   0.30420185732468513|        124|0.6975723684965943|\n",
      "|      Parasite|     0.825085770061366|    0.1749142296239439|       1921|0.8249350949880088|\n",
      "|     Inception|    0.8771357714563982|   0.12286422944972214|        365|0.8757855017496431|\n",
      "|     The Thing|    0.7633445176656004|   0.23665548025341143|        128|0.7630181198881044|\n",
      "|     Prisoners|    0.7677609682564671|    0.2322390359840972|        254| 0.767525501942541|\n",
      "|    Fight Club|     0.817899975018882|    0.1821000252636096|        174|0.8164319618950472|\n",
      "|  Nightcrawler|    0.8417514086150262|    0.1582485925737861|        280|0.8404953801980292|\n",
      "|  Interstellar|      0.89228317674853|   0.10771682494792269|        375|0.8908086671364952|\n",
      "|     Midsommar|    0.7541998671040593|    0.2458001330190753|        401|0.7541838031426191|\n",
      "|  Blade Runner|    0.8798318843731172|   0.12016811486495839|        112|0.8754436604639834|\n",
      "|  Annihilation|     0.867995822337821|    0.1320041761747021|        329|0.8666093667062345|\n",
      "|        Oldboy|    0.7110966693962014|   0.28890333126306006|        300|0.7116424157332019|\n",
      "|           Saw|    0.6824277930089815|    0.3175722098283076|        188|0.6838891596339659|\n",
      "|     Coherence|    0.8787566895442769|   0.12124330903455703|         94|  0.87360635082852|\n",
      "|       Memento|    0.9059979402771241|   0.09400205504105454|        176|0.9025885058489265|\n",
      "+--------------+----------------------+----------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_sentiment_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c711ca4-115e-4729-a5d2-9d345945404a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_sentiment_df_pd = filtered_sentiment_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1db90e9-e2fb-4673-87aa-6fb967324e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_top_20_movies_pd.columns = [\"title\", \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fbf0d13-a401-4051-abbf-93db32c43839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hereditary</td>\n",
       "      <td>2733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parasite</td>\n",
       "      <td>2578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alien</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prisoners</td>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Thing</td>\n",
       "      <td>2468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Midsommar</td>\n",
       "      <td>2446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oldboy</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Blade Runner</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Annihilation</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Memento</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Coherence</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inception</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shutter Island</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Saw</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nightcrawler</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Lighthouse</td>\n",
       "      <td>1829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Big</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  count\n",
       "0       Hereditary   2733\n",
       "1         Parasite   2578\n",
       "2     Interstellar   2557\n",
       "3            Alien   2489\n",
       "4        Prisoners   2478\n",
       "5        The Thing   2468\n",
       "6        Midsommar   2446\n",
       "7          Arrival   2375\n",
       "8       Fight Club   2338\n",
       "9           Oldboy   2337\n",
       "10    Blade Runner   2317\n",
       "11    Annihilation   2171\n",
       "12         Memento   2159\n",
       "13       Coherence   2011\n",
       "14       Inception   1954\n",
       "15  Shutter Island   1928\n",
       "16             Saw   1899\n",
       "17    Nightcrawler   1890\n",
       "18  The Lighthouse   1829\n",
       "19             Big   1753"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_20_movies_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1dec1207-2e78-4ea6-b23d-d6f5fdece500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>average_positive_score</th>\n",
       "      <th>average_negative_score</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>weighted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big</td>\n",
       "      <td>0.854987</td>\n",
       "      <td>0.145013</td>\n",
       "      <td>57</td>\n",
       "      <td>0.848271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutter Island</td>\n",
       "      <td>0.793570</td>\n",
       "      <td>0.206430</td>\n",
       "      <td>259</td>\n",
       "      <td>0.792946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lighthouse</td>\n",
       "      <td>0.856795</td>\n",
       "      <td>0.143205</td>\n",
       "      <td>403</td>\n",
       "      <td>0.855771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hereditary</td>\n",
       "      <td>0.677252</td>\n",
       "      <td>0.322748</td>\n",
       "      <td>383</td>\n",
       "      <td>0.678031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>0.913287</td>\n",
       "      <td>0.086713</td>\n",
       "      <td>440</td>\n",
       "      <td>0.911839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alien</td>\n",
       "      <td>0.695798</td>\n",
       "      <td>0.304202</td>\n",
       "      <td>124</td>\n",
       "      <td>0.697572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Parasite</td>\n",
       "      <td>0.825086</td>\n",
       "      <td>0.174914</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.824935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inception</td>\n",
       "      <td>0.877136</td>\n",
       "      <td>0.122864</td>\n",
       "      <td>365</td>\n",
       "      <td>0.875786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Thing</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>0.236655</td>\n",
       "      <td>128</td>\n",
       "      <td>0.763018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prisoners</td>\n",
       "      <td>0.767761</td>\n",
       "      <td>0.232239</td>\n",
       "      <td>254</td>\n",
       "      <td>0.767526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>174</td>\n",
       "      <td>0.816432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nightcrawler</td>\n",
       "      <td>0.841751</td>\n",
       "      <td>0.158249</td>\n",
       "      <td>280</td>\n",
       "      <td>0.840495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>0.892283</td>\n",
       "      <td>0.107717</td>\n",
       "      <td>375</td>\n",
       "      <td>0.890809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Midsommar</td>\n",
       "      <td>0.754200</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>401</td>\n",
       "      <td>0.754184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blade Runner</td>\n",
       "      <td>0.879832</td>\n",
       "      <td>0.120168</td>\n",
       "      <td>112</td>\n",
       "      <td>0.875444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Annihilation</td>\n",
       "      <td>0.867996</td>\n",
       "      <td>0.132004</td>\n",
       "      <td>329</td>\n",
       "      <td>0.866609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oldboy</td>\n",
       "      <td>0.711097</td>\n",
       "      <td>0.288903</td>\n",
       "      <td>300</td>\n",
       "      <td>0.711642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Saw</td>\n",
       "      <td>0.682428</td>\n",
       "      <td>0.317572</td>\n",
       "      <td>188</td>\n",
       "      <td>0.683889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Coherence</td>\n",
       "      <td>0.878757</td>\n",
       "      <td>0.121243</td>\n",
       "      <td>94</td>\n",
       "      <td>0.873606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Memento</td>\n",
       "      <td>0.905998</td>\n",
       "      <td>0.094002</td>\n",
       "      <td>176</td>\n",
       "      <td>0.902589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  average_positive_score  average_negative_score  \\\n",
       "0              Big                0.854987                0.145013   \n",
       "1   Shutter Island                0.793570                0.206430   \n",
       "2   The Lighthouse                0.856795                0.143205   \n",
       "3       Hereditary                0.677252                0.322748   \n",
       "4          Arrival                0.913287                0.086713   \n",
       "5            Alien                0.695798                0.304202   \n",
       "6         Parasite                0.825086                0.174914   \n",
       "7        Inception                0.877136                0.122864   \n",
       "8        The Thing                0.763345                0.236655   \n",
       "9        Prisoners                0.767761                0.232239   \n",
       "10      Fight Club                0.817900                0.182100   \n",
       "11    Nightcrawler                0.841751                0.158249   \n",
       "12    Interstellar                0.892283                0.107717   \n",
       "13       Midsommar                0.754200                0.245800   \n",
       "14    Blade Runner                0.879832                0.120168   \n",
       "15    Annihilation                0.867996                0.132004   \n",
       "16          Oldboy                0.711097                0.288903   \n",
       "17             Saw                0.682428                0.317572   \n",
       "18       Coherence                0.878757                0.121243   \n",
       "19         Memento                0.905998                0.094002   \n",
       "\n",
       "    num_reviews  weighted_rating  \n",
       "0            57         0.848271  \n",
       "1           259         0.792946  \n",
       "2           403         0.855771  \n",
       "3           383         0.678031  \n",
       "4           440         0.911839  \n",
       "5           124         0.697572  \n",
       "6          1921         0.824935  \n",
       "7           365         0.875786  \n",
       "8           128         0.763018  \n",
       "9           254         0.767526  \n",
       "10          174         0.816432  \n",
       "11          280         0.840495  \n",
       "12          375         0.890809  \n",
       "13          401         0.754184  \n",
       "14          112         0.875444  \n",
       "15          329         0.866609  \n",
       "16          300         0.711642  \n",
       "17          188         0.683889  \n",
       "18           94         0.873606  \n",
       "19          176         0.902589  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentiment_df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "879152b0-a87d-43d0-a86b-5418da98cba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b01be382-41c9-4bc8-aab2-1b53e4201b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sentiment_of_suggestions = pd.merge(filtered_sentiment_df_pd, df_top_20_movies_pd, on=\"title\")[[\"title\", \"weighted_rating\", \"count\"]].sort_values(by=\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00d84536-c783-428e-a2e6-e701e3b89ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>weighted_rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hereditary</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>2733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Parasite</td>\n",
       "      <td>0.824935</td>\n",
       "      <td>2578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>0.890809</td>\n",
       "      <td>2557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alien</td>\n",
       "      <td>0.697572</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prisoners</td>\n",
       "      <td>0.767526</td>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Thing</td>\n",
       "      <td>0.763018</td>\n",
       "      <td>2468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Midsommar</td>\n",
       "      <td>0.754184</td>\n",
       "      <td>2446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrival</td>\n",
       "      <td>0.911839</td>\n",
       "      <td>2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>0.816432</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oldboy</td>\n",
       "      <td>0.711642</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blade Runner</td>\n",
       "      <td>0.875444</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Annihilation</td>\n",
       "      <td>0.866609</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Memento</td>\n",
       "      <td>0.902589</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Coherence</td>\n",
       "      <td>0.873606</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inception</td>\n",
       "      <td>0.875786</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutter Island</td>\n",
       "      <td>0.792946</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Saw</td>\n",
       "      <td>0.683889</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nightcrawler</td>\n",
       "      <td>0.840495</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lighthouse</td>\n",
       "      <td>0.855771</td>\n",
       "      <td>1829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big</td>\n",
       "      <td>0.848271</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  weighted_rating  count\n",
       "3       Hereditary         0.678031   2733\n",
       "6         Parasite         0.824935   2578\n",
       "12    Interstellar         0.890809   2557\n",
       "5            Alien         0.697572   2489\n",
       "9        Prisoners         0.767526   2478\n",
       "8        The Thing         0.763018   2468\n",
       "13       Midsommar         0.754184   2446\n",
       "4          Arrival         0.911839   2375\n",
       "10      Fight Club         0.816432   2338\n",
       "16          Oldboy         0.711642   2337\n",
       "14    Blade Runner         0.875444   2317\n",
       "15    Annihilation         0.866609   2171\n",
       "19         Memento         0.902589   2159\n",
       "18       Coherence         0.873606   2011\n",
       "7        Inception         0.875786   1954\n",
       "1   Shutter Island         0.792946   1928\n",
       "17             Saw         0.683889   1899\n",
       "11    Nightcrawler         0.840495   1890\n",
       "2   The Lighthouse         0.855771   1829\n",
       "0              Big         0.848271   1753"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_of_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90ac443b-1995-4de5-956b-73e68eeb5f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sentiment_of_suggestions.to_csv(\"../../data/csv/sentiment_of_suggestions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae654c47-ca14-4aac-8494-c8bdaaeb8fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a UDF to calculate normalized Levenshtein similarity score\n",
    "def similarity_score(str1, str2):\n",
    "    len1 = len(str1)\n",
    "    len2 = len(str2)\n",
    "    max_len = max(len1, len2)\n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "    return (max_len - levenshtein(str1, str2)) / max_len\n",
    "\n",
    "similarity_udf = udf(similarity_score, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d6d047-7ae3-4374-9669-008b6fe8de9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_top_500_movies.write.parquet(f\"s3a://{bucket}/projects/comments/extracted_movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1206e3-315a-4b86-8f29-1730a54a85f5",
   "metadata": {},
   "source": [
    "# ANIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f1db9-da50-4ec6-a93e-a79877341718",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SPARK JOB FOR NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9918c-4268-4acc-8fdc-5da3f7ff5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# session = sagemaker.Session()\n",
    "# bucket = \"project-group34\"\n",
    "# !wget -qO- https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/jars/spark-nlp-assembly-5.1.3.jar | aws s3 cp - s3://{bucket}/lab8/spark-nlp-assembly-5.1.3.jar\n",
    "# !aws s3 ls s3://{bucket}/lab8/spark-nlp-assembly-5.1.3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4b2eea-421f-4540-98d0-98eb6d0bb7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad07276-a679-4e9f-b840-2b086676682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./code/suggestion_extract_process.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./code/suggestion_extract_process.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import (\n",
    "    DoubleType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType\n",
    "import re\n",
    "from pyspark.sql.functions import explode, count\n",
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel, NerConverter\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "eng_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s,%(levelname)s,%(module)s,%(filename)s,%(lineno)d,%(message)s', level=logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "def main():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"app inputs and outputs\")\n",
    "    parser.add_argument(\"--s3_dataset_path\", type=str, help=\"Path of dataset in S3\")    \n",
    "    parser.add_argument(\"--col_name_for_filtering\", type=str, help=\"Name of the column to filter\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3\")\\\n",
    "    .getOrCreate()\n",
    "    \n",
    "    logger.info(f\"Spark version: {spark.version}\")\n",
    "    logger.info(f\"sparknlp version: {sparknlp.version()}\")\n",
    "    \n",
    "    # This is needed to save RDDs which is the only way to write nested Dataframes into CSV format\n",
    "    sc = spark.sparkContext\n",
    "    sc._jsc.hadoopConfiguration().set(\n",
    "        \"mapred.output.committer.class\", \"org.apache.hadoop.mapred.FileOutputCommitter\"\n",
    "    )\n",
    "\n",
    "    # Downloading the data from S3 into a Dataframe\n",
    "    logger.info(f\"going to read {args.s3_dataset_path} for r/{args.col_name_for_filtering}\")\n",
    "    df = spark.read.parquet(args.s3_dataset_path, header=True)\n",
    "    vals = [args.col_name_for_filtering]\n",
    "    df_filtered = df.where(col(\"subreddit\").isin(vals))\n",
    "    logger.info(f\"finished reading files...\")\n",
    "    logger.info(f\"Number of rows in data: {df_filtered.count()}\")\n",
    "    \n",
    "    # DATA CLEANING\n",
    "    df_filtered = df_filtered.filter((df.body != '[deleted]') & (df.author != '[deleted]'))\n",
    "\n",
    "    # Define the pipeline stages\n",
    "    document_assembler = DocumentAssembler() \\\n",
    "        .setInputCol(\"body\") \\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "    sentence_detector = SentenceDetector() \\\n",
    "        .setInputCols([\"document\"]) \\\n",
    "        .setOutputCol(\"sentence\")\n",
    "\n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([\"sentence\"]) \\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "    # Use GloVe embeddings\n",
    "    embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\", \"en\") \\\n",
    "        .setInputCols([\"sentence\", \"token\"]) \\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "\n",
    "    # Use a lighter NER model\n",
    "    ner_model = NerDLModel.pretrained(\"ner_dl\", \"en\") \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = NerConverter() \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "        .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "    # Build the pipeline\n",
    "    nlp_pipeline = Pipeline(stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        embeddings,\n",
    "        ner_model,\n",
    "        ner_converter\n",
    "    ])\n",
    "\n",
    "    # Apply the pipeline to your DataFrame\n",
    "    model = nlp_pipeline.fit(df_filtered)\n",
    "    result = model.transform(df_filtered)\n",
    "\n",
    "    print(\"NLP Pipeline Ran Succesfully!\")\n",
    "                \n",
    "    result = result.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"id\", \"created_utc\", \"score\", \"controversiality\", \"ner_chunk\")\n",
    "\n",
    "    # Define a UDF to filter and extract anime names\n",
    "    def extract_anime(chunks):\n",
    "        anime_names = [chunk.result for chunk in chunks if chunk.metadata['entity'] in ['PERSON', 'ORG']]\n",
    "        return anime_names\n",
    "\n",
    "    extract_anime_names_udf = udf(extract_anime, ArrayType(StringType()))\n",
    "\n",
    "    # Apply the UDF to the DataFrame\n",
    "    anime_df = result.withColumn(\"movie_names\", extract_anime_names_udf(F.col(\"ner_chunk\")))\n",
    "    \n",
    "    anime_df.write.parquet(\"s3a://project-group34/project/suggestions/all_anime/ner/\", mode=\"overwrite\")\n",
    "    \n",
    "    logger.info(f\"all done...\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f5224b-cf24-4f37-ae88-8f5262772546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 ms, sys: 61 µs, total: 14.9 ms\n",
      "Wall time: 34.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.spark.processing import PySparkProcessor\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e4bc35-a9dc-4c9d-b2c0-d668a78cd88b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'655678691473'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b750230-9a1b-4e48-9cf2-558f5141efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "CPU times: user 76.8 ms, sys: 0 ns, total: 76.8 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker.spark.processing import PySparkProcessor\n",
    "\n",
    "# Setup the PySpark processor to run the job. Note the instance type and instance count parameters. SageMaker will create these many instances of this type for the spark job.\n",
    "role = sagemaker.get_execution_role()\n",
    "spark_processor = PySparkProcessor(\n",
    "    base_job_name=\"sm-spark-project\",\n",
    "    image_uri=f\"{account_id}.dkr.ecr.us-east-1.amazonaws.com/sagemaker-spark:latest\",\n",
    "    framework_version=\"3.3\",\n",
    "    role=role,\n",
    "    instance_count=8,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    max_runtime_in_seconds=7200,\n",
    ")\n",
    "\n",
    "# # S3 URI of the initialization script\n",
    "# s3_uri_init_script = f's3://{bucket}/{script_key}'\n",
    "\n",
    "# s3 paths\n",
    "session = sagemaker.Session()\n",
    "output_prefix_logs = f\"spark_logs\"\n",
    "\n",
    "configuration = [\n",
    "    {\n",
    "        \"Classification\": \"spark-defaults\",\n",
    "        \"Properties\": {\"spark.executor.memory\": \"12g\", \"spark.executor.cores\": \"4\"},\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ef3e0f-b2b2-4881-9e5f-aade0765903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going to extract suggestions data for subreddit=Animesuggest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sm-spark-project-2023-11-26-18-21-00-232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!CPU times: user 5.03 s, sys: 438 ms, total: 5.47 s\n",
      "Wall time: 1h 58min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"going to extract suggestions data for subreddit=Animesuggest\")\n",
    "bucket = \"project-group34\"\n",
    "output_prefix_data_comments = \"project/comments/yyyy=*\"\n",
    "s3_path = f\"s3a://{bucket}/{output_prefix_data_comments}\"\n",
    "col_name_for_filtering = \"Animesuggest\"\n",
    "\n",
    "# run the job now, the arguments array is provided as command line to the Python script (Spark code in this case).\n",
    "spark_processor.run(\n",
    "    submit_app=\"./code/suggestion_extract_process.py\",\n",
    "    submit_jars=[f\"s3://{bucket}/spark-nlp-assembly-5.1.3.jar\"],\n",
    "    arguments=[\n",
    "        \"--s3_dataset_path\",\n",
    "        s3_path,\n",
    "        \"--col_name_for_filtering\",\n",
    "        col_name_for_filtering,\n",
    "    ],\n",
    "    spark_event_logs_s3_uri=\"s3://{}/{}/spark_event_logs\".format(bucket, output_prefix_logs),\n",
    "    logs=False,\n",
    "    configuration=configuration\n",
    ")\n",
    "# give some time for resources from this iterations to get cleaned up\n",
    "# if we start the job immediately we could get insufficient resources error\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034fbc20-d4b6-466c-b05f-ea759898e715",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8b942c-c9a5-454a-ad08-9617d935d6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a907a13-e6f8-4479-8aa2-1dcf6452d524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.0\n",
      "sparknlp version: 5.1.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"sparknlp version: {sparknlp.version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658d56e-c1cf-45c1-a478-7319c1420e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d4671e-8a65-433d-8538-d19efd2bdc3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "reading comments from s3a://project-group34/project/comments/yyyy=2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 03:18:48 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 205 ms, sys: 8.31 ms, total: 214 ms\n",
      "Wall time: 6.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bucket = \"project-group34\"\n",
    "session = sagemaker.Session()\n",
    "output_prefix_data_comments = \"project/comments/yyyy=2021\"\n",
    "s3_path = f\"s3a://{bucket}/{output_prefix_data_comments}\"\n",
    "print(f\"reading comments from {s3_path}\")\n",
    "comments = spark.read.parquet(s3_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0127134-a32a-44f7-a395-325f2b451d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comments = comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea18957-1f7d-43d4-8316-851cc0215e43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- retrieved_on: timestamp (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041761ba-7c26-4ca6-bf7c-e9f0918cccd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|       subreddit|         author|                body| parent_id|     id|        created_utc|score|controversiality|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|    Animesuggest|        Athenza|{Now and Then, He...| t3_m3ygv3|gqscelh|2021-03-13 10:15:52|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Ima, Soko ni Ir...|t1_gqscelh|gqscf1z|2021-03-13 10:16:05|    1|               0|\n",
      "|    Animesuggest|      [deleted]|           [deleted]| t3_m3vnjl|gqscjse|2021-03-13 10:18:25|    1|               0|\n",
      "|MovieSuggestions|      katnip_fl|       Jacobs Ladder| t3_m3rw47|gqscl5i|2021-03-13 10:19:07|    2|               0|\n",
      "|    Animesuggest|        Athenza|{Kino no Tabi: Th...| t3_m3xpu6|gqscnqz|2021-03-13 10:20:26|    1|               0|\n",
      "|    Animesuggest|    Dropsoftime|Try Mahouka kouko...| t3_m43dco|gqscnr8|2021-03-13 10:20:26|    3|               0|\n",
      "|MovieSuggestions|   alienstabler|[Holes (2003)](ht...| t3_l20wrm|gqscozr|2021-03-13 10:21:04|    1|               0|\n",
      "|    Animesuggest|       Roboragi|**Kino no Tabi: T...|t1_gqscnqz|gqscp63|2021-03-13 10:21:10|    1|               0|\n",
      "|    Animesuggest|crash-scientist|I didn’t mean to ...|t1_gqs4syw|gqscp6i|2021-03-13 10:21:10|    2|               0|\n",
      "|    Animesuggest|        dorting|    Watch Evangelion| t3_m3vnjl|gqscp9a|2021-03-13 10:21:13|    2|               0|\n",
      "|MovieSuggestions| ThalesHedonist|V for Vendetta\\n\\...| t3_m3rw47|gqscpsz|2021-03-13 10:21:29|    3|               0|\n",
      "|    Animesuggest|        Athenza|{Vampire Hunter D...| t3_m3wy06|gqscspa|2021-03-13 10:22:51|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Vampire Hunter ...|t1_gqscspa|gqsct5l|2021-03-13 10:23:05|    2|               0|\n",
      "|MovieSuggestions|   jaymewheeler|Synchronic was co...| t3_m3rw47|gqscu76|2021-03-13 10:23:37|    2|               0|\n",
      "|    Animesuggest|        Arvidex|- {Wonder Egg Pei...| t3_m3vnjl|gqscuva|2021-03-13 10:23:57|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Wonder Egg Prio...|t1_gqscuva|gqscvqx|2021-03-13 10:24:25|    1|               0|\n",
      "|    Animesuggest|        mgd5800|{Nejimaki Seirei ...| t3_m43dco|gqscxbt|2021-03-13 10:25:12|    2|               0|\n",
      "|MovieSuggestions|     SwissBliss|Climax!!!!! Sound...| t3_m3rw47|gqscxjk|2021-03-13 10:25:19|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Nejimaki Seirei...|t1_gqscxbt|gqscy94|2021-03-13 10:25:40|    2|               0|\n",
      "|    Animesuggest|     DyeDye1234|{is the order a r...| t3_m41ujb|gqsd2ku|2021-03-13 10:27:55|    1|               0|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# display a subset of columns\n",
    "comments.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"id\", \"created_utc\", \"score\", \"controversiality\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64dcbc-cb79-497f-805c-bfba623076a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f1d9e5a-cd48-4b0f-8761-269c69020750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out rows where 'body' or 'author' is '[deleted]'\n",
    "comments_filtered = comments.filter((comments.body != '[deleted]') & (comments.author != '[deleted]'))\n",
    "\n",
    "# Show the filtered DataFrame\n",
    "comments_filtered = comments_filtered.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"id\", \"created_utc\", \"score\", \"controversiality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa5694d-a1b3-40bd-8c5a-d34442aefedb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|       subreddit|         author|                body| parent_id|     id|        created_utc|score|controversiality|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "|    Animesuggest|        Athenza|{Now and Then, He...| t3_m3ygv3|gqscelh|2021-03-13 10:15:52|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Ima, Soko ni Ir...|t1_gqscelh|gqscf1z|2021-03-13 10:16:05|    1|               0|\n",
      "|MovieSuggestions|      katnip_fl|       Jacobs Ladder| t3_m3rw47|gqscl5i|2021-03-13 10:19:07|    2|               0|\n",
      "|    Animesuggest|        Athenza|{Kino no Tabi: Th...| t3_m3xpu6|gqscnqz|2021-03-13 10:20:26|    1|               0|\n",
      "|    Animesuggest|    Dropsoftime|Try Mahouka kouko...| t3_m43dco|gqscnr8|2021-03-13 10:20:26|    3|               0|\n",
      "|MovieSuggestions|   alienstabler|[Holes (2003)](ht...| t3_l20wrm|gqscozr|2021-03-13 10:21:04|    1|               0|\n",
      "|    Animesuggest|       Roboragi|**Kino no Tabi: T...|t1_gqscnqz|gqscp63|2021-03-13 10:21:10|    1|               0|\n",
      "|    Animesuggest|crash-scientist|I didn’t mean to ...|t1_gqs4syw|gqscp6i|2021-03-13 10:21:10|    2|               0|\n",
      "|    Animesuggest|        dorting|    Watch Evangelion| t3_m3vnjl|gqscp9a|2021-03-13 10:21:13|    2|               0|\n",
      "|MovieSuggestions| ThalesHedonist|V for Vendetta\\n\\...| t3_m3rw47|gqscpsz|2021-03-13 10:21:29|    3|               0|\n",
      "|    Animesuggest|        Athenza|{Vampire Hunter D...| t3_m3wy06|gqscspa|2021-03-13 10:22:51|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Vampire Hunter ...|t1_gqscspa|gqsct5l|2021-03-13 10:23:05|    2|               0|\n",
      "|MovieSuggestions|   jaymewheeler|Synchronic was co...| t3_m3rw47|gqscu76|2021-03-13 10:23:37|    2|               0|\n",
      "|    Animesuggest|        Arvidex|- {Wonder Egg Pei...| t3_m3vnjl|gqscuva|2021-03-13 10:23:57|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Wonder Egg Prio...|t1_gqscuva|gqscvqx|2021-03-13 10:24:25|    1|               0|\n",
      "|    Animesuggest|        mgd5800|{Nejimaki Seirei ...| t3_m43dco|gqscxbt|2021-03-13 10:25:12|    2|               0|\n",
      "|MovieSuggestions|     SwissBliss|Climax!!!!! Sound...| t3_m3rw47|gqscxjk|2021-03-13 10:25:19|    2|               0|\n",
      "|    Animesuggest|       Roboragi|**Nejimaki Seirei...|t1_gqscxbt|gqscy94|2021-03-13 10:25:40|    2|               0|\n",
      "|    Animesuggest|     DyeDye1234|{is the order a r...| t3_m41ujb|gqsd2ku|2021-03-13 10:27:55|    1|               0|\n",
      "|    Animesuggest|       Roboragi|**Gochuumon wa Us...|t1_gqsd2ku|gqsd3ca|2021-03-13 10:28:18|    1|               0|\n",
      "+----------------+---------------+--------------------+----------+-------+-------------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad4d636-2eb6-479e-8ba0-395e126ba94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments_filtered = comments_filtered.where(col(\"subreddit\").isin(\"Animesuggest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38aa8b8d-4691-458d-b944-06b7b0a70ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 384.9 MB\n",
      "[OK!]\n",
      "ner_dl_bert download started this may take some time.\n",
      "Approximate size to download 15.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# # Define the pipeline stages\n",
    "# document_assembler = DocumentAssembler() \\\n",
    "#     .setInputCol(\"body\") \\\n",
    "#     .setOutputCol(\"document\")\n",
    "\n",
    "# sentence_detector = SentenceDetector() \\\n",
    "#     .setInputCols([\"document\"]) \\\n",
    "#     .setOutputCol(\"sentence\")\n",
    "\n",
    "# tokenizer = Tokenizer() \\\n",
    "#     .setInputCols([\"sentence\"]) \\\n",
    "#     .setOutputCol(\"token\")\n",
    "\n",
    "# # Use a pretrained embeddings model, for example, BERT\n",
    "# embeddings = BertEmbeddings.pretrained(\"bert_base_cased\", \"en\") \\\n",
    "#     .setInputCols([\"sentence\", \"token\"]) \\\n",
    "#     .setOutputCol(\"embeddings\")\n",
    "\n",
    "# ner_model = NerDLModel.pretrained(\"ner_dl_bert\", \"en\") \\\n",
    "#     .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "#     .setOutputCol(\"ner\")\n",
    "\n",
    "# ner_converter = NerConverter() \\\n",
    "#     .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "#     .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# # Build the pipeline\n",
    "# nlp_pipeline = Pipeline(stages=[\n",
    "#     document_assembler,\n",
    "#     sentence_detector,\n",
    "#     tokenizer,\n",
    "#     embeddings,\n",
    "#     ner_model,\n",
    "#     ner_converter\n",
    "# ])\n",
    "\n",
    "# # Apply the pipeline to your DataFrame\n",
    "# model = nlp_pipeline.fit(comments_filtered_movies)\n",
    "# result = model.transform(comments_filtered_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aeb97f-87e5-4fce-be4b-db31e3644e45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ANIME SUGGESTIONS EXTRACTION USING NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e0608-e098-4934-865a-d1e447902511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel, NerConverter\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline stages\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"body\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Use GloVe embeddings\n",
    "embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\", \"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# Use a lighter NER model\n",
    "ner_model = NerDLModel.pretrained(\"ner_dl\", \"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# Build the pipeline\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    embeddings,\n",
    "    ner_model,\n",
    "    ner_converter\n",
    "])\n",
    "\n",
    "# Apply the pipeline to your DataFrame\n",
    "model = nlp_pipeline.fit(comments_filtered)\n",
    "result = model.transform(comments_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "668cbcbf-9f63-4f74-8203-9822cc91d62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = result.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"id\", \"created_utc\", \"score\", \"controversiality\", \"ner_chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae0f1b12-68fa-4666-ad53-828e74539677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+\n",
      "|   subreddit|     author|                body| parent_id|     id|        created_utc|score|controversiality|           ner_chunk|\n",
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+\n",
      "|Animesuggest|    Athenza|{Now and Then, He...| t3_m3ygv3|gqscelh|2021-03-13 10:15:52|    2|               0|[{chunk, 24, 29, ...|\n",
      "|Animesuggest|   Roboragi|**Ima, Soko ni Ir...|t1_gqscelh|gqscf1z|2021-03-13 10:16:05|    1|               0|[{chunk, 2, 4, Im...|\n",
      "|Animesuggest|    Athenza|{Kino no Tabi: Th...| t3_m3xpu6|gqscnqz|2021-03-13 10:20:26|    1|               0|[{chunk, 9, 12, T...|\n",
      "|Animesuggest|Dropsoftime|Try Mahouka kouko...| t3_m43dco|gqscnr8|2021-03-13 10:20:26|    3|               0|[{chunk, 4, 10, M...|\n",
      "|Animesuggest|   Roboragi|**Kino no Tabi: T...|t1_gqscnqz|gqscp63|2021-03-13 10:21:10|    1|               0|[{chunk, 2, 5, Ki...|\n",
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7c46ed-502a-42dd-b94b-7e35e80dde72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Define a UDF to filter and extract movie names\n",
    "def extract_anime(chunks):\n",
    "    movie_names = [chunk.result for chunk in chunks if chunk.metadata['entity'] in ['PERSON', 'ORG']]\n",
    "    return movie_names\n",
    "\n",
    "extract_anime_names_udf = udf(extract_anime, ArrayType(StringType()))\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "anime_df = result.withColumn(\"movie_names\", extract_anime_names_udf(F.col(\"ner_chunk\")))\n",
    "\n",
    "# # Display the results\n",
    "# anime_df.select(\"body\", \"movie_names\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8706ad4b-c098-4914-83a3-7dbac1b60528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+--------------------+\n",
      "|   subreddit|     author|                body| parent_id|     id|        created_utc|score|controversiality|           ner_chunk|         movie_names|\n",
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+--------------------+\n",
      "|Animesuggest|    Athenza|{Now and Then, He...| t3_m3ygv3|gqscelh|2021-03-13 10:15:52|    2|               0|[{chunk, 24, 29, ...|                  []|\n",
      "|Animesuggest|   Roboragi|**Ima, Soko ni Ir...|t1_gqscelh|gqscf1z|2021-03-13 10:16:05|    1|               0|[{chunk, 2, 4, Im...|[Ima, Soko ni Iru...|\n",
      "|Animesuggest|    Athenza|{Kino no Tabi: Th...| t3_m3xpu6|gqscnqz|2021-03-13 10:20:26|    1|               0|[{chunk, 9, 12, T...|[The Beautiful Wo...|\n",
      "|Animesuggest|Dropsoftime|Try Mahouka kouko...| t3_m43dco|gqscnr8|2021-03-13 10:20:26|    3|               0|[{chunk, 4, 10, M...|                  []|\n",
      "|Animesuggest|   Roboragi|**Kino no Tabi: T...|t1_gqscnqz|gqscp63|2021-03-13 10:21:10|    1|               0|[{chunk, 2, 5, Ki...|[Mobile Suit Gund...|\n",
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "anime_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a3492-433c-430f-91d8-216d93ffe7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anime_df.write.parquet(\"s3a://project-group34/project/suggestions/all_anime/ner/2021\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a314eea6-7483-467c-a395-85d9944770fe",
   "metadata": {},
   "source": [
    "## ANIME SUGGESTIONS EXTRACTION USING REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17209a2e-9532-47c3-95b1-4703d68dd7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.executor.cores\", \"3\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\"\n",
    "    )\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6516252-7781-4666-b750-8be35eb331b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa1a0e2f-7786-42cd-8bbf-1602fa76c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anime_df = spark.read.parquet(\"s3a://project-group34/project/suggestions/all_anime/ner/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ecc1aea-7ce5-4684-9f94-fb8507c0a587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+--------------------+\n",
      "|   subreddit|     author|                body| parent_id|     id|        created_utc|score|controversiality|           ner_chunk|         movie_names|\n",
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+--------------------+\n",
      "|Animesuggest|    Athenza|{Now and Then, He...| t3_m3ygv3|gqscelh|2021-03-13 10:15:52|    2|               0|[{chunk, 24, 29, ...|                  []|\n",
      "|Animesuggest|   Roboragi|**Ima, Soko ni Ir...|t1_gqscelh|gqscf1z|2021-03-13 10:16:05|    1|               0|[{chunk, 2, 4, Im...|[Ima, Soko ni Iru...|\n",
      "|Animesuggest|    Athenza|{Kino no Tabi: Th...| t3_m3xpu6|gqscnqz|2021-03-13 10:20:26|    1|               0|[{chunk, 9, 12, T...|[The Beautiful Wo...|\n",
      "|Animesuggest|Dropsoftime|Try Mahouka kouko...| t3_m43dco|gqscnr8|2021-03-13 10:20:26|    3|               0|[{chunk, 4, 10, M...|                  []|\n",
      "|Animesuggest|   Roboragi|**Kino no Tabi: T...|t1_gqscnqz|gqscp63|2021-03-13 10:21:10|    1|               0|[{chunk, 2, 5, Ki...|[Mobile Suit Gund...|\n",
      "+------------+-----------+--------------------+----------+-------+-------------------+-----+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "anime_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b738850c-75ee-4ad3-ba00-f53ea4c801c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField\n",
    "\n",
    "# import spacy\n",
    "import re\n",
    "\n",
    "# # Load spaCy model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Define schema for the UDF output\n",
    "# anime_schema = StructType([\n",
    "#     StructField(\"anime_positions\", ArrayType(ArrayType(StringType()))),\n",
    "#     StructField(\"anime_names\", ArrayType(StringType()))\n",
    "# ])\n",
    "\n",
    "# # UDF to extract anime names\n",
    "# @udf(anime_schema)\n",
    "# def extract_anime_names_udf(text):\n",
    "#     doc = nlp(text)\n",
    "#     anime_positions = []\n",
    "#     anime_names = []\n",
    "\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == \"ORG\" or ent.label_ == \"PERSON\":\n",
    "#             anime_positions.append([ent.start_char, ent.end_char])\n",
    "#             anime_names.append(ent.text)\n",
    "\n",
    "#     return (anime_positions, anime_names)\n",
    "\n",
    "# UDF to remove anime names\n",
    "@udf(StringType())\n",
    "def remove_anime_names_udf(text, anime_names):\n",
    "    if anime_names:\n",
    "        for name in anime_names:\n",
    "            text = text.replace(name, ' ')\n",
    "        return ' '.join(text.split())\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# UDF to extract anime names using regex\n",
    "@udf(ArrayType(StringType()))\n",
    "def extract_anime_names_regex_udf(text, anime_names):\n",
    "    anime_name_pattern = r'(?:\\\"([^\\\"]+)\\\"|([A-Z][a-z]*(?:\\s+(?:[a-z]+\\s+)*[A-Z][a-z]*)*)(?: \\(\\d{4}\\))?)'\n",
    "\n",
    "    anime_matches = re.findall(anime_name_pattern, text)\n",
    "    anime = [match[0] or match[1] or match[2] for match in anime_matches]\n",
    "    return anime_names + anime\n",
    "\n",
    "# Remove anime names from the 'body' text\n",
    "df_removed_anime_names = anime_df.withColumn(\"body_no_anime\", remove_anime_names_udf(anime_df[\"body\"], anime_df[\"movie_names\"]))\n",
    "\n",
    "# Regex method to supplement the NER extraction\n",
    "df_final = df_removed_anime_names.withColumn(\"additional_anime_names\", extract_anime_names_regex_udf(df_removed_anime_names[\"body_no_anime\"], df_removed_anime_names[\"movie_names\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1fee0cd-4b39-4a9b-970e-f48987140ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.select(\"subreddit\", \"author\", \"body\", \"created_utc\", \"score\", \"controversiality\", \"additional_anime_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "528da40d-c239-4a0d-9376-db235e62bbc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------+-------------------+-----+----------------+----------------------+\n",
      "|   subreddit|     author|                body|        created_utc|score|controversiality|additional_anime_names|\n",
      "+------------+-----------+--------------------+-------------------+-----+----------------+----------------------+\n",
      "|Animesuggest|    Athenza|{Now and Then, He...|2021-03-13 10:15:52|    2|               0|  [Now and Then, He...|\n",
      "|Animesuggest|   Roboragi|**Ima, Soko ni Ir...|2021-03-13 10:16:05|    1|               0|  [Ima, Soko ni Iru...|\n",
      "|Animesuggest|    Athenza|{Kino no Tabi: Th...|2021-03-13 10:20:26|    1|               0|  [The Beautiful Wo...|\n",
      "|Animesuggest|Dropsoftime|Try Mahouka kouko...|2021-03-13 10:20:26|    3|               0|         [Try Mahouka]|\n",
      "|Animesuggest|   Roboragi|**Kino no Tabi: T...|2021-03-13 10:21:10|    1|               0|  [Mobile Suit Gund...|\n",
      "+------------+-----------+--------------------+-------------------+-----+----------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ecf4144-43a0-45d9-8acc-20f4ab34e692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "eng_stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa4ec90-736f-47a3-9157-ad0640ac5f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "def remove_stop_word_from_anime_names(animes):\n",
    "    # Filter out single-word anime names that are in the stop words list\n",
    "    return [anime for anime in animes if not (len(anime.split()) == 1 and anime.lower() in eng_stopwords)]\n",
    "\n",
    "remove_stop_word_udf = udf(remove_stop_word_from_anime_names, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "204dda5e-3723-4090-b2ee-94ab2a8cada6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.withColumn(\"anime_names_final\", remove_stop_word_udf(df_final[\"additional_anime_names\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36bda465-2fdb-4ce2-a73e-9ed3e99fc8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.select(\"subreddit\", \"author\", \"body\", \"created_utc\", \"score\", \"controversiality\", \"anime_names_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5512beb8-f05e-4616-9c93-319e9ac5eba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a UDF to filter out single-letter anime names\n",
    "def remove_single_letter_animes(anime_names):\n",
    "    return [name for name in anime_names if len(name.strip()) > 1]\n",
    "\n",
    "remove_single_letter_animes_udf = udf(remove_single_letter_animes, ArrayType(StringType()))\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "df_final = df_final.withColumn(\"anime_names_final_cleaned\", remove_single_letter_animes_udf(\"anime_names_final\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "550ba8f2-e675-4333-8660-a2ac36ece2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = df_final.select(\"subreddit\", \"author\", \"body\", \"created_utc\", \"score\", \"controversiality\", \"anime_names_final_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4d914dd-b907-461f-867e-60aaa9e5dbb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|   subreddit|         author|                body|        created_utc|score|controversiality|anime_names_final_cleaned|\n",
      "+------------+---------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|Animesuggest|        Athenza|{Now and Then, He...|2021-03-13 10:15:52|    2|               0|     [Now and Then, He...|\n",
      "|Animesuggest|       Roboragi|**Ima, Soko ni Ir...|2021-03-13 10:16:05|    1|               0|     [Ima, Soko ni Iru...|\n",
      "|Animesuggest|        Athenza|{Kino no Tabi: Th...|2021-03-13 10:20:26|    1|               0|     [The Beautiful Wo...|\n",
      "|Animesuggest|    Dropsoftime|Try Mahouka kouko...|2021-03-13 10:20:26|    3|               0|            [Try Mahouka]|\n",
      "|Animesuggest|       Roboragi|**Kino no Tabi: T...|2021-03-13 10:21:10|    1|               0|     [Mobile Suit Gund...|\n",
      "|Animesuggest|crash-scientist|I didn’t mean to ...|2021-03-13 10:21:10|    2|               0|     [IDK, But you lit...|\n",
      "|Animesuggest|        dorting|    Watch Evangelion|2021-03-13 10:21:13|    2|               0|       [Watch Evangelion]|\n",
      "|Animesuggest|        Athenza|{Vampire Hunter D...|2021-03-13 10:22:51|    2|               0|     [{Vampire Hunter ...|\n",
      "|Animesuggest|       Roboragi|**Vampire Hunter ...|2021-03-13 10:23:05|    2|               0|     [Bloodlust, Vampi...|\n",
      "|Animesuggest|        Arvidex|- {Wonder Egg Pei...|2021-03-13 10:23:57|    2|               0|     [{Wonder Egg Peio...|\n",
      "|Animesuggest|       Roboragi|**Wonder Egg Prio...|2021-03-13 10:24:25|    1|               0|     [Wonder Egg, Wond...|\n",
      "|Animesuggest|        mgd5800|{Nejimaki Seirei ...|2021-03-13 10:25:12|    2|               0|     [The Labyrinth of...|\n",
      "|Animesuggest|       Roboragi|**Nejimaki Seirei...|2021-03-13 10:25:40|    2|               0|     [Sky, Alderamin, ...|\n",
      "|Animesuggest|     DyeDye1234|{is the order a r...|2021-03-13 10:27:55|    1|               0|                 [Tanaka]|\n",
      "|Animesuggest|       Roboragi|**Gochuumon wa Us...|2021-03-13 10:28:18|    1|               0|     [KINMOZA!\"),, Yur...|\n",
      "|Animesuggest|  _-Sandwitch-_|Third Mushishi an...|2021-03-13 10:30:02|   10|               0|     [Third Mushishi a...|\n",
      "|Animesuggest|     DyeDye1234|Not a manga but {...|2021-03-13 10:31:48|    1|               0|                       []|\n",
      "|Animesuggest|       Roboragi|**Katanagatari** ...|2021-03-13 10:32:15|    1|               0|     [Katanagatari, En...|\n",
      "|Animesuggest|         MaCl97|           \"Monster\"|2021-03-13 10:34:28|    1|               0|                [Monster]|\n",
      "|Animesuggest|    kyriosgreek|&gt;Mahouka kouko...|2021-03-13 10:35:44|    1|               0|                [Mahouka]|\n",
      "+------------+---------------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8947065-1073-441a-b1a0-4fa7d14ca234",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.write.parquet(\"s3a://project-group34/project/suggestions/all_animes/cleaned_with_regex/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251195c-791d-48b2-ab02-efed95a3840d",
   "metadata": {},
   "source": [
    "### EXPLODING SUGGESTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8f400-a9c1-4d13-b1b8-69d52be89171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.executor.cores\", \"3\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\"\n",
    "    )\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652e4798-9332-4f92-b5d4-0e3a0a70ae9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03303997-34a1-4fcb-acd9-a7ca0e6f0e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 20:54:25 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final = spark.read.parquet(\"s3a://project-group34/project/suggestions/all_animes/cleaned_with_regex/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86116b10-1bb4-47ce-96b9-e7d67eb7f649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|   subreddit|     author|                body|        created_utc|score|controversiality|anime_names_final_cleaned|\n",
      "+------------+-----------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "|Animesuggest|    Athenza|{Now and Then, He...|2021-03-13 10:15:52|    2|               0|     [Now and Then, He...|\n",
      "|Animesuggest|   Roboragi|**Ima, Soko ni Ir...|2021-03-13 10:16:05|    1|               0|     [Ima, Soko ni Iru...|\n",
      "|Animesuggest|    Athenza|{Kino no Tabi: Th...|2021-03-13 10:20:26|    1|               0|     [The Beautiful Wo...|\n",
      "|Animesuggest|Dropsoftime|Try Mahouka kouko...|2021-03-13 10:20:26|    3|               0|            [Try Mahouka]|\n",
      "|Animesuggest|   Roboragi|**Kino no Tabi: T...|2021-03-13 10:21:10|    1|               0|     [Mobile Suit Gund...|\n",
      "+------------+-----------+--------------------+-------------------+-----+----------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd8cf02-adbc-4781-9b4b-f4a6ca7cb6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col, count, split\n",
    "\n",
    "# Flatten the anime_names column\n",
    "df_flattened = df_final.withColumn(\"anime_name\", explode(col(\"anime_names_final_cleaned\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be340e06-0c03-4c75-9349-2fe134b31325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "# Rename specified anime titles\n",
    "df_flattened = df_flattened.withColumn(\"anime_name\",\n",
    "                   when(col(\"anime_name\") == \"Steins\", \"Steins Gate\")\n",
    "                   .when(col(\"anime_name\") == \"Gate\", \"Steins Gate\")\n",
    "                   .when(col(\"anime_name\") == \"One\", \"One Piece\")\n",
    "                   .when(col(\"anime_name\") == \"Attack\", \"Attack on Titan\")\n",
    "                   .when(col(\"anime_name\") == \"Titan\", \"Attack on Titan\")\n",
    "                   .when(col(\"anime_name\") == \"Kaguya\", \"Kaguya-sama: Love Is War\")\n",
    "                   .when(col(\"anime_name\") == \"English: Made in Abyss\", \"Made in Abyss\")\n",
    "                   .when(col(\"anime_name\") == \"English: Violet Evergarden\", \"Violet Evergarden\")\n",
    "                   .when(col(\"anime_name\") == \"Steins; \", \"Steins Gate\")\n",
    "                   .when(col(\"anime_name\") == \"AOT\", \"Attack on Titan\")\n",
    "                   .otherwise(col(\"anime_name\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09de723b-140b-431b-b4c9-e1670aba2500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "# Replace \"English: \" and \"English : \" with an empty string\n",
    "df_flattened = df_flattened.withColumn(\"anime_name\", regexp_replace(col(\"anime_name\"), \"English: ?\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8078019-5eff-4fc4-9b78-665d4fc0bdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim, col\n",
    "\n",
    "df_flattened = df_flattened.withColumn(\"anime_name\", trim(col(\"anime_name\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78e6dda4-d69e-415c-a099-ac6996265738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_anime_terms = [\n",
    "    \"Roboragi\", \"Status\", \"Genres\", \"Finished\", \"Episodes\", \"English: \",\n",
    "    \"Animesuggest\", \"Edit\", \"Source\", \"Nihilate\", \"Synonyms\", \"Mistake\",\n",
    "    \"Drama\", \"Comedy\", \"Action\", \"Romance\", \"Fantasy\", \"Slice of Life\",\n",
    "    \"Supernatural\", \"Adventure\", \"Psychological\", \"Sci\", \"Fi\", \"Mystery\",\n",
    "    \"Thriller\", \"Horror\", \"Thanks\", \"Movie\", \"Ecchi\", \"English\", \"Thank\",\n",
    "    \"Manga\", \"Also\", \"Mecha\", \"Please\", \"Sports\", \"Releasing\", \"Music\", \"Yeah\", \n",
    "    \"English: The \", \"Oh\", \"Fate\", \"Chapters\", \"OP\", \"Volumes\", \"Yes\", \"Episode\", \n",
    "    \"Maybe\", \"English: :\", \"Well\", \"Anime\", \"Season\", \"V Short\", \"Juj\", \"English: The\",\n",
    "    \"Jo\", \"English: A\", \"Netflix\", \"Great\", \"\", \"A\", \":\", \"on\", \"Really\", \"Like\", \"But I\",\n",
    "    \"The\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7275289e-8f7f-4f52-a072-c14c6586b475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out the non-anime names and streaming services\n",
    "df_flattened = df_flattened.filter(~col(\"anime_name\").isin(non_anime_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b477942b-ee54-4783-b2b5-61455adb6bff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|   subreddit|  author|                body|        created_utc|score|controversiality|anime_names_final_cleaned|          anime_name|\n",
      "+------------+--------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|Animesuggest| Athenza|{Now and Then, He...|2021-03-13 10:15:52|    2|               0|     [Now and Then, He...|        Now and Then|\n",
      "|Animesuggest| Athenza|{Now and Then, He...|2021-03-13 10:15:52|    2|               0|     [Now and Then, He...|      Here and There|\n",
      "|Animesuggest|Roboragi|**Ima, Soko ni Ir...|2021-03-13 10:16:05|    1|               0|     [Ima, Soko ni Iru...|                 Ima|\n",
      "|Animesuggest|Roboragi|**Ima, Soko ni Ir...|2021-03-13 10:16:05|    1|               0|     [Ima, Soko ni Iru...|    Soko ni Iru Boku|\n",
      "|Animesuggest|Roboragi|**Ima, Soko ni Ir...|2021-03-13 10:16:05|    1|               0|     [Ima, Soko ni Iru...|Now and Then, Her...|\n",
      "+------------+--------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0faa33eb-9ede-49d9-a288-32306983af8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened.write.parquet(\"s3a://project-group34/project/suggestions/all_animes/flattened/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e09eb9-8425-4dd0-a398-0f261d5f6642",
   "metadata": {},
   "source": [
    "### GROUPING SUGGESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b62f8e-a917-4239-8afd-6ff5bc19d72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import pyspark and build Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import pyspark and build Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\\\n",
    "    .config(\"spark.executor.cores\", \"3\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.3,org.apache.hadoop:hadoop-aws:3.2.2\")\\\n",
    "    .config(\n",
    "            \"fs.s3a.aws.credentials.provider\",\n",
    "            \"com.amazonaws.auth.ContainerCredentialsProvider\"\n",
    "    )\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97348fb8-841c-4154-9b1b-7f9b138f71b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pyspark.sql.functions import lower, regexp_replace, col, concat_ws\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import Finisher, DocumentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "045ff4c5-eb9a-4158-9ebe-5b8b042f53e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_flattened = spark.read.parquet(\"s3a://project-group34/project/suggestions/all_animes/flattened/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d434683f-d031-48c5-8984-e22ec33c393c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|   subreddit|          author|                body|        created_utc|score|controversiality|anime_names_final_cleaned|          anime_name|\n",
      "+------------+----------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "|Animesuggest|   ElegantTea122|Happy Sugar Life\\...|2021-01-28 17:24:45|    1|               0|     [Happy Sugar Life...|Happy Sugar Life\\...|\n",
      "|Animesuggest|   ElegantTea122|Happy Sugar Life\\...|2021-01-28 17:24:45|    1|               0|     [Happy Sugar Life...|          All have M|\n",
      "|Animesuggest|fearlesslalready| {God of highschool}|2021-01-28 17:27:15|    1|               1|                    [God]|                 God|\n",
      "|Animesuggest|      DuckFantic|I’ve never heard ...|2021-01-28 17:28:46|    3|               0|     [Black Clover, I’ll]|        Black Clover|\n",
      "|Animesuggest|      DuckFantic|I’ve never heard ...|2021-01-28 17:28:46|    3|               0|     [Black Clover, I’ll]|                I’ll|\n",
      "+------------+----------------+--------------------+-------------------+-----+----------------+-------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_flattened.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396eae3c-b7e3-4394-8d47-ebb0a1538d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime_frequency = df_flattened.groupBy(\"anime_name\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9bd6d51-9e68-4768-9069-bc2fd34c5e88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          anime_name|count|\n",
      "+--------------------+-----+\n",
      "|               Sword|  565|\n",
      "|Apollon (Kids on ...|    3|\n",
      "|                Vivy| 2813|\n",
      "|          Keiyakusha|  250|\n",
      "|                 S G|  117|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_anime_frequency.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae25b4ad-551e-449b-be7c-044941986c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Sort by count in descending order\n",
    "df_top_100_animes = df_anime_frequency.sort(desc('count')).limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e8faac-4bd9-44ad-9ca0-feadafe296b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:===============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|anime_name                       |count|\n",
      "+---------------------------------+-----+\n",
      "|Steins Gate                      |19606|\n",
      "|Attack on Titan                  |16722|\n",
      "|One Piece                        |10936|\n",
      "|Violet Evergarden                |8780 |\n",
      "|Made in Abyss                    |8558 |\n",
      "|Monster                          |8543 |\n",
      "|Clannad                          |7461 |\n",
      "|Zero                             |6724 |\n",
      "|Death Note                       |6559 |\n",
      "|Code Geass                       |6169 |\n",
      "|Cowboy Bebop                     |5758 |\n",
      "|Horimiya                         |5710 |\n",
      "|Gintama                          |5654 |\n",
      "|Berserk                          |5485 |\n",
      "|Dororo                           |5053 |\n",
      "|Vinland Saga                     |5043 |\n",
      "|Overlord                         |4887 |\n",
      "|Naruto                           |4778 |\n",
      "|Death Parade                     |4663 |\n",
      "|Mob Psycho                       |4621 |\n",
      "|Hunter x Hunter                  |4505 |\n",
      "|Fruits Basket                    |4500 |\n",
      "|Toradora                         |4356 |\n",
      "|Brotherhood                      |4338 |\n",
      "|Fullmetal Alchemist              |4324 |\n",
      "|Kaguya-sama: Love Is War         |4114 |\n",
      "|Another                          |3886 |\n",
      "|Mushishi                         |3799 |\n",
      "|Parasyte                         |3754 |\n",
      "|Erased                           |3694 |\n",
      "|Akudama Drive                    |3595 |\n",
      "|Hyouka                           |3587 |\n",
      "|Dorohedoro                       |3571 |\n",
      "|Mahou Shoujo                     |3527 |\n",
      "|Black Lagoon                     |3428 |\n",
      "|Samurai Champloo                 |3367 |\n",
      "|Jujutsu Kaisen                   |3301 |\n",
      "|Neon Genesis Evangelion          |3275 |\n",
      "|One Punch Man                    |3184 |\n",
      "|Your Lie in April                |3152 |\n",
      "|Silent Voice                     |3106 |\n",
      "|Odd Taxi                         |3101 |\n",
      "|Nichijou                         |3080 |\n",
      "|Gurren Lagann                    |3044 |\n",
      "|Bleach                           |3044 |\n",
      "|Definitely                       |2987 |\n",
      "|Konosuba                         |2929 |\n",
      "|Akame                            |2923 |\n",
      "|Love                             |2920 |\n",
      "|Tokyo Ghoul                      |2902 |\n",
      "|Ergo Proxy                       |2858 |\n",
      "|Trigun                           |2835 |\n",
      "|Charlotte                        |2818 |\n",
      "|Vivy                             |2813 |\n",
      "|Black Clover                     |2783 |\n",
      "|Talentless Nana                  |2732 |\n",
      "|Shiki                            |2729 |\n",
      "|Barakamon                        |2696 |\n",
      "|From the New World               |2676 |\n",
      "|Kaiji                            |2673 |\n",
      "|Try                              |2645 |\n",
      "|Madoka Magica                    |2641 |\n",
      "|Perfect Blue                     |2622 |\n",
      "|Psycho                           |2620 |\n",
      "|Good                             |2613 |\n",
      "|Haikyuu                          |2610 |\n",
      "|A Place Further Than the Universe|2609 |\n",
      "|Death                            |2596 |\n",
      "|Land of the Lustrous             |2563 |\n",
      "|Dr                               |2528 |\n",
      "|ERASED                           |2460 |\n",
      "|Watch                            |2449 |\n",
      "|Demon Slayer                     |2405 |\n",
      "|Grand Blue                       |2405 |\n",
      "|Puella Magi Madoka Magica        |2400 |\n",
      "|Akira                            |2361 |\n",
      "|Angel Beats                      |2346 |\n",
      "|Baccano                          |2338 |\n",
      "|Golden Time                      |2337 |\n",
      "|Serial Experiments Lain          |2334 |\n",
      "|Oregairu                         |2327 |\n",
      "|Galactic Heroes                  |2308 |\n",
      "|March comes in like a lion       |2290 |\n",
      "|Sword Art Online                 |2283 |\n",
      "|Claymore                         |2276 |\n",
      "|Promised Neverland               |2254 |\n",
      "|Evangelion                       |2250 |\n",
      "|Lion                             |2248 |\n",
      "|Mononoke                         |2219 |\n",
      "|Wotakoi                          |2205 |\n",
      "|100                              |2190 |\n",
      "|Assassination Classroom          |2146 |\n",
      "|Terror in Resonance              |2130 |\n",
      "|Bot                              |2106 |\n",
      "|Black                            |2101 |\n",
      "|Jojo                             |2092 |\n",
      "|Asobi Asobase                    |2091 |\n",
      "|Noragami                         |2077 |\n",
      "|Orange                           |2070 |\n",
      "|Elfen Lied                       |2055 |\n",
      "+---------------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top_100_animes.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05c4b1c9-5ae2-47d0-95e3-b1254c5c5363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top_100_animes_pd = df_top_100_animes.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f409621-a28b-42b0-9793-369b8e713727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steins Gate</td>\n",
       "      <td>19606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attack on Titan</td>\n",
       "      <td>16722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>10936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Violet Evergarden</td>\n",
       "      <td>8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Made in Abyss</td>\n",
       "      <td>8558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jojo</td>\n",
       "      <td>2092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Asobi Asobase</td>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Noragami</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Orange</td>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Elfen Lied</td>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           anime_name  count\n",
       "0         Steins Gate  19606\n",
       "1     Attack on Titan  16722\n",
       "2           One Piece  10936\n",
       "3   Violet Evergarden   8780\n",
       "4       Made in Abyss   8558\n",
       "..                ...    ...\n",
       "95               Jojo   2092\n",
       "96      Asobi Asobase   2091\n",
       "97           Noragami   2077\n",
       "98             Orange   2070\n",
       "99         Elfen Lied   2055\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_100_animes_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0931c5c9-8413-449d-9b5e-067d80cab680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_top_100_animes_pd.to_csv(\"../../data/csv/top100_animes_suggested.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648934c-449f-485b-8ca9-a624648c7372",
   "metadata": {},
   "source": [
    "## MERGE WITH EXTERNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822e950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb7af38-d774-41f8-a896-af2ebf10fb4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_name</th>\n",
       "      <th>japanese_title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steins Gate</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>19606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attack on Titan</td>\n",
       "      <td>Shingeki no Kyojin</td>\n",
       "      <td>16722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>Wan P_su</td>\n",
       "      <td>10936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Violet Evergarden</td>\n",
       "      <td>Vaioretto Ev_g_den</td>\n",
       "      <td>8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Made in Abyss</td>\n",
       "      <td>Meido in Abisu</td>\n",
       "      <td>8558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          anime_name      japanese_title  count\n",
       "0        Steins Gate         Steins;Gate  19606\n",
       "1    Attack on Titan  Shingeki no Kyojin  16722\n",
       "2          One Piece            Wan P_su  10936\n",
       "3  Violet Evergarden  Vaioretto Ev_g_den   8780\n",
       "4      Made in Abyss      Meido in Abisu   8558"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit = pd.read_csv(\"../../data/csv/top100_animes_suggested.csv\")\n",
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa34596-d4ee-42be-8ea2-cb7a1ed4376b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>episodes</th>\n",
       "      <th>popularity</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"0\"</td>\n",
       "      <td>['Music']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7345.0</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Aesop\" no Ohanashi yori: Ushi to Kaeru, Yokub...</td>\n",
       "      <td>['Kids']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12413.0</td>\n",
       "      <td>5.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Bungaku Shoujo\" Kyou no Oyatsu: Hatsukoi</td>\n",
       "      <td>['Comedy', 'Fantasy', 'School']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3466.0</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Bungaku Shoujo\" Memoire</td>\n",
       "      <td>['Drama', 'Romance', 'School']</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2943.0</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bungaku Shoujo\" Movie</td>\n",
       "      <td>['Mystery', 'Drama', 'Romance', 'School']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>7.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0                                                \"0\"   \n",
       "1           1  \"Aesop\" no Ohanashi yori: Ushi to Kaeru, Yokub...   \n",
       "2           2          \"Bungaku Shoujo\" Kyou no Oyatsu: Hatsukoi   \n",
       "3           3                           \"Bungaku Shoujo\" Memoire   \n",
       "4           4                             \"Bungaku Shoujo\" Movie   \n",
       "\n",
       "                                       genre episodes  popularity  score  \n",
       "0                                  ['Music']      1.0      7345.0   4.77  \n",
       "1                                   ['Kids']      1.0     12413.0   5.61  \n",
       "2            ['Comedy', 'Fantasy', 'School']      1.0      3466.0   6.96  \n",
       "3             ['Drama', 'Romance', 'School']      3.0      2943.0   7.40  \n",
       "4  ['Mystery', 'Drama', 'Romance', 'School']      1.0      1799.0   7.48  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_external = pd.read_csv(\"../../data/csv/anime_data.csv\")\n",
    "df_external.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9abb6fcc-17f7-4e38-8b66-81d5e9d3e21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c834c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match(name, choices, scorer=fuzz.WRatio, limit=1):\n",
    "    return process.extractOne(name, choices, scorer=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3eda4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df_external['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be1a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fuzzy matching\n",
    "df_reddit['matched_title'] = df_reddit['japanese_title'].apply(lambda x: get_best_match(x, titles, scorer=fuzz.WRatio)[0])\n",
    "df_reddit['matched_score'] = df_reddit['japanese_title'].apply(lambda x: df_external.loc[df_external['title'] == get_best_match(x, titles, scorer=fuzz.WRatio)[0], 'score'].iloc[0])\n",
    "\n",
    "# Apply fuzzy matching\n",
    "df_reddit['matched_title_english'] = df_reddit['anime_name'].apply(lambda x: get_best_match(x, titles, scorer=fuzz.WRatio)[0])\n",
    "df_reddit['matched_score_english'] = df_reddit['anime_name'].apply(lambda x: df_external.loc[df_external['title'] == get_best_match(x, titles, scorer=fuzz.WRatio)[0], 'score'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e3536ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_name</th>\n",
       "      <th>japanese_title</th>\n",
       "      <th>count</th>\n",
       "      <th>matched_title</th>\n",
       "      <th>matched_score</th>\n",
       "      <th>matched_title_english</th>\n",
       "      <th>matched_score_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steins Gate</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>19606</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>9.11</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attack on Titan</td>\n",
       "      <td>Shingeki no Kyojin</td>\n",
       "      <td>16722</td>\n",
       "      <td>Shingeki no Kyojin</td>\n",
       "      <td>8.47</td>\n",
       "      <td>K-On!</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>Wan P_su</td>\n",
       "      <td>10936</td>\n",
       "      <td>Doraemon Movie 25: Nobita no Wan Nyan Jikuuden</td>\n",
       "      <td>7.42</td>\n",
       "      <td>One Piece</td>\n",
       "      <td>8.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Violet Evergarden</td>\n",
       "      <td>Vaioretto Ev_g_den</td>\n",
       "      <td>8780</td>\n",
       "      <td>gdMen</td>\n",
       "      <td>5.95</td>\n",
       "      <td>Violet Evergarden</td>\n",
       "      <td>8.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Made in Abyss</td>\n",
       "      <td>Meido in Abisu</td>\n",
       "      <td>8558</td>\n",
       "      <td>Isu</td>\n",
       "      <td>4.56</td>\n",
       "      <td>Made in Abyss</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monster</td>\n",
       "      <td>Monsut_</td>\n",
       "      <td>8543</td>\n",
       "      <td>Monsuto Anime</td>\n",
       "      <td>6.44</td>\n",
       "      <td>Monster</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clannad</td>\n",
       "      <td>Kuranado</td>\n",
       "      <td>7461</td>\n",
       "      <td>K</td>\n",
       "      <td>7.62</td>\n",
       "      <td>Clannad</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zero</td>\n",
       "      <td>Zero</td>\n",
       "      <td>6724</td>\n",
       "      <td>AIKa Zero</td>\n",
       "      <td>5.98</td>\n",
       "      <td>AIKa Zero</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Death Note</td>\n",
       "      <td>Desu N_to</td>\n",
       "      <td>6559</td>\n",
       "      <td>TO</td>\n",
       "      <td>6.43</td>\n",
       "      <td>Death Note</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Code Geass</td>\n",
       "      <td>Code Geass</td>\n",
       "      <td>6169</td>\n",
       "      <td>Code Geass: Boukoku no Akito 1 - Yokuryuu wa M...</td>\n",
       "      <td>7.49</td>\n",
       "      <td>Code Geass: Boukoku no Akito 1 - Yokuryuu wa M...</td>\n",
       "      <td>7.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>5758</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>8.81</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>8.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Horimiya</td>\n",
       "      <td>Horimiya</td>\n",
       "      <td>5710</td>\n",
       "      <td>Grim</td>\n",
       "      <td>5.30</td>\n",
       "      <td>Grim</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gintama</td>\n",
       "      <td>Gintama</td>\n",
       "      <td>5654</td>\n",
       "      <td>Gintama</td>\n",
       "      <td>8.97</td>\n",
       "      <td>Gintama</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Berserk</td>\n",
       "      <td>Berserk</td>\n",
       "      <td>5485</td>\n",
       "      <td>Berserk</td>\n",
       "      <td>6.60</td>\n",
       "      <td>Berserk</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dororo</td>\n",
       "      <td>Dororo</td>\n",
       "      <td>5053</td>\n",
       "      <td>Dororo</td>\n",
       "      <td>8.23</td>\n",
       "      <td>Dororo</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vinland Saga</td>\n",
       "      <td>Vinland Saga</td>\n",
       "      <td>5043</td>\n",
       "      <td>Vinland Saga</td>\n",
       "      <td>8.78</td>\n",
       "      <td>Vinland Saga</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Overlord</td>\n",
       "      <td>Overlord</td>\n",
       "      <td>4887</td>\n",
       "      <td>Overlord</td>\n",
       "      <td>8.05</td>\n",
       "      <td>Overlord</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Naruto</td>\n",
       "      <td>Naruto</td>\n",
       "      <td>4778</td>\n",
       "      <td>Naruto</td>\n",
       "      <td>7.93</td>\n",
       "      <td>Naruto</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Death Parade</td>\n",
       "      <td>Death Parade</td>\n",
       "      <td>4663</td>\n",
       "      <td>Death Parade</td>\n",
       "      <td>8.22</td>\n",
       "      <td>Death Parade</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mob Psycho</td>\n",
       "      <td>Mob Psycho</td>\n",
       "      <td>4621</td>\n",
       "      <td>Mob Psycho 100</td>\n",
       "      <td>8.51</td>\n",
       "      <td>Mob Psycho 100</td>\n",
       "      <td>8.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           anime_name      japanese_title  count  \\\n",
       "0         Steins Gate         Steins;Gate  19606   \n",
       "1     Attack on Titan  Shingeki no Kyojin  16722   \n",
       "2           One Piece            Wan P_su  10936   \n",
       "3   Violet Evergarden  Vaioretto Ev_g_den   8780   \n",
       "4       Made in Abyss      Meido in Abisu   8558   \n",
       "5             Monster             Monsut_   8543   \n",
       "6             Clannad            Kuranado   7461   \n",
       "7                Zero                Zero   6724   \n",
       "8          Death Note           Desu N_to   6559   \n",
       "9          Code Geass          Code Geass   6169   \n",
       "10       Cowboy Bebop        Cowboy Bebop   5758   \n",
       "11           Horimiya            Horimiya   5710   \n",
       "12            Gintama             Gintama   5654   \n",
       "13            Berserk             Berserk   5485   \n",
       "14             Dororo              Dororo   5053   \n",
       "15       Vinland Saga        Vinland Saga   5043   \n",
       "16           Overlord            Overlord   4887   \n",
       "17             Naruto              Naruto   4778   \n",
       "18       Death Parade        Death Parade   4663   \n",
       "19         Mob Psycho          Mob Psycho   4621   \n",
       "\n",
       "                                        matched_title  matched_score  \\\n",
       "0                                         Steins;Gate           9.11   \n",
       "1                                  Shingeki no Kyojin           8.47   \n",
       "2      Doraemon Movie 25: Nobita no Wan Nyan Jikuuden           7.42   \n",
       "3                                               gdMen           5.95   \n",
       "4                                                 Isu           4.56   \n",
       "5                                       Monsuto Anime           6.44   \n",
       "6                                                   K           7.62   \n",
       "7                                           AIKa Zero           5.98   \n",
       "8                                                  TO           6.43   \n",
       "9   Code Geass: Boukoku no Akito 1 - Yokuryuu wa M...           7.49   \n",
       "10                                       Cowboy Bebop           8.81   \n",
       "11                                               Grim           5.30   \n",
       "12                                            Gintama           8.97   \n",
       "13                                            Berserk           6.60   \n",
       "14                                             Dororo           8.23   \n",
       "15                                       Vinland Saga           8.78   \n",
       "16                                           Overlord           8.05   \n",
       "17                                             Naruto           7.93   \n",
       "18                                       Death Parade           8.22   \n",
       "19                                     Mob Psycho 100           8.51   \n",
       "\n",
       "                                matched_title_english  matched_score_english  \n",
       "0                                         Steins;Gate                   9.11  \n",
       "1                                               K-On!                   7.86  \n",
       "2                                           One Piece                   8.53  \n",
       "3                                   Violet Evergarden                   8.62  \n",
       "4                                       Made in Abyss                   8.83  \n",
       "5                                             Monster                   8.69  \n",
       "6                                             Clannad                   8.16  \n",
       "7                                           AIKa Zero                   5.98  \n",
       "8                                          Death Note                   8.65  \n",
       "9   Code Geass: Boukoku no Akito 1 - Yokuryuu wa M...                   7.49  \n",
       "10                                       Cowboy Bebop                   8.81  \n",
       "11                                               Grim                   5.30  \n",
       "12                                            Gintama                   8.97  \n",
       "13                                            Berserk                   6.60  \n",
       "14                                             Dororo                   8.23  \n",
       "15                                       Vinland Saga                   8.78  \n",
       "16                                           Overlord                   8.05  \n",
       "17                                             Naruto                   7.93  \n",
       "18                                       Death Parade                   8.22  \n",
       "19                                     Mob Psycho 100                   8.51  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfb5afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = [\"One Piece\", \"Violet Evergarden\", \"Made in Abyss\", \"Monster\", \"Clannad\", \"Death Note\"]\n",
    "\n",
    "for anime_name in anime:\n",
    "    \n",
    "    for i in range(len(df_reddit)):\n",
    "        \n",
    "        if df_reddit.loc[i, \"anime_name\"] == anime_name:\n",
    "            df_reddit.loc[i, \"matched_title\"] = anime_name\n",
    "            df_reddit.loc[i, \"matched_score\"] = df_reddit.loc[i, \"matched_score_english\"]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f67e4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit = df_reddit[[\"anime_name\", \"japanese_title\", \"count\", \"matched_score\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a55b5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit.to_csv(\"../../data/csv/top20_animes_with_scores.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "dsan6600",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
